[
["index.html", "Minicurso de verano de Aprendizaje Máquina Temario", " Minicurso de verano de Aprendizaje Máquina Felipe González 2018-06-12 Temario Minicurso de aprendizaje máquina (ITAM, Junio 2018). En este curso de orientación aplicada se presentan las ideas fundamentales de aprendizaje máquina junto con ejemplos en R. Se suponen conocimientos básicos de cálculo multivariado y álgebra lineal. Notas Modelos lineales y regularización Introducción a aprendizaje máquina y métodos lineales. Sesgo, varianza y error de predicción. Evaluación de modelos. Regularización para modelos lineales. Métodos de optimización para ML Descenso en grandiente, descenso en gradiente estocástico y métodos derivados. Métodos basados en árboles Árboles para clasificación y regresión. Métodos de agregación para controlar varianza: bagging, boosting y bosques aleatorios. Aspectos prácticos en la construcción y evaluación de modelos. Recomendaciones generales en el proceso de mejora: datos y modelos. Problemas comunes en la evaluación de modelos. Referencias http://www-bcf.usc.edu/~gareth/ISL/ http://www.deeplearningbook.org Software https://www.r-project.org https://www.rstudio.com "],
["introduccion.html", "Sección 1 Introducción 1.1 ¿Qué es aprendizaje de máquina (machine learning)? 1.2 Aprendizaje Supervisado 1.3 Predicciones 1.4 Cuantificación de error o precisión 1.5 Tarea de aprendizaje supervisado 1.6 ¿Por qué tenemos errores? 1.7 Resumen", " Sección 1 Introducción 1.1 ¿Qué es aprendizaje de máquina (machine learning)? Métodos computacionales para aprender de datos con el fin de producir reglas para mejorar el desempeño en alguna tarea o toma de decisión. En este curso nos enfocamos en las tareas de aprendizaje supervisado, donde intentamos predecir o estimar una variable respuesta a partir de datos de entrada. Ejemplos de tareas de aprendizaje: Predecir si un cliente de tarjeta de crédito va a caer en impago en los próximos tres meses. Reconocer palabras escritas a mano (OCR). Detectar llamados de ballenas en grabaciones de boyas. Estimar el ingreso mensual de un hogar a partir de las características de la vivienda, posesiones y equipamiento y localización geográfica. Dividir a los clientes de Netflix según sus gustos. Recomendar artículos a clientes de un programa de lealtad o servicio online. Las razones usuales para intentar resolver estos problemas computacionalmente son diversas: Quisiéramos obtener una respuesta barata, rápida, automatizada, y con suficiente precisión. Por ejemplo, reconocer caracteres en una placa de coche de una fotografía se puede hacer por personas, pero eso es lento y costoso. Igual oír cada segundo de grabación de las boyas para saber si hay ballenas o no. Hacer mediciones directas del ingreso de un hogar requiere mucho tiempo y esfuerzo. Quisiéramos superar el desempeño actual de los expertos o de reglas simples utilizando datos: por ejemplo, en la decisión de dar o no un préstamo a un solicitante, puede ser posible tomar mejores decisiones con algoritmos que con evaluaciones personales o con reglas simples que toman en cuenta el ingreso mensual, por ejemplo. Queremos entender de manera más completa y sistemática el comportamiento de un fenómeno, identificando variables o patrones importantes. Es posible aproximarse a todos estos problemas usando reglas (por ejemplo, si los pixeles del centro de la imagen están vacíos, entonces es un cero, si el crédito total es mayor al 50% del ingreso anual, declinar el préstamo, etc) Las razones para intentar usar aprendizaje para producir reglas en lugar de intentar construir estas reglas directamente son, por ejemplo: Cuando conjuntos de reglas creadas a mano se desempeñan mal (por ejemplo, para otorgar créditos, reconocer caracteres, etc.) Reglas creadas a mano pueden ser difíciles de mantener (por ejemplo, un corrector ortográfico.) Ejemplo: reconocimiento de dígitos escritos a mano ¿Cómo reconocer los siguientes dígitos de manera automática? En los datos tenemos los valores de cada pixel (los caracteres son imagenes de 16x16 pixeles), y una etiqueta asociada, que es el número que la imagen representa. Podemos ver las imágenes y las etiquetas: library(tidyverse) zip_train &lt;- read_csv(file = &#39;datos/zip-train.csv&#39;) muestra_1 &lt;- sample_n(zip_train, 10) graficar_digitos(muestra_1) muestra_2 &lt;- sample_n(zip_train, 10) graficar_digitos(muestra_2) Los 16x16=256 están escritos acomodando las filas de la imagen en vector de 256 valores (cada renglón de zip_train). Un dígito entonces se representa como in vector de 256 números: dim(zip_train) ## [1] 7291 257 as.numeric(zip_train[1,]) ## [1] 6.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -0.631 0.862 ## [11] -0.167 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 ## [21] -1.000 -1.000 -1.000 -0.992 0.297 1.000 0.307 -1.000 -1.000 -1.000 ## [31] -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -0.410 ## [41] 1.000 0.986 -0.565 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 ## [51] -1.000 -1.000 -1.000 -1.000 -0.683 0.825 1.000 0.562 -1.000 -1.000 ## [61] -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -0.938 ## [71] 0.540 1.000 0.778 -0.715 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 ## [81] -1.000 -1.000 -1.000 -1.000 -1.000 0.100 1.000 0.922 -0.439 -1.000 ## [91] -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 ## [101] -0.257 0.950 1.000 -0.162 -1.000 -1.000 -1.000 -0.987 -0.714 -0.832 ## [111] -1.000 -1.000 -1.000 -1.000 -1.000 -0.797 0.909 1.000 0.300 -0.961 ## [121] -1.000 -1.000 -0.550 0.485 0.996 0.867 0.092 -1.000 -1.000 -1.000 ## [131] -1.000 0.278 1.000 0.877 -0.824 -1.000 -0.905 0.145 0.977 1.000 ## [141] 1.000 1.000 0.990 -0.745 -1.000 -1.000 -0.950 0.847 1.000 0.327 ## [151] -1.000 -1.000 0.355 1.000 0.655 -0.109 -0.185 1.000 0.988 -0.723 ## [161] -1.000 -1.000 -0.630 1.000 1.000 0.068 -0.925 0.113 0.960 0.308 ## [171] -0.884 -1.000 -0.075 1.000 0.641 -0.995 -1.000 -1.000 -0.677 1.000 ## [181] 1.000 0.753 0.341 1.000 0.707 -0.942 -1.000 -1.000 0.545 1.000 ## [191] 0.027 -1.000 -1.000 -1.000 -0.903 0.792 1.000 1.000 1.000 1.000 ## [201] 0.536 0.184 0.812 0.837 0.978 0.864 -0.630 -1.000 -1.000 -1.000 ## [211] -1.000 -0.452 0.828 1.000 1.000 1.000 1.000 1.000 1.000 1.000 ## [221] 1.000 0.135 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -0.483 0.813 ## [231] 1.000 1.000 1.000 1.000 1.000 1.000 0.219 -0.943 -1.000 -1.000 ## [241] -1.000 -1.000 -1.000 -1.000 -1.000 -0.974 -0.429 0.304 0.823 1.000 ## [251] 0.482 -0.474 -0.991 -1.000 -1.000 -1.000 -1.000 ¿Cómo combinamos esta información en un cálculo para reconocer el dígito computacionalmente? Un enfoque más utilizado anteriormente para resolver este tipo de problemas consistía en procesar estas imágenes con filtros hechos a mano (por ejemplo, calcular cuántos pixeles están prendidos, si existen ciertas curvas o trazos) para después construir reglas para determinar cada dígito. Actualmente, el enfoque más exitoso es utilizar métodos de aprendizaje que aprendan automáticamente esos filtros y esas reglas basadas en filtros (redes convolucionales). Ejemplo: predecir ingreso trimestral Consideramos la medición de ingreso total trimestral para una muestra de hogares de la encuesta de ENIGH. Cada una de estas mediciones es muy costosa en tiempo y dinero. dat_ingreso &lt;- read_csv(file = &#39;datos/enigh-ejemplo.csv&#39;) head(dat_ingreso) %&gt;% select(TAM_HOG, INGCOR, NOM_ENT_1, FOCOS, PISOS, marginación, tamaño_localidad) %&gt;% knitr::kable() TAM_HOG INGCOR NOM_ENT_1 FOCOS PISOS marginación tamaño_localidad 4 30238.13 Jalisco 11 3 Muy bajo De 15 mil a 100 mil 3 61147.41 México 10 2 Bajo De 15 mil a 100 mil 2 6170.21 Puebla 1 1 Alto De 2500 a 15 mil 2 14639.79 Distrito Federal 5 2 Muy bajo 100 mil o más 1 40638.35 Chihuahua 8 3 Muy bajo De 15 mil a 100 mil 2 21172.35 Baja California 4 2 Muy bajo 100 mil o más ggplot(dat_ingreso, aes(x=INGTOT)) + geom_histogram(bins = 100) + scale_x_log10() Pero quizá podemos usar otras variables más fácilmente medibles para predecir el ingreso de un hogar. Por ejemplo, si consideramos el número de focos en la vivienda: ggplot(dat_ingreso, aes(x = FOCOS, y = INGTOT)) + geom_point() + scale_y_log10() + xlim(c(0,50)) O el tamaño de la localidad: ggplot(dat_ingreso, aes(x = tamaño_localidad, y = INGTOT)) + geom_boxplot() + scale_y_log10() En algunas encuestas se pregunta directamente el ingreso mensual del hogar. La respuesta es generalmente una mala estimación del verdadero ingreso, por lo que actualmente se prefiere utilizar aprendizaje para estimar a partir de otras variables que son más fielmente reportadas por encuestados (años de estudio, ocupación, número de focos en el hogar, etc.) 1.2 Aprendizaje Supervisado Por el momento nos concentramos en problemas supervisados de regresión, es decir predicción de variables numéricas. ¿Cómo entendemos el problema de predicción? 1.2.1 Proceso generador de datos (modelo teórico) Para entender lo que estamos intentando hacer, pensaremos en términos de modelos probabilísticos que generan los datos. La idea es que estos representan los procesos que generan los datos o las observaciones. Si \\(Y\\) es la respuesta que queremos predecir, y \\(X\\) es una entrada que queremos usar para predecir \\(Y\\), consideramos que las variables aleatorias \\(Y\\) y \\(X\\) están relacionadas como sigue: \\[Y=f(X)+\\epsilon,\\] donde \\(\\epsilon\\) es una término de error aleatorio que no depende de \\(X\\), y que tiene valor esperado \\(\\textrm{E}(\\epsilon)=0\\). \\(f\\) expresa la relación sistemática que hay entre \\(Y\\) y \\(X\\): para cada valor posible de \\(X\\), la contribución de \\(X\\) a \\(Y\\) es \\(f(X)\\). Pero \\(X\\) no determina a \\(Y\\), como en el ejemplo anterior de rendimiento de coches. Entonces agregamos una error aleatorio \\(\\epsilon\\), con media cero (si la media no es cero podemos agregar una constante a \\(f\\)), que no contiene información acerca de \\(X\\) (independiente de \\(X\\)). \\(\\epsilon\\) representa, por ejemplo, el efecto de variables que no hemos medido o procesos aleatorios que determinan la respuesta. La función \\(f\\) típicamente es complicada y desconocida. Ejemplo Vamos a usar simulación para entender estas ideas: supongamos que \\(X\\) es el número de años de estudio de una persona y \\(Y\\) es su ingreso mensual. En primer lugar, estas son el número de años de estudio de 8 personas: x &lt;- c(1,7,10,0,0,5,9,13,2,4,17,18,1,2) Ahora supondremos que la dependencia de Y de X está dada por \\(Y=f(X)+\\epsilon\\) por una función \\(f\\) que no conocemos (esta función está determinada por el fenómeno) f &lt;- function(x){ ifelse(x &lt; 10, 1000*sqrt(x), 1000*sqrt(10)) } El ingreso no se determina únicamente por número de años de estudio. Suponemos entonces que hay algunas variables adicionales que perturban los niveles de \\(f(X)\\) por una cantidad aleatoria. Los valores que observamos de \\(Y\\) están dados entonces por \\(Y=f(X)+\\epsilon\\). Entonces podríamos obtener, por ejemplo: x_g &lt;- seq(0,20,0.5) y_g &lt;- f(x_g) dat_g &lt;- data.frame(x = x_g, y = y_g) set.seed(281) error &lt;- rnorm(length(x), 0, 500) y &lt;- f(x) + error datos &lt;- data_frame(x = x, y = y) datos$y_media &lt;- f(datos$x) ggplot(datos, aes(x = x, y = y)) + geom_point() + geom_line(data=dat_g, colour = &#39;gray&#39;, size = 1.1) + geom_segment(aes(x = x, xend = x, y = y, yend = y_media), col=&#39;red&#39;) En problemas de aprendizaje nunca conocemos esta \\(f\\) verdadera, aunque quizá sabemos algo acerca de sus propiedades (por ejemplo, continua, de variación suave). Lo que tenemos son los datos, que también podrían haber resultado en (para otra muestra de personas, por ejemplo): set.seed(28015) error &lt;- rnorm(length(x), 0, 500) y &lt;- f(x) + error datos &lt;- data.frame(x = x, y = y) ggplot(datos, aes(x = x, y = y)) + geom_point() La siguiente observación nos da una idea de lo que intentamos hacer, aunque todavía es vaga y requiere refinamiento: Bajo los supuestos del modelo \\(Y=f(X)+\\epsilon\\), aprender de los datos significa intentar recuperar o estimar la forma de la función \\(f\\) que no conocemos. \\(f\\) representa la relación sistemática entre \\(Y\\) y \\(X\\). ¿Qué tan bien podemos estimar esa \\(f\\) que no conocemos, con los datos disponibles? ¿Qué significa estimar bien? Incluso este ejemplo tan simple muestra las dificultades que vamos a enfrentar, y la importancia de determinar con cuidado qué tanta información tenemos, y qué tan buenas pueden ser nuestras predicciones. 1.3 Predicciones La idea es entonces producir una estimación de \\(f\\) que nos permita hacer predicciones. Si denotamos por \\(\\hat{f}\\) a una estimación de \\(f\\) construida a partir de los datos, podemos hacer predicciones aplicando \\(\\hat{f}\\) a valores de \\(X\\). La predicción de Y la denotamos por \\(\\hat{Y}\\), y \\[\\hat{Y}=\\hat{f}(X).\\] El error de predicción (residual) está dado por el valor observado menos la predicción: \\[Y-\\hat{Y}.\\] En nuestro ejemplo anterior, podríamos construir, por ejemplo, una recta ajustada por mínimos cuadrados: curva_1 &lt;- geom_smooth(data=datos, method = &quot;lm&quot;, se=FALSE, color=&quot;red&quot;, formula = y ~ x, size = 1.1) ggplot(datos, aes(x = x, y = y)) + geom_point() + curva_1 En este caso \\(\\hat{f}\\) es una recta, y la podemos usar para hacer predicciones. Por ejemplo, si tenemos una observación con \\(x_0=8\\) años de estudio, nuestra predicción del ingreso \\(\\hat{y}=\\hat{f}(8)\\) sería lineal &lt;- lm(y ~ x,data = datos) pred_1 &lt;- predict(lineal, newdata = data.frame(x=8)) pred_1 ## 1 ## 2193.561 ggplot(datos, aes(x = x, y = y)) + geom_point() + curva_1 + geom_segment(x = 0, xend = 8, y = pred_1, yend = pred_1, colour = &#39;salmon&#39;) + geom_segment(x = 8, xend = 8, y = 0, yend = pred_1, colour = &#39;salmon&#39;) + annotate(&#39;text&#39;, x = 0.5, y = pred_1 + 100, label = round(pred_1, 1)) + geom_point( x= 8, y =3200, col=&#39;green&#39;, size = 4) Si observamos que para esta observación con \\(x_0=8\\), resulta que el correspondiente ingreso es \\(y_0=3200\\), entonces el error sería y_0 &lt;- 3200 y_0 - pred_1 ## 1 ## 1006.439 En aprendizaje buscamos que estos errores sean lo más cercano a cero que sea posible. 1.4 Cuantificación de error o precisión El elemento faltante para definir la tarea de aprendizaje supervisado es qué significa aproximar bien a \\(f\\), o tener predicciones precisas. Para esto definimos una función de pérdida: \\[L(Y, \\hat{f}(X)),\\] que nos dice cuánto nos cuesta hacer la predicción \\(\\hat{f}(X)\\) cuando el verdadero valor es \\(Y\\) y las variables de entrada son \\(X\\). Una opción conveniente para problemas de regresión es la pérdida cuadrática: \\[L(Y, \\hat{f}(X)) = (Y - \\hat{f}(X))^2\\] Esta es una cantidad aleatoria, de modo que en algunos casos este error puede ser más grande o más chico. Usualmente buscamos una \\(\\hat{f}\\) de modo que el error promedio sea chico: \\[Err = E[(Y - \\hat{f}(X))^2]\\] Nota: Intenta demostrar que bajo error cuadrático medio y suponiendo el modelo aditivo \\(Y=f(X)+\\epsilon\\), el mejor predictor de \\(Y\\) es \\(f(x)= E[Y|X=x]\\). Es decir: lo que nos interesa es aproximar lo mejor que se pueda la esperanza condicional 1.5 Tarea de aprendizaje supervisado Ahora tenemos los elementos para definir con precisión el problema de aprendizaje supervisado. Consideramos un proceso generador de datos \\((X,Y)\\). En primer lugar, tenemos datos de los que vamos a aprender. Supongamos que tenemos un conjunto de datos etiquetados (generados según \\((X,Y)\\)) \\[{\\mathcal L}=\\{ (x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}), \\ldots, (x^{(N)}, y^{(N)}) \\}\\] que llamamos conjunto de entrenamiento. Nótese que usamos minúsculas para denotar observaciones particulares de \\((X,Y)\\). Un algoritmo de aprendizaje es una regla que asigna a cada conjunto de entrenamiento \\({\\mathcal L}\\) una función \\(\\hat{f}\\): \\[{\\mathcal L} \\to \\hat{f}.\\] Para medir el desempeño de un predictor particular \\(\\hat{f}\\) queremos ver cómo se va a comportar haciendo predicciones que no fueron vistos en el entrenamiento. Esto es porque esta es justamente la tarea que queremos resolver: Tenemos un conjunto de datos de entrenamiento, y construimos nuestro predictor \\(\\hat{f}\\). En el futuro llegan nuevos datos, y queremos aplicar nuestro predictor para hacer predicciones. Entonces, el desempeño del predictor particular \\(\\hat{f}\\) se mide como sigue: si en el futuro observamos otra muestra \\({\\mathcal T}\\) (que podemos llamar muestra de prueba) \\[{\\mathcal T}=\\{ (x_0^{(1)},y_0^{(1)}),(x_0^{(2)},y_0^{(2)}), \\ldots, (x_0^{(m)}, y_0^{(m)}) \\}\\] entonces decimos que el error de predicción (cuadrático) de \\(\\hat{f}\\) para el ejemplo \\((x_0^{(j)},y_0^{(j)})\\) está dado por \\[(y_0^{(j)} - \\hat{f}(x_0^{(j)}))^2\\] y el error sobre la muestra \\({\\mathcal T}\\) es \\[\\widehat{Err} = \\frac{1}{m}\\sum_{j=1}^m (y_0^{(j)} - \\hat{f}(x_0^{(j)}))^2\\] Es muy importante considerar dos muestras separadas en esta definición: No tiene mucho sentido medir el desempeño de nuestro algoritmo sobre la muestra de entrenamiento, pues el algoritmo puede ver las etiquetas. Considerar el error sobre una muestra diferente a la de entrenamiento nos permite evaluar si nuestro algoritmo generaliza, que se puede pensar como “verdadero” aprendizaje. Nótese que \\(\\widehat{Err}\\) es una estimación de \\(Err\\) (por la ley de los grandes números, si \\({\\mathcal T}\\) es muestra i.i.d. de \\((X,Y)\\)). También consideramos el error de entrenamiento, dado por \\[\\overline{err} = \\frac{1}{N}\\sum_{i=1}^N (y^{(i)} - \\hat{f}(x^{(i)}))^2\\] Nótese sin embargo que el error de entrenamiento no necesariamente es una buena estimación del error de prueba, que mide el desempeño verdadero del modelo. La razón es que modelos suficientemente flexibles pueden memorizar los datos de entrenamiento en lugar de aprender a generalizar de ellos. Un error de entrenamiento bajo no garantiza un desempeño bueno en el futuro. Discutiremos este punto más adelante. 1.5.0.1 Ejemplo En el ejemplo que hemos estado usando, ¿que curva preferirías para predecir, la gris, la roja o la azul? ¿Cuál tiene menor error de entrenamiento? set.seed(280572) error &lt;- rnorm(length(x), 0, 500) y &lt;- f(x) + error datos_entrena &lt;- data.frame(x=x, y=y) head(datos_entrena) ## x y ## 1 1 86.22033 ## 2 7 2353.75863 ## 3 10 3078.71029 ## 4 0 -397.80229 ## 5 0 424.73363 ## 6 5 3075.92998 curva.1 &lt;- geom_smooth(data=datos_entrena, method = &quot;loess&quot;, se=FALSE, color=&quot;gray&quot;, span=1, size=1.1) curva.2 &lt;- geom_smooth(data=datos_entrena, method = &quot;loess&quot;, se=FALSE, color=&quot;red&quot;, span=0.3, size=1.1) curva.3 &lt;- geom_smooth(data=datos_entrena, method = &quot;lm&quot;, se=FALSE, color=&quot;blue&quot;, size=1.1) ggplot(datos_entrena, aes(x=x, y=y)) + geom_point() + curva.1 + curva.2 + curva.3 Calculamos los errores de entrenamiento de cada curva: mod_rojo &lt;- loess(y ~ x, data = datos_entrena, span=0.3) mod_gris &lt;- loess(y ~ x, data = datos_entrena, span=1) mod_recta &lt;- lm(y ~ x, data = datos_entrena) df_mods &lt;- data_frame(nombre = c(&#39;recta&#39;, &#39;rojo&#39;,&#39;gris&#39;)) df_mods$modelo &lt;- list(mod_recta, mod_rojo, mod_gris) error_f &lt;- function(df){ function(mod){ preds &lt;- predict(mod, newdata = df) round(sqrt(mean((preds-df$y)^2))) } } error_ent &lt;- error_f(datos_entrena) df_mods &lt;- df_mods %&gt;% mutate(error_entrena = map_dbl(modelo, error_ent)) df_mods ## # A tibble: 3 x 3 ## nombre modelo error_entrena ## &lt;chr&gt; &lt;list&gt; &lt;dbl&gt; ## 1 recta &lt;S3: lm&gt; 782 ## 2 rojo &lt;S3: loess&gt; 189 ## 3 gris &lt;S3: loess&gt; 389 El error de entrenamiento es considerablemente menor para la curva roja, y es más grande para la recta. Sin embargo, consideremos que tenemos una nueva muestra (de prueba). set.seed(218052272) x_0 &lt;- sample(0:13, 100, replace = T) error &lt;- rnorm(length(x_0), 0, 500) y_0 &lt;- f(x_0) + error datos_prueba &lt;- data_frame(x = x_0, y = y_0) datos_prueba ## # A tibble: 100 x 2 ## x y ## &lt;int&gt; &lt;dbl&gt; ## 1 9 2156. ## 2 11 3227. ## 3 3 2382. ## 4 10 3482. ## 5 7 2733. ## 6 7 2326. ## 7 12 3464. ## 8 0 -564. ## 9 10 3296. ## 10 0 366. ## # ... with 90 more rows error_p &lt;- error_f(datos_prueba) df_mods &lt;- df_mods %&gt;% mutate(error_prueba = map_dbl(modelo, error_p)) df_mods ## # A tibble: 3 x 4 ## nombre modelo error_entrena error_prueba ## &lt;chr&gt; &lt;list&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 recta &lt;S3: lm&gt; 782 801 ## 2 rojo &lt;S3: loess&gt; 189 628 ## 3 gris &lt;S3: loess&gt; 389 520 Observaciones En la tarea de aprendizaje estadístico, las dos partes, entrenamiento y prueba, son cruciales. Una no tiene sentido sin la otra. Si no hacemos entrenamiento, no podemos construir modelos que respondan a los datos. Si no hacemos prueba, no podemos saber si nuestro modelo ajustado en entrenamiento es bueno o malo. El mejor modelo entrenamiento es uno que “sobreajusta” a los datos, pero es el peor con una muestra de prueba. La curva roja aprende del una componente de ruido del modelo - lo cual realmente no es aprendizaje. El modelo de la recta no es bueno en entrenamiento ni en prueba. Este modelo no tiene la capacidad para aprender de la señal en los datos. El mejor modelo en la muestra de prueba es uno que está entre la recta y la curva roja en términos de flexibilidad. Nuestra intuición para escoger el modelo gris desde el principio se refleja en que generaliza mejor que los otros, y eso a su vez se refleja en un error de prueba más bajo. 1.6 ¿Por qué tenemos errores? ¿De dónde provienen los errores en la predicción? Si establemos que el error es una función creciente de \\(Y-\\hat{Y}\\), vemos que \\[ Y-\\hat{Y} = f(X) + \\epsilon - \\hat{f}(X)= (f(X) - \\hat{f}(X)) + \\epsilon,\\] donde vemos que hay dos componentes que pueden hacer grande a \\(Y-\\hat{Y}\\): La diferencia \\(f(X) - \\hat{f}(X)\\) está asociada a error reducible, pues depende de qué tan bien estimemos \\(f(X)\\) con \\(\\hat{f}(X)\\) El error aleatorio \\(\\epsilon\\), asociado a error irreducible. Cualquiera de estas dos cantidades pueden hacer que nuestras predicciones no sean precisas. En nuestro ejemplo anterior, el error reducible: Es grande para el modelo rojo, pues responde demasiado fuerte a ruido en los datos (tiene varianza alta). Es grande para el modelo de la recta, pues no tiene capacidad para acercarse a la verdadera curva (está sesgado). En aprendizaje supervisado, nuestro objetivo es reducir el error reducible tanto como sea posible (obtener la mejor estimación de \\(f\\)). No podemos hacer nada acerca del error irreducible, pues este se debe a aleatoriedad en el fenómeno o a variables que no conocemos. Notación Las observaciones o datos que usaremos para construir nuestras estimaciones las denotamos como sigue. Cada observación (o caso, o ejemplo) está dada por el valor de una variable de entrada \\(X\\) y un valor de la variable de salida \\(Y\\). Cuando tenemos \\(N\\) ejemplos de entrenamiento, los escribimos como los pares \\[(x^{(1)},y^{(1)}), (x^{(2)},y^{(2)}) \\ldots, (x^{(N)},y^{(N)})\\]. Cuando los datos de entrada contienen \\(p\\) variables o atributos, escribimos \\[x^{(i)} = (x_1^{(i)}, x_2^{(i)},\\ldots, x_p^{(i)})\\] Escribimos también la matriz de entradas de dimensión Nxp: \\[\\underline{X} = \\left ( \\begin{array}{cccc} x_1^{(1)} &amp; x_2^{(1)} &amp; \\ldots &amp; x_p^{(1)} \\\\ x_1^{(2)} &amp; x_2^{(2)} &amp; \\ldots &amp; x_p^{(2)}\\\\ \\vdots &amp; \\vdots &amp; &amp; \\vdots \\\\ x_1^{(N)} &amp; x_2^{(N)} &amp; \\ldots &amp; x_p^{(N)} \\\\ \\end{array} \\right)\\] y \\[\\underline{y} =(y^{(1)},y^{(2)}, \\ldots, y^{(N)})^t.\\] Adicionalmente, usamos la notación \\[{\\mathcal L}=\\{ (x^{(1)},y^{(1)}), (x^{(2)},y^{(2)}), \\ldots, (x^{(N)},y^{(N)}) \\}\\] para denotar al conjunto de datos con los que construimos nuestro modelo. A este conjunto le llamaremos conjunto o muestra de entrenamiento (learning set) 1.7 Resumen Aprendizaje de máquina: algoritmos que aprenden de los datos para predecir cantidades numéricas, o clasificar (aprendizaje supervisado), o para encontrar estructura en los datos (aprendizaje no supervisado). En aprendizaje supervisado, el esquema general es: Un algoritmo aprende de una muestra de entrenamiento \\({\\mathcal L}\\), que es generada por el proceso generador de datos que nos interesa. Eso quiere decir que produce una función \\(\\hat{f}\\) (a partir de \\({\\mathcal L}\\)) que nos sirve para hacer predicciones \\(x \\to \\hat{f}(x)\\) de \\(y\\) El error de predicción del algoritmo es \\(Err\\), que mide en promedio qué tan lejos están las predicciones de valores reales. Para estimar esta cantidad usamos una muestra de prueba \\({\\mathcal T}\\), que es independiente de \\({\\mathcal L}\\). Esta es porque nos interesa el desempeño futuro de \\(\\hat{f}\\) para nuevos casos que el algoritmo no ha visto (esto es aprender). El error en la muestra de entrenamiento no necesariamente es buen indicador del desempeño futuro de nuestro algoritmo. Para obtener las mejores predicciones posibles, es necesario que el algoritmo sea capaz de capturar patrones en los datos, pero no tanto que tienda a absorber ruido en la estimación - es un balance de complejidad y rigidez. En términos estadísticos, se trata de un balance de varianza y sesgo. "],
["regresion-lineal.html", "Sección 2 Regresión lineal 2.1 Introducción 2.2 Aprendizaje de coeficientes (ajuste) 2.3 Descenso en gradiente 2.4 Descenso en gradiente para regresión lineal 2.5 Normalización de entradas 2.6 Interpretación de modelos lineales 2.7 ¿Por qué el modelo lineal funciona bien (muchas veces)? Ejercicio", " Sección 2 Regresión lineal 2.1 Introducción Consideramos un problema de regresión con entradas \\(X=(X_1,X_2,\\ldots, X_p)\\) y salida \\(Y\\). Una de las maneras más simples que podemos intentar para predecir \\(Y\\) en función de las \\(X_j\\)´s es mediante una suma ponderada de los valores de las \\(X_j&#39;s\\), usando una función \\[f_\\beta (X) = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\cdots + \\beta_p X_p,\\] Nuestro trabajo será entonces, dada una muestra de entrenamiento \\({\\mathcal L}\\), encontrar valores apropiados de las \\(\\beta\\)’s, para construir un predictor: \\[\\hat{f}(X) = \\hat{\\beta}_0 + \\hat{\\beta}_1 X_1 + \\hat{\\beta}_2 X_2 \\cdots + \\hat{\\beta} X_p\\] y usaremos esta función \\(\\hat{f}\\) para hacer predicciones \\(\\hat{Y} =\\hat{f}(X)\\). 2.1.0.1 Ejemplos Queremos predecir las ventas futuras anuales \\(Y\\) de un supermercado que se va a construir en un lugar dado. Las variables que describen el lugar son \\(X_1 = trafico\\_peatones\\), \\(X_2=trafico\\_coches\\). En una aproximación simple, podemos suponer que la tienda va a capturar una fracción de esos tráficos que se van a convertir en ventas. Quisieramos predecir con una función de la forma \\[f_\\beta (peatones, coches) = \\beta_0 + \\beta_1\\, peatones + \\beta_2\\, coches.\\] Por ejemplo, después de un análisis estimamos que \\(\\hat{\\beta}_0 = 1000000\\) (ventas base) \\(\\hat{\\beta}_1 = (200)*0.02 = 4\\) \\(\\hat{\\beta}_2 = (300)*0.01 =3\\) Entonces haríamos predicciones con \\[\\hat{f}(peatones, coches) = 1000000 + 4\\,peatones + 3\\, coches\\] El modelo lineal es más flexible de lo que parece en una primera aproximación, porque tenemos libertad para construir las variables de entrada a partir de nuestros datos. Por ejemplo, si tenemos una tercera variable \\(estacionamiento\\) que vale 1 si hay un estacionamiento cerca o 0 si no lo hay, podríamos definir las variables \\(X_1= peatones\\) \\(X_2 = coches\\) \\(X_3 = estacionamiento\\) \\(X_4 = coches*estacionamiento\\) Donde la idea de agregar \\(X_4\\) es que si hay estacionamiento entonces vamos a capturar una fracción adicional del trafico de coches, y la idea de \\(X_3\\) es que la tienda atraerá más nuevas visitas si hay un estacionamiento cerca. Buscamos ahora modelos de la forma \\[f_\\beta(X_1,X_2,X_3,X_4) = \\beta_0 + \\beta_1X_1 + \\beta_2 X_2 + \\beta_3 X_3 +\\beta_4 X_4\\] y podríamos obtener después de nuestra análisis las estimaciones \\(\\hat{\\beta}_0 = 800000\\) (ventas base) \\(\\hat{\\beta}_1 = 4\\) \\(\\hat{\\beta}_2 = (300)*0.005 = 1.5\\) \\(\\hat{\\beta}_3 = 400000\\) \\(\\hat{\\beta}_4 = (300)*0.02 = 6\\) y entonces haríamos predicciones con el modelo \\[\\hat{f} (X_1,X_2,X_3,X_4) = 800000 + 4\\, X_1 + 1.5 \\,X_2 + 400000\\, X_3 +6\\, X_4\\] 2.2 Aprendizaje de coeficientes (ajuste) En el ejemplo anterior, los coeficientes fueron calculados (o estimados) usando experiencia, argumentos teóricos, o quizá otras fuentes de datos (como estudios o encuestas, conteos, etc.) Ahora quisiéramos construir un algoritmo para aprender estos coeficientes del modelo \\[f_\\beta (X_1) = \\beta_0 + \\beta_1 X_1 + \\cdots \\beta_p X_p\\] a partir de una muestra de entrenamiento \\[{\\mathcal L}=\\{ (x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}), \\ldots, (x^{(N)}, y^{(N)}) \\}\\] El criterio de ajuste (algoritmo de aprendizaje) más usual para regresión lineal es el de mínimos cuadrados. Construimos las predicciones (ajustados) para la muestra de entrenamiento: \\[\\hat{y}^{(i)} = f_\\beta (x^{(i)}) = \\beta_0 + \\beta_1 x_1^{(i)}+ \\cdots + \\beta_p x_p^{(i)}\\] Y consideramos las diferencias de los ajustados con los valores observados: \\[e^{(i)} = y^{(i)} - f_\\beta (x^{(i)})\\] La idea entonces es minimizar la suma de los residuales al cuadrado, para intentar que la función ajustada pase lo más cercana a los puntos de entrenamiento que sea posible. Si \\[RSS(\\beta) = \\sum_{i=1}^N (y^{(i)} - f_\\beta(x^{(i)}))^2\\] Queremos resolver Mínimos cuadrados \\[\\min_{\\beta} RSS(\\beta) = \\min_{\\beta}\\sum_{i=1}^N (y^{(i)} - f_\\beta(x^{(i)}))^2\\] 2.2.0.1 Ejemplo Consideremos library(readr) library(dplyr) library(knitr) prostata &lt;- read_csv(&#39;datos/prostate.csv&#39;) %&gt;% select(lcavol, lpsa, train) kable(head(prostata), format = &#39;html&#39;) lcavol lpsa train -0.5798185 -0.4307829 TRUE -0.9942523 -0.1625189 TRUE -0.5108256 -0.1625189 TRUE -1.2039728 -0.1625189 TRUE 0.7514161 0.3715636 TRUE -1.0498221 0.7654678 TRUE prostata_entrena &lt;- filter(prostata, train) ggplot(prostata_entrena, aes(x = lcavol, y = lpsa)) + geom_point() En este caso, buscamos ajustar el modelo (tenemos una sola entrada) \\(f_{\\beta} (X_1) = \\beta_0 + \\beta_1 X_1\\), que es una recta. Los cálculos serían como sigue: rss_calc &lt;- function(datos){ y &lt;- datos$lpsa x &lt;- datos$lcavol fun_out &lt;- function(beta){ y_hat &lt;- beta[1] + beta[2]*x e &lt;- (y - y_hat) rss &lt;- sum(e^2) 0.5*rss } fun_out } Nuestra función rss es entonces: rss &lt;- rss_calc(prostata_entrena) Por ejemplo, si consideramos \\((\\beta_0, \\beta_1) = (0, 1.5)\\), obtenemos beta &lt;- c(0,1.5) rss(beta) ## [1] 61.63861 Que corresponde a la recta ggplot(prostata_entrena, aes(x = lcavol, y = lpsa)) + geom_point() + geom_abline(slope = beta[2], intercept = beta[1], col =&#39;red&#39;) Podemos comparar con \\((\\beta_0, \\beta_1) = (1, 1)\\), obtenemos beta &lt;- c(1,1) rss(beta) ## [1] 27.11781 ggplot(prostata_entrena, aes(x = lcavol, y = lpsa)) + geom_point() + geom_abline(slope = beta[2], intercept = beta[1], col =&#39;red&#39;) Ahora minimizamos. Podríamos hacer res_opt &lt;- optim(c(0,0), rss, method = &#39;BFGS&#39;) beta_hat &lt;- res_opt$par beta_hat ## [1] 1.5163048 0.7126351 res_opt$convergence ## [1] 0 ggplot(prostata_entrena, aes(x = lcavol, y = lpsa)) + geom_point() + geom_abline(slope = 1, intercept = 1, col =&#39;red&#39;) + geom_abline(slope = beta_hat[2], intercept = beta_hat[1]) Raíz del error cuadrático medio El error cuadrático medio, como medida de error, es difícil de interpretar. Por eso muchas veces preferimos reportar la raíz del error cuadrático medio, que tiene las mismas unidades que la variables que queremos predecir. A la raíz del error cuadrático medio le llamamos también error estándar \\(ee\\) de predicción. Bajo ciertas hipótesis, puede demostrarse que 95% de las veces, el valor verdadero está a no más de 2 errores estándar de la predicción. 2.3 Descenso en gradiente Aunque el problema de mínimos cuadrados se puede resolver analíticamente, proponemos un método numérico básico que es efectivo y puede escalarse a problemas grandes de manera relativamente simple: descenso en gradiente, o descenso máximo. Supongamos que una función \\(h(x)\\) es convexa y tiene un mínimo. La idea de descenso en gradiente es comenzar con un candidato inicial \\(z_0\\) y calcular la derivada en \\(z^{(0)}\\). Si \\(h(z^{(0)})&gt;0\\), la función es creciente en \\(z^{(0)}\\) y nos movemos ligeramente a la izquierda para obtener un nuevo candidato \\(z^{(1)}\\). si \\(h(z^{(0)})&lt;0\\), la función es decreciente en \\(z^{(0)}\\) y nos movemos ligeramente a la derecha para obtener un nuevo candidato \\(z^{(1)}\\). Iteramos este proceso hasta que la derivada es cercana a cero (estamos cerca del óptimo). Si \\(\\eta&gt;0\\) es una cantidad chica, podemos escribir \\[z^{(1)} = z^{(0)} - \\eta \\,h&#39;(z^{(0)}).\\] Nótese que cuando la derivada tiene magnitud alta, el movimiento de \\(z^{(0)}\\) a \\(z^{(1)}\\) es más grande, y siempre nos movemos una fracción de la derivada. En general hacemos \\[z^{(j+1)} = z^{(j)} - \\eta\\,h&#39;(z^{(j)})\\] para obtener una sucesión \\(z^{(0)},z^{(1)},\\ldots\\). Esperamos a que \\(z^{(j)}\\) converja para terminar la iteración. 2.3.0.1 Ejemplo Si tenemos h &lt;- function(x) x^2 + (x - 2)^2 - log(x^2 + 1) Calculamos (a mano): h_deriv &lt;- function(x) 2 * x + 2 * (x - 2) - 2*x/(x^2 + 1) Ahora iteramos con \\(\\eta = 0.4\\) y valor inicial \\(z_0=5\\) z_0 &lt;- 5 eta &lt;- 0.4 descenso &lt;- function(n, z_0, eta, h_deriv){ z &lt;- matrix(0,n, length(z_0)) z[1, ] &lt;- z_0 for(i in 1:(n-1)){ z[i+1, ] &lt;- z[i, ] - eta * h_deriv(z[i, ]) } z } z &lt;- descenso(20, 5, 0.1, h_deriv) z ## [,1] ## [1,] 5.000000 ## [2,] 3.438462 ## [3,] 2.516706 ## [4,] 1.978657 ## [5,] 1.667708 ## [6,] 1.488834 ## [7,] 1.385872 ## [8,] 1.326425 ## [9,] 1.291993 ## [10,] 1.272002 ## [11,] 1.260375 ## [12,] 1.253606 ## [13,] 1.249663 ## [14,] 1.247364 ## [15,] 1.246025 ## [16,] 1.245243 ## [17,] 1.244788 ## [18,] 1.244523 ## [19,] 1.244368 ## [20,] 1.244277 Y vemos que estamos cerca de la convergencia. curve(h, -3, 6) points(z[,1], h(z)) text(z[1:6], h(z[1:6]), pos = 3) 2.3.1 Selección de tamaño de paso \\(\\eta\\) Si hacemos \\(\\eta\\) muy chico, el algoritmo puede tardar mucho en converger: z &lt;- descenso(20, 5, 0.01, h_deriv) curve(h, -3, 6) points(z, h(z)) text(z[1:6], h(z[1:6]), pos = 3) Si hacemos \\(\\eta\\) muy grande, el algoritmo puede divergir: z &lt;- descenso(20, 5, 1.5, h_deriv) z ## [,1] ## [1,] 5.000000e+00 ## [2,] -1.842308e+01 ## [3,] 9.795302e+01 ## [4,] -4.837345e+02 ## [5,] 2.424666e+03 ## [6,] -1.211733e+04 ## [7,] 6.059265e+04 ## [8,] -3.029573e+05 ## [9,] 1.514792e+06 ## [10,] -7.573955e+06 ## [11,] 3.786978e+07 ## [12,] -1.893489e+08 ## [13,] 9.467445e+08 ## [14,] -4.733723e+09 ## [15,] 2.366861e+10 ## [16,] -1.183431e+11 ## [17,] 5.917153e+11 ## [18,] -2.958577e+12 ## [19,] 1.479288e+13 ## [20,] -7.396442e+13 Es necesario ajustar el tamaño de paso para cada problema particular. Si la convergencia es muy lenta, podemos incrementarlo. Si las iteraciones divergen, podemos disminuirlo 2.3.2 Funciones de varias variables Si ahora \\(h(z)\\) es una función de \\(p\\) variables, podemos intentar la misma idea usando el gradiente. Por cálculo sabemos que el gradiente apunta en la dirección de máximo crecimiento local. El gradiente es el vector columna con las derivadas parciales de \\(h\\): \\[\\nabla h(z) = \\left( \\frac{\\partial h}{\\partial z_1}, \\frac{\\partial h}{\\partial z_2}, \\ldots, \\frac{\\partial h}{\\partial z_p} \\right)^t\\] Y el paso de iteración, dado un valor inicial \\(z_0\\) y un tamaño de paso \\(\\eta &gt;0\\) es \\[z^{(i+1)} = z^{(i)} - \\eta \\nabla h(z^{(i)})\\] Las mismas consideraciones acerca del tamaño de paso \\(\\eta\\) aplican en el problema multivariado. h &lt;- function(z) { z[1]^2 + z[2]^2 - z[1] * z[2] } h_gr &lt;- function(z_1,z_2) apply(cbind(z_1, z_2), 1, h) grid_graf &lt;- expand.grid(z_1 = seq(-3, 3, 0.1), z_2 = seq(-3, 3, 0.1)) grid_graf &lt;- grid_graf %&gt;% mutate( val = apply(cbind(z_1,z_2), 1, h)) gr_contour &lt;- ggplot(grid_graf, aes(x = z_1, y = z_2, z = val)) + geom_contour(binwidth = 1.5, aes(colour = ..level..)) gr_contour El gradiente (calculado a mano) está dado por h_grad &lt;- function(z){ c(2*z[1] - z[2], 2*z[2] - z[1]) } Podemos graficar la dirección de máximo descenso para diversos puntos. Estas direcciones son ortogonales a la curva de nivel que pasa por cada uno de los puntos: grad_1 &lt;- h_grad(c(0,-2)) grad_2 &lt;- h_grad(c(1,1)) eta &lt;- 0.2 gr_contour + geom_segment(aes(x=0.0, xend=0.0-eta*grad_1[1], y=-2, yend=-2-eta*grad_1[2]), arrow = arrow(length = unit(0.2,&quot;cm&quot;)))+ geom_segment(aes(x=1, xend=1-eta*grad_2[1], y=1, yend=1-eta*grad_2[2]), arrow = arrow(length = unit(0.2,&quot;cm&quot;)))+ coord_fixed(ratio = 1) Y aplicamos descenso en gradiente: inicial &lt;- c(3, 1) iteraciones &lt;- descenso(20, inicial , 0.1, h_grad) iteraciones ## [,1] [,2] ## [1,] 3.0000000 1.0000000 ## [2,] 2.5000000 1.1000000 ## [3,] 2.1100000 1.1300000 ## [4,] 1.8010000 1.1150000 ## [5,] 1.5523000 1.0721000 ## [6,] 1.3490500 1.0129100 ## [7,] 1.1805310 0.9452330 ## [8,] 1.0389481 0.8742395 ## [9,] 0.9185824 0.8032864 ## [10,] 0.8151946 0.7344874 ## [11,] 0.7256044 0.6691094 ## [12,] 0.6473945 0.6078479 ## [13,] 0.5787004 0.5510178 ## [14,] 0.5180621 0.4986843 ## [15,] 0.4643181 0.4507536 ## [16,] 0.4165298 0.4070347 ## [17,] 0.3739273 0.3672807 ## [18,] 0.3358699 0.3312173 ## [19,] 0.3018177 0.2985609 ## [20,] 0.2713102 0.2690305 ggplot(data= grid_graf) + geom_contour(binwidth = 1.5, aes(x = z_1, y = z_2, z = val, colour = ..level..)) + geom_point(data = data.frame(iteraciones), aes(x=X1, y=X2), colour = &#39;red&#39;) 2.4 Descenso en gradiente para regresión lineal Vamos a escribir ahora el algoritmo de descenso en gradiente para regresión lineal. Igual que en los ejemplos anteriores, tenemos que precalcular el gradiente. Una vez que esto esté terminado, escribir la iteración es fácil. Recordamos que queremos minimizar (dividiendo entre dos para simplificar más adelante) \\[RSS(\\beta) = \\frac{1}{2}\\sum_{i=1}^N (y^{(i)} - f_\\beta(x^{(i)}))^2\\] La derivada de la suma es la suma de las derivadas, así nos concentramos en derivar uno de los términos \\[ \\frac{1}{2}(y^{(i)} - f_\\beta(x^{(i)}))^2 \\] Usamos la regla de la cadena para obtener \\[ \\frac{1}{2}\\frac{\\partial}{\\partial \\beta_j} (y^{(i)} - f_\\beta(x^{(i)}))^2 = -(y^{(i)} - f_\\beta(x^{(i)})) \\frac{\\partial f_\\beta(x^{(i)})}{\\partial \\beta_j}\\] Ahora recordamos que \\[f_{\\beta} (x) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\cdots + \\beta_p x_p\\] Y vemos que tenemos dos casos. Si \\(j=0\\), \\[\\frac{\\partial f_\\beta(x^{(i)})}{\\partial \\beta_0} = 1\\] y si \\(j=1,2,\\ldots, p\\) entonces \\[\\frac{\\partial f_\\beta(x^{(i)})}{\\partial \\beta_j} = x_j^{(i)}\\] Entonces: \\[\\frac{\\partial f_\\beta(x^{(i)})}{\\partial \\beta_0} = -(y^{(i)} - f_\\beta(x^{(i)}))\\] y \\[\\frac{\\partial f_\\beta(x^{(i)})}{\\partial \\beta_j} = - x_j^{(i)}(y^{(i)} - f_\\beta(x^{(i)}))\\] Y sumando todos los términos (uno para cada caso de entrenamiento): Gradiente para regresión lineal Sea \\(e^{(i)} = y_{(i)} - f_{\\beta} (x^{(i)})\\). Entonces \\[\\begin{equation} \\frac{\\partial RSS(\\beta)}{\\partial \\beta_0} = - \\sum_{i=1}^N e^{(i)} \\tag{2.1} \\end{equation}\\] \\[\\begin{equation} \\frac{\\partial RSS(\\beta)}{\\partial \\beta_j} = - \\sum_{i=1}^N x_j^{(i)}e^{(i)} \\tag{2.2} \\end{equation}\\] para \\(j=1,2,\\ldots, p\\). Nótese que cada punto de entrenamiento contribuye al cálculo del gradiente - la contribución es la dirección de descenso de error para ese punto particular de entrenamiento. Nos movemos entonces en una dirección promedio, para intentar hacer el error total lo más chico posible. Podemos implementar ahora estos cálculos. Aunque podríamos escribir ciclos para hacer estos cálculos, es mejor hacer los cálculos en forma matricial, de manera que aprovechamos rutinas de álgebra lineal eficiente. El cálculo del gradiente es como sigue: grad_calc &lt;- function(x_ent, y_ent){ salida_grad &lt;- function(beta){ f_beta &lt;- as.matrix(cbind(1, x_ent)) %*% beta e &lt;- y_ent - f_beta grad_out &lt;- -as.numeric(t(cbind(1,x_ent)) %*% e) names(grad_out) &lt;- c(&#39;Intercept&#39;, colnames(x_ent)) grad_out } salida_grad } grad &lt;- grad_calc(prostata_entrena[, 1, drop = FALSE], prostata_entrena$lpsa) grad(c(0,1)) ## Intercept lcavol ## -76.30319 -70.93938 grad(c(1,1)) ## Intercept lcavol ## -9.303187 17.064556 Podemos checar nuestro cálculo del gradiente: delta &lt;- 0.001 (rss(c(1 + delta,1)) - rss(c(1,1)))/delta ## [1] -9.269687 (rss(c(1,1+delta)) - rss(c(1,1)))/delta ## [1] 17.17331 Y ahora iteramos para obtener iteraciones &lt;- descenso(30, c(0,0), 0.005, grad) iteraciones ## [,1] [,2] ## [1,] 0.0000000 0.0000000 ## [2,] 0.8215356 1.4421892 ## [3,] 0.7332652 0.9545169 ## [4,] 0.8891507 1.0360252 ## [5,] 0.9569494 0.9603012 ## [6,] 1.0353555 0.9370937 ## [7,] 1.0977074 0.9046239 ## [8,] 1.1534587 0.8800287 ## [9,] 1.2013557 0.8576489 ## [10,] 1.2430547 0.8385314 ## [11,] 1.2791967 0.8218556 ## [12,] 1.3105688 0.8074114 ## [13,] 1.3377869 0.7948709 ## [14,] 1.3614051 0.7839915 ## [15,] 1.3818983 0.7745509 ## [16,] 1.3996803 0.7663595 ## [17,] 1.4151098 0.7592518 ## [18,] 1.4284979 0.7530844 ## [19,] 1.4401148 0.7477329 ## [20,] 1.4501947 0.7430895 ## [21,] 1.4589411 0.7390604 ## [22,] 1.4665303 0.7355643 ## [23,] 1.4731155 0.7325308 ## [24,] 1.4788295 0.7298986 ## [25,] 1.4837875 0.7276146 ## [26,] 1.4880895 0.7256328 ## [27,] 1.4918224 0.7239132 ## [28,] 1.4950614 0.7224211 ## [29,] 1.4978719 0.7211265 ## [30,] 1.5003106 0.7200031 Y checamos que efectivamente el error total de entrenamiento decrece apply(iteraciones, 1, rss) ## [1] 249.60960 51.70986 32.49921 28.96515 27.22475 25.99191 25.07023 ## [8] 24.37684 23.85483 23.46181 23.16591 22.94312 22.77538 22.64910 ## [15] 22.55401 22.48242 22.42852 22.38794 22.35739 22.33438 22.31706 ## [22] 22.30402 22.29421 22.28681 22.28125 22.27706 22.27390 22.27153 ## [29] 22.26974 22.26839 Notación y forma matricial Usando la notación de la clase anterior (agregando una columna de unos al principio): \\[\\underline{X} = \\left ( \\begin{array}{ccccc} 1 &amp; x_1^{(1)} &amp; x_2^{(1)} &amp; \\ldots &amp; x_p^{(1)} \\\\ 1 &amp; x_1^{(2)} &amp; x_2^{(2)} &amp; \\ldots &amp; x_p^{(2)}\\\\ 1&amp; \\vdots &amp; \\vdots &amp; &amp; \\vdots \\\\ 1 &amp; x_1^{(N)} &amp; x_2^{(N)} &amp; \\ldots &amp; x_p^{(N)} \\\\ \\end{array} \\right)\\] y \\[\\underline{y} =(y^{(1)},y^{(2)}, \\ldots, y^{(N)})^t.\\] Como \\[\\underline{e} = \\underline{y} - \\underline{X}\\beta\\] tenemos entonces (de las fórmulas (2.1) y (2.2)): \\[\\begin{equation} \\nabla RSS(\\beta) = \\underline{X}^t(\\underline{X}\\beta - \\underline{y}) = -\\underline{X}^t \\underline{e} \\tag{2.3} \\end{equation}\\] 2.5 Normalización de entradas La convergencia de descenso en gradiente (y también el desempeño numérico para otros algoritmos) puede dificultarse cuando las escalas tienen escalas muy diferentes. En este ejemplo simple, una variable tiene desviación estándar 10 y otra 1: x2 &lt;- rnorm(100, 0, 1) x1 &lt;- rnorm(100, 0, 10) + 5 * x2 y &lt;- 0.1 * x1 + x2 + rnorm(100, 0, 1) dat &lt;- data_frame(x1, x2, y) rss &lt;- function(beta) mean((as.matrix(dat[, 1:2]) %*% beta - y)^2) grid_beta &lt;- expand.grid(beta1 = seq(-10, 10, 0.5), beta2 = seq(-10, 10, 0.5)) rss_1 &lt;- apply(grid_beta, 1, rss) dat_x &lt;- data.frame(grid_beta, rss_1) ggplot(dat_x, aes(x = beta1, y = beta2, z = rss_1)) + geom_contour() En algunas direcciones el gradiente es muy grande, y en otras chico. Esto implica que la convergencia puede ser muy lenta en algunas direcciones, puede diverger en otras, y que hay que ajustar el paso \\(\\eta &gt; 0\\) con cuidado, dependiendo de dónde comiencen las iteraciones. Una normalización usual es con la media y desviación estándar, donde hacemos, para cada variable de entrada \\(j=1,2,\\ldots, p\\) \\[ x_j^{(i)} = \\frac{ x_j^{(i)} - \\bar{x}_j}{s_j}\\] donde \\[\\bar{x}_j = \\frac{1}{N} \\sum_{i=1}^N x_j^{(i)}\\] \\[s_j = \\sqrt{\\frac{1}{N-1}\\sum_{i=1}^N (x_j^{(i)}- \\bar{x}_j )^2}\\] es decir, centramos y normalizamos por columna. Otra opción común es restar el mínimo y dividir entre la diferencia del máximo y el mínimo, de modo que las variables resultantes toman valores en \\([0,1]\\). Entonces escalamos antes de ajustar: x1_s = (x1 - mean(x1))/sd(x1) x2_s = (x2 - mean(x2))/sd(x2) dat &lt;- data_frame(x1_s, x2_s, y) rss &lt;- function(beta) mean((as.matrix(dat[, 1:2]) %*% beta - y)^2) grid_beta &lt;- expand.grid(beta1 = seq(-10, 10, 0.5), beta2 = seq(-10, 10, 0.5)) rss_1 &lt;- apply(grid_beta, 1, rss) dat_x &lt;- data.frame(grid_beta, rss_1) ggplot(dat_x, aes(x = beta1, y = beta2, z = rss_1)) + geom_contour() Nótese que los coeficientes ajustados serán diferentes a los del caso no normalizado. Cuando normalizamos antes de ajustar el modelo, las predicciones deben hacerse con entradas normalizadas. La normalización se hace con los mismos valores que se usaron en el entrenamiento (y no recalculando medias y desviaciones estándar con el conjunto de prueba). En cuanto a la forma funcional del predictor \\(f\\), el problema con entradas normalizadas es equivalente al de las entradas no normalizadas. Asegúrate de esto escribiendo cómo correponden los coeficientes de cada modelo normalizado con los coeficientes del modelo no normalizado. 2.6 Interpretación de modelos lineales Muchas veces se considera que la facilidad de interpretación es una fortaleza del modelo lineal. Esto es en parte cierto, pero hay algunas consideraciones importantes que debemos tomar en cuenta. La interpretación más sólida es la de las predicciones: podemos decir por qué una predicción es alta o baja. Consideremos el ejemplo de cáncer de prostata, por ejemplo: library(tidyr) prostate_completo &lt;- read_csv(file = &#39;datos/prostate.csv&#39;) pr_entrena &lt;- filter(prostate_completo, train) pr_entrena &lt;- pr_entrena %&gt;% mutate(id = 1:nrow(pr_entrena)) #normalizamos pr_entrena_s &lt;- pr_entrena %&gt;% select(id, lcavol, age, lpsa) %&gt;% gather(variable, valor, lcavol:age) %&gt;% group_by(variable) %&gt;% mutate(media = mean(valor), desv = sd(valor)) %&gt;% mutate(valor_s = (valor - media)/desv) pr_modelo &lt;- pr_entrena_s %&gt;% select(id, lpsa, variable, valor_s) %&gt;% spread(variable, valor_s) mod_pr &lt;- lm( lpsa ~ lcavol + age , data = pr_modelo ) round(coefficients(mod_pr), 2) ## (Intercept) lcavol age ## 2.45 0.88 0.02 y observamos el rango de \\(lpsa\\): round(summary(pr_modelo$lpsa), 2) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## -0.43 1.67 2.57 2.45 3.37 5.48 Ahora podemos interpretar el predictor: Cuando las variables lcavol y age están en sus media, la predicción de lpsa es 2.5 Si lcavol sube 1 desviación estándar por encima de la media, el predictor de lpsa sube alrededor de 0.9 unidades (de un rango de alrededor de 6 unidades) Si age sube 1 desviación estándar por encima de su media, el predictor de lpsa sube 0.02, lo cual es un movimiento muy chico considerando la variación de lpsa. Así podemos explicar cada predicción - considerando qué variables aportan positiva y cuáles negativamente a la predicción. El camino más seguro es limitarse a hacer este tipo de análisis de las predicciones. Hablamos de entender la estructura predictiva del problema con los datos que tenemos - y no intentamos ir hacia la explicación del fenómeno. Cualquier otra interpretación requiere mucho más cuidados, y requiere una revisión de la especificación correcta del modelo. Parte de estos cuidados se estudian en un curso de regresión desde el punto de vista estadístico, por ejemplo: Variación muestral. Es necesario considerar la variación en nuestras estimaciones de los coeficientes para poder concluir acerca de su relación con el fenómeno (tratable desde punto de vista estadístico, pero hay que checar supuestos). Quizá el error de estimación del coeficiente de lcavol es 2 veces su magnitud - difícilmente podemos concluir algo acerca la relación de lcavol. Efectos no lineales: si la estructura del problema es altamente no lineal, los coeficientes de un modelo lineal no tienen una interpretación clara en relación al fenómeno. Esto también es parcialmente tratable con diagnósticos. set.seed(2112) x &lt;- rnorm(20) y &lt;- x^2 summary(lm(y ~x)) ## ## Call: ## lm(formula = y ~ x) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.7462 -0.5022 -0.3313 0.3435 1.6273 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.85344 0.17570 4.857 0.000127 *** ## x 0.04117 0.18890 0.218 0.829929 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.7484 on 18 degrees of freedom ## Multiple R-squared: 0.002632, Adjusted R-squared: -0.05278 ## F-statistic: 0.0475 on 1 and 18 DF, p-value: 0.8299 Otros cuidados adicionales se requieren si queremos hacer afirmaciones causales: Variables omitidas: si faltan algunas variables cruciales en el fenómeno que nos interesa, puede ser muy difícil interpretar el resto de los coeficientes en términos del fenómeno Ejemplo: Supongamos que queremos predecir cuánto van a gastar en televisiones samsung ciertas personas que llegan a Amazon. Una variable de entrada es el número de anuncios de televisiones Samsung que recibieron antes de llegar a Amazon. El coeficiente de esta variable es alto (significativo, etc.), así que concluimos que el anuncio causa compras de televisiones Samsung. ¿Qué está mal aquí? El modelo no está mal, sino la interpretación. Cuando las personas están investigando acerca de televisiones, recibe anuncios. La razón es que esta variable nos puede indicar más bien quién está en proceso de compra de una televisión samsung (reciben anuncios) y quién no (no hacen búsquedas relevantes, así que no reciben anuncios). El modelo está mal especificado porque no consideramos que hay otra variable importante, que es el interés de la persona en compra de TVs Samsung. En general, la recomendación es que las interpretaciones causales deben considerarse como preliminares (o sugerencias), y se requiere más análisis y consideraciones antes de poder tener interpretaciones causales sólidas. Ejercicio En el siguiente ejercicio intentamos predecir el porcentaje de grasa corporal (una medición relativamente cara) usando mediciones de varias partes del cuerpo, edad, peso y estatura. Ver script bodyfat_ejercicio.R library(tidyr) dat_grasa &lt;- read_csv(file = &#39;datos/bodyfat.csv&#39;) head(dat_grasa) ## # A tibble: 6 x 14 ## grasacorp edad peso estatura cuello pecho abdomen cadera muslo rodilla ## &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 12.3 23 154. 67.8 36.2 93.1 85.2 94.5 59 37.3 ## 2 6.1 22 173. 72.2 38.5 93.6 83 98.7 58.7 37.3 ## 3 25.3 22 154 66.2 34 95.8 87.9 99.2 59.6 38.9 ## 4 10.4 26 185. 72.2 37.4 102. 86.4 101. 60.1 37.3 ## 5 28.7 24 184. 71.2 34.4 97.3 100 102. 63.2 42.2 ## 6 20.9 24 210. 74.8 39 104. 94.4 108. 66 42 ## # ... with 4 more variables: tobillo &lt;dbl&gt;, biceps &lt;dbl&gt;, antebrazo &lt;dbl&gt;, ## # muñeca &lt;dbl&gt; nrow(dat_grasa) ## [1] 252 2.7 ¿Por qué el modelo lineal funciona bien (muchas veces)? Regresión lineal es un método muy simple, y parecería que debería haber métodos más avanzados que lo superen fácilmente. Para empezar, es poco creíble que el modelo \\[f(X) = b_0 + b_1X_1 + \\cdots b_p X_p\\] se cumple exactamente para el fenómeno que estamos tratando. Pero regresión lineal muchas veces supera a métodos que intentan construir predictores más complejos. Una de las primeras razones es que podemos ver la aproximación lineal como una aproximación de primer orden a la verdadera \\(f(X)\\), y muchas veces eso es suficiente para producir predicciones razonables. Adicionalmente, otras veces sólo tenemos suficientes datos para hacer una aproximación de primer orden, aún cuando la verdadera \\(f(X)\\) no sea lineal, y resulta que esta aproximación da buenos resultados. Esto es particularmente cierto en problemas de dimensión alta, como veremos a continuación. 2.7.1 k vecinos más cercanos Un método popular, con buen desempeño en varios ejemplos, es el de k-vecinos más cercanos, que consiste en hacer aproximaciones locales directas de \\(f(X)\\). Sea \\({\\mathcal L}\\) un conjunto de entrenamiento. Para \\(k\\) entera fija, y \\(x_0\\) una entrada donde queremos predecir, definimos a \\(N_k(x_0)\\) como el conjunto de los \\(k\\) elementos de \\({\\mathcal L}\\) que tienen \\(x^{(i)}\\) más cercana a \\(x_0\\). Hacemos la predicción \\[\\hat{f}(x_0) = \\frac{1}{k}\\sum_{x^{(i)} \\in N_k(x_0)} y^{(i)}\\] Es decir, promediamos las \\(k\\) \\(y\\)’s con \\(x\\)’s más cercanas a donde queremos predecir. Ejemplo library(ISLR) datos &lt;- Auto[, c(&#39;name&#39;, &#39;weight&#39;,&#39;year&#39;, &#39;mpg&#39;)] datos$peso_kg &lt;- datos$weight*0.45359237 datos$rendimiento_kpl &lt;- datos$mpg*(1.609344/3.78541178) nrow(datos) ## [1] 392 Vamos a separa en muestra de entrenamiento y de prueba estos datos. Podemos hacerlo como sigue (2/3 para entrenamiento aproximadamente en este caso, así obtenemos alrededor de 100 casos para prueba): set.seed(213) datos$muestra_unif &lt;- runif(nrow(datos), 0, 1) datos_entrena &lt;- filter(datos, muestra_unif &gt; 1/3) datos_prueba &lt;- filter(datos, muestra_unif &lt;= 1/3) nrow(datos_entrena) ## [1] 274 nrow(datos_prueba) ## [1] 118 ggplot(datos_entrena, aes(x = peso_kg, y = rendimiento_kpl)) + geom_point() Consideremos un modelo de \\(k=15\\) vecinos más cercanos. La función de predicción ajustada es entonces: library(kknn) # nótese que no normalizamos entradas - esto también es importante # hacer cuando hacemos vecinos más cercanos, pues en otro caso # las variables con escalas más grandes dominan el cálculo mod_15vmc &lt;- kknn(rendimiento_kpl ~ peso_kg, train = datos_entrena, test = data_frame(peso_kg=seq(700,2200, by = 10)), k=15) dat_graf &lt;- data_frame(peso_kg = seq(700,2200, by = 10), rendimiento_kpl = predict(mod_15vmc)) ggplot(datos_entrena, aes(x = peso_kg, y = rendimiento_kpl)) + geom_point(alpha=0.6) + geom_line(data=dat_graf, col=&#39;red&#39;, size = 1.2) Y para \\(k=5\\) vecinos más cercanos: mod_5vmc &lt;- kknn(rendimiento_kpl ~ peso_kg, train = datos_entrena, test = data_frame(peso_kg=seq(700,2200, by = 10)), k = 5) dat_graf &lt;- data_frame(peso_kg = seq(700,2200, by = 10), rendimiento_kpl = predict(mod_5vmc)) ggplot(datos_entrena, aes(x = peso_kg, y = rendimiento_kpl)) + geom_point(alpha=0.6) + geom_line(data=dat_graf, col=&#39;red&#39;, size = 1.2) En nuestro caso, los errores de prueba son mod_3vmc &lt;- kknn(rendimiento_kpl ~ peso_kg, train = datos_entrena, test = datos_prueba, k = 3) mod_15vmc &lt;- kknn(rendimiento_kpl ~ peso_kg, train = datos_entrena, test = datos_prueba, k = 15) (mean((datos_prueba$rendimiento_kpl-predict(mod_3vmc))^2)) ## [1] 3.346934 (mean((datos_prueba$rendimiento_kpl-predict(mod_15vmc))^2)) ## [1] 2.697658 Pregunta: ¿Cómo escogerías una \\(k\\) adecuada para este problema? Recuerda que adecuada significa que se reduzca a mínimo posible el error de predicción. Como ejercicio, compara los modelos con \\(k = 2, 25, 200\\) utilizando una muestra de prueba. ¿Cuál se desempeña mejor? Da las razones de el mejor o peor desempeño: recuerda que el desempeño en predicción puede sufrir porque la función estimada no es suficiente flexible para capturar patrones importantes, pero también porque parte del ruido se incorpora en la predicción. Por los ejemplos anteriores, vemos que k-vecinos más cercanos puede considerarse como un aproximador universal, que puede adaptarse a cualquier patrón importante que haya en los datos. Entonces, ¿cuál es la razón de utilizar otros métodos como regresión? ¿Por qué el desempeño de regresión sería superior? La maldición de la dimensionalidad El método de k-vecinos más cercanos funciona mejor cuando hay muchas \\(x\\) cercanas a \\(x0\\), de forma que el promedio sea estable (muchas \\(x\\)), y extrapolemos poco (\\(x\\) cercanas). Cuando \\(k\\) es muy chica, nuestras estimaciones son ruidosas, y cuando \\(k\\) es grande y los vecinos están lejos, entonces estamos sesgando la estimación local con datos lejanos a nuestra región de interés. El problema es que en dimensión alta, casi cualquier conjunto de entrenamiento (independientemente del tamaño) sufre fuertemente por uno o ambas dificultades del problema. Ejemplo Consideremos que la salida Y es determinística \\(Y = e^{-8\\sum_{j=1}^p x_j^2}\\). Vamos a usar 1-vecino más cercano para hacer predicciones, c on una muestra de entrenamiento de 1000 casos. Generamos \\(x^{i}\\)‘s uniformes en \\([ 1,1]\\), para \\(p = 2\\), y calculamos la respuesta \\(Y\\) para cada caso: fun_exp &lt;- function(x) exp(-8*sum(x^2)) x_1 &lt;- runif(1000, -1, 1) x_2 &lt;- runif(1000, -1, 1) dat &lt;- data_frame(x_1 = x_1, x_2 = x_2) dat$y &lt;- apply(dat, 1, fun_exp) ggplot(dat, aes(x = x_1, y = x_2, colour = y)) + geom_point() La mejor predicción en \\(x_0 = (0,0)\\) es \\(f((0,0)) = 1\\). Eñ vecino más cercano al origen es dist_origen &lt;- apply(dat, 1, function(x) sqrt(sum(head(x, -1)^2))) mas_cercano_indice &lt;- which.min(dist_origen) mas_cercano &lt;- dat[mas_cercano_indice, ] mas_cercano ## # A tibble: 1 x 3 ## x_1 x_2 y ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.0327 0.0101 0.991 Nuestra predicción es entonces \\(\\hat{f}(0)=\\) 0.9906871, que es bastante cercano al valor verdadero (1). Ahora intentamos hacer lo mismo para dimensión \\(p=8\\). dat_lista &lt;- lapply(1:8, function(i) runif(1000, -1, 1)) dat &lt;- Reduce(cbind, dat_lista) %&gt;% data.frame dat$y &lt;- apply(dat, 1, fun_exp) dist_origen &lt;- apply(dat, 1, function(x) sqrt(sum(head(x, -1)^2))) mas_cercano_indice &lt;- which.min(dist_origen) mas_cercano &lt;- dat[mas_cercano_indice, ] mas_cercano ## init V2 V3 V4 V5 V6 ## 239 0.1612183 0.4117209 0.2546389 -0.226929 0.0774977 0.03897632 ## V7 V8 y ## 239 -0.4959736 0.0382697 0.01073141 Y el resultado es un desastre. Nuestra predicción es mas_cercano$y ## [1] 0.01073141 Necesitariamos una muestra de alrededor de un millón de casos para obtener resultados no tan malos (pruébalo). ¿Qué es lo que está pasando? La razón es que en dimensiones altas, los puntos de la muestra de entrenamiento están muy lejos unos de otros, y están cerca de la frontera, incluso para tamaños de muestra relativamente grandes como n = 1000. Cuando la dimensión crece, la situación empeora exponencialmente. En dimensiones altas, todos los conjuntos de entrenamiento factibles se distribuyen de manera rala en el espacio de entradas. Ahora intentamos algo similar con una función que es razonable aproximar con una función lineal: fun_cubica &lt;- function(x) 0.5 * (1 + x[1])^3 set.seed(821) sims_1 &lt;- lapply(1:40, function(i) runif(1000, -0.5, 0.5) ) dat &lt;- data.frame(Reduce(cbind, sims_1)) dat$y &lt;- apply(dat, 1, fun_cubica) dist_origen &lt;- apply(dat[, 1:40], 1, function(x) sqrt(sum(x^2))) mas_cercano_indice &lt;- which.min(dist_origen) dat$y[mas_cercano_indice] ## [1] 0.09842398 Este no es un resultado muy bueno. Sin embargo, mod_lineal &lt;- lm(y ~ ., data = dat) origen &lt;- data.frame(matrix(rep(0,40), 1, 40)) names(origen) &lt;- names(dat)[1:40] predict(mod_lineal, newdata = origen) ## 1 ## 0.6251876 Donde podemos ver que típicamente la predicción de regresión es mucho mejor que la de 1 vecino más cercano. Esto es porque el modelo explota la estructura aproximadamente lineal del problema. Nota: corre este ejemplo varias veces con semilla diferente. Lo que sucede más específicamente es que en regresión lineal utilizamos todos los datos para hacer nuestra estimación en cada predicción. Si la estructura del problema es aproximadamente lineal, entonces regresión lineal explota la estructura para hacer pooling de toda la infromación para construir predicción con sesgo y varianza bajas. Ejercicio Para este ejemplo usaremos los datos de https://archive.ics.uci.edu/ml/machine-learning-databases/housing/. El objetivo es predecir el valor mediano de las viviendas en áreas del censo de Estados Unidos, utilizando variables relacionadas con criminalidad, ambiente, tipo de viviendas, etc. Separa la muestra en dos partes: unos 400 para entrenamiento y el resto para prueba. Describe las variables en la muestra de prueba (rango, media, mediana, por ejemplo). Construye un modelo lineal para predecir MEDV en términos de las otras variables. Utiliza descenso en gradiente para estimar los coeficientes con los predictores estandarizados. Verifica tus resultados con la función lm. Evalúa el error de entrenamiento \\(\\overline{err}\\) de tu modelo, y evalúa después la estimación del error de predicción \\(\\hat{Err}\\) con la muestra de prueba. Utiliza la raíz del la media de los errores al cuadrado. (Adicional) Construye un modelo de 1,5,20 y 50 vecinos más cercanos, y evalúa su desempeño. ¿Cuál es la mejor \\(k\\) para reducir el error de prueba? "],
["regresion-logistica.html", "Sección 3 Regresión logística 3.1 El problema de clasificación 3.2 Estimación de probabilidades de clase 3.3 Error para modelos de clasificación 3.4 Regresión logística 3.5 Aprendizaje de coeficientes para regresión logística (binomial). 3.6 Observaciones adicionales Ejercicio: datos de diabetes 3.7 Más sobre problemas de clasificación", " Sección 3 Regresión logística 3.1 El problema de clasificación Una variabla \\(G\\) categórica o cualitativa toma valores que no son numéricos. Por ejemplo, si \\(G\\) denota el estado del contrato de celular de un cliente dentro de un año, podríamos tener \\(G\\in \\{ activo, cancelado\\}\\). En un problema de clasificación buscamos predecir una variable respuesta categórica \\(G\\) en función de otras variables de entrada \\(X=(X_1,X_2,\\ldots, X_p)\\). Ejemplos Predecir si un cliente cae en impago de una tarjeta de crédito, de forma que podemos tener \\(G=corriente\\) o \\(G=impago\\). Variables de entrada podrían ser \\(X_1=\\) porcentaje de saldo usado, \\(X_2=\\) atrasos en los úlltimos 3 meses, \\(X_3=\\) edad, etc En nuestro ejemplo de reconocimiento de dígitos tenemos \\(G\\in\\{ 0,1,\\ldots, 9\\}\\). Nótese que los` dígitos no se pueden considerar como valores numéricos (son etiquetas). Tenemos que las entradas \\(X_j\\) para \\(j=1,2,\\ldots, 256\\) son valores de cada pixel (imágenes blanco y negro). En reconocimiento de imágenes quiza tenemos que \\(G\\) pertenece a un conjunto que típicamente contiene miles de valores (manzana, árbol, pluma, perro, coche, persona, cara, etc.). Las \\(X_j\\) son valores de pixeles de la imagen para tres canales (rojo, verde y azul). Si las imágenes son de 100x100, tendríamos 30,000 variables de entrada. ¿Qué estimar en problemas de clasificación? En problemas de regresión, consideramos modelos de la forma \\(Y= f(X) + \\epsilon\\), y vimos que podíamos plantear el problema de aprendizaje supervisado como uno donde el objetivo es estimar lo mejor que podamos la función \\(f\\) mediante un estimador \\(\\hat{f}\\). Usamos entonces \\(\\hat{f}\\) para hacer predicciónes. En el caso de regresión: \\(f(X)\\) es la relación sistemática de \\(Y\\) en función de \\(X\\) Dada \\(X\\), la variable observada \\(Y\\) es una variable aleatoria (\\(\\epsilon\\) depende de otras variables que no conocemos) No podemos usar un modelo así en clasificación pues \\(G\\) no es numérica. Sin embargo, podemos pensar que \\(X\\) nos da cierta información probabilística acerca de las clases que pueden ocurrir: \\(P(G|X)\\) es la probabilidad condicional de observar \\(G\\) si tenemos \\(X\\). Esto es la información sistemática de \\(G\\) en función de \\(X\\) Dada \\(X\\), la clase observada \\(G\\) es una variable aleatoria (depende de otras variables que no conocemos). En analogía con el problema de regresión, quisiéramos estimar las probabilidades condicionales \\(P(G|X)\\), que es la parte sistemática de la relación de \\(G\\) en función de \\(X\\). Normalmente codificamos las clases \\(g\\) con una etiqueta numérica, de modo que \\(G\\in\\{1,2,\\ldots, K\\}\\): Ejemplo (Impago de tarjetas de crédito) Supongamos que \\(X=\\) porcentaje del crédito máximo usado, y \\(G\\in\\{1, 2\\}\\), donde \\(1\\) corresponde al corriente y \\(2\\) representa impago. Podríamos tener, por ejemplo: \\[\\begin{align*} p_1(10\\%) &amp;= P(G=1|X=10\\%) = 0.95 \\\\ p_2(10\\%) &amp;= P(G=2|X=10\\%) = 0.05 \\end{align*}\\] y \\[\\begin{align*} p_1(95\\%) &amp;= P(G=1|X=95\\%) = 0.70 \\\\ p_2(95\\%) &amp;= P(G=2|X=95\\%) = 0.30 \\end{align*}\\] En resumen: En problemas de clasificación queremos estimar la parte sistemática de la relación de \\(G\\) en función \\(X\\), que en este caso quiere decir que buscamos estimar las probabilidades condicionales: \\[\\begin{align*} p_1(x) &amp;= P(G=1|X=x), \\\\ p_2(x) &amp;= P(G=2|X=x), \\\\ \\vdots &amp; \\\\ p_K(x) &amp;= P(G=K|X=x) \\end{align*}\\] para cada valor \\(x\\) de las entradas. A partir de estas probabilidades de clase podemos producir un clasificador de varias maneras (las discutiremos más adelante). La forma más simple es usando el clasificador de Bayes: Dadas las probabilidades condicionales \\(p_1(x),p_2(x),\\ldots, p_K(x)\\), el clasificador de Bayes asociado está dado por \\[G (x) = \\arg\\max_{g} p_g(x)\\] Es decir, clasificamos en la clase que tiene máxima probabilidad de ocurrir. Ejemplo (Impago de tarjetas de crédito) Supongamos que \\(X=\\) porcentaje del crédito máximo usado, y \\(G\\in\\{1, 2\\}\\), donde \\(1\\) corresponde al corriente y \\(2\\) representa impago. Las probabilidades condicionales de clase para la clase al corriente podrían ser, por ejemplo: \\(p_1(x) = P(G=1|X = x) =0.95\\) si \\(x &lt; 15\\%\\) \\(p_1(x) = P(G=1|X = x) = 0.95 - 0.007(x-15)\\) si \\(x&gt;=15\\%\\) Estas son probabilidades, pues hay otras variables que influyen en que un cliente permanezca al corriente o no en sus pagos más allá de información contenida en el porcentaje de crédito usado. Nótese que estas probabilidades son diferentes a las no condicionadas, por ejempo, podríamos tener que a total \\(P(G=1)=0.83\\). p_1 &lt;- function(x){ ifelse(x &lt; 15, 0.95, 0.95 - 0.007 * (x - 15)) } curve(p_1, 0,100, xlab = &#39;Porcentaje de crédito máximo&#39;, ylab = &#39;p_1(x)&#39;, ylim = c(0,1)) ¿Por qué en este ejemplo ya no mostramos la función \\(p_2(x)\\)? Si usamos el clasificador de Bayes, tendríamos por ejemplo que si \\(X=10\\%\\), como \\(p_1(10\\%) = 0.95\\) y \\(p_2(10\\%)=0.05\\), nuestra predicción de clase sería \\(G(10\\%) = 1\\) (al corriente), pero si \\(X=70\\%\\), \\(G(70\\%) = 1\\) (impago), pues \\(p_1(70\\%) = 0.57\\) y \\(p_2(70\\%) = 0.43\\). 3.2 Estimación de probabilidades de clase ¿Cómo estimamos ahora las probabilidades de clase a partir de una muestra de entrenamiento? Veremos por ahora dos métodos: k-vecinos más cercanos y regresión logística. Ejemplo Vamos a generar unos datos con el modelo simple del ejemplo anterior: library(dplyr) library(tidyr) library(kknn) set.seed(1933) x &lt;- pmin(rexp(500,1/30),100) probs &lt;- p_1(x) g &lt;- ifelse(rbinom(length(x), 1, probs)==1 ,1, 2) dat_ent &lt;- data_frame(x = x, p_1 = probs, g = factor(g)) dat_ent %&gt;% select(x, g) ## # A tibble: 500 x 2 ## x g ## &lt;dbl&gt; &lt;fct&gt; ## 1 0.532 1 ## 2 25.4 1 ## 3 37.5 1 ## 4 20.9 1 ## 5 70.9 2 ## 6 14.8 1 ## 7 49.4 1 ## 8 20.9 1 ## 9 35.5 1 ## 10 9.83 1 ## # ... with 490 more rows Como este problema es de dos clases, podemos graficar como sigue: graf_1 &lt;- ggplot(dat_ent, aes(x = x)) + geom_jitter(aes(colour = g, y = as.numeric(g==&#39;1&#39;)), width=0, height=0.1) graf_1 3.2.1 k-vecinos más cercanos Podemos extender fácilmente k vecinos más cercanos para ver un ejemplo de cómo estimar las probabilidades de clase \\(p_g(x)\\). La idea general es igual que en regresión: Supongamos que tenemos un conjunto de entrenamiento \\[{\\mathcal L}=\\{ (x^{(1)},g^{(1)}),(x^{(2)},g^{(2)}), \\ldots, (x^{(N)}, g^{(N)}) \\}\\] La idea es que si queremos predecir en \\(x_0\\), busquemos varios \\(k\\) vecinos más cercanos a \\(x_0\\), y estimamos entonces \\(p_g(x)\\) como la proporción de casos tipo \\(g\\) que hay entre los \\(k\\) vecinos de \\(x_0\\). Vemos entonces que este método es un intento de hacer una aproximación directa de las probabilidades condicionales de clase. Podemos escribir esto como: Estimamos contando los elementos de cada clase entre los \\(k\\) vecinos más cercanos: \\[\\hat{p}_g (x_0) = \\frac{1}{k}\\sum_{x^{(i)} \\in N_k(x_0)} I( g^{(i)} = g),\\] para \\(g=1,2,\\ldots, K\\), donde \\(N_k(x_0)\\) es el conjunto de \\(k\\) vecinos más cercanos en \\({\\mathcal L}\\) de \\(x_0\\), y \\(I(g^{(i)}=g)=1\\) cuando \\(g^{(i)}=g\\), y cero en otro caso. Ejemplo Regresamos a nuestro problema de impago. Vamos a intentar estimar la probabilidad condicional de estar al corriente usando k vecinos más cercanos (curva roja): graf_data &lt;- data_frame(x = seq(0,100, 1)) vmc &lt;- kknn(g ~ x, train = dat_ent, k = 60, test = graf_data, kernel = &#39;rectangular&#39;) graf_data$p_1 &lt;- vmc$prob[ ,1] graf_verdadero &lt;- data_frame(x = 0:100, p_1 = p_1(x)) graf_1 + geom_line(data = graf_data, aes(y = p_1), colour = &#39;red&#39;, size=1.2) + geom_line(data = graf_verdadero, aes(y = p_1)) + ylab(&#39;Probabilidad al corriente&#39;) + xlab(&#39;% crédito usado&#39;) Igual que en el caso de regresión, ahora tenemos qué pensar cómo validar nuestra estimación, pues no vamos a tener la curva negra real para comparar. Ejemplo Consideremos datos de diabetes en mujeres Pima: A population of women who were at least 21 years old, of Pima Indian heritage and living near Phoenix, Arizona, was tested for diabetes according to World Health Organization criteria. The data were collected by the US National Institute of Diabetes and Digestive and Kidney Diseases. We used the 532 complete records after dropping the (mainly missing) data on serum insulin. npreg number of pregnancies. glu plasma glucose concentration in an oral glucose tolerance test. bp diastolic blood pressure (mm Hg). skin triceps skin fold thickness (mm). bmi body mass index (weight in kg/(height in m)^2). ped diabetes pedigree function. age age in years. type Yes or No, for diabetic according to WHO criteria. diabetes_ent &lt;- as_data_frame(MASS::Pima.tr) diabetes_pr &lt;- as_data_frame(MASS::Pima.te) diabetes_ent ## # A tibble: 200 x 8 ## npreg glu bp skin bmi ped age type ## * &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;fct&gt; ## 1 5 86 68 28 30.2 0.364 24 No ## 2 7 195 70 33 25.1 0.163 55 Yes ## 3 5 77 82 41 35.8 0.156 35 No ## 4 0 165 76 43 47.9 0.259 26 No ## 5 0 107 60 25 26.4 0.133 23 No ## 6 5 97 76 27 35.6 0.378 52 Yes ## 7 3 83 58 31 34.3 0.336 25 No ## 8 1 193 50 16 25.9 0.655 24 No ## 9 3 142 80 15 32.4 0.2 63 No ## 10 2 128 78 37 43.3 1.22 31 Yes ## # ... with 190 more rows Intentaremos predecir diabetes dependiendo del BMI: library(ggplot2) ggplot(diabetes_ent, aes(x = bmi, y= as.numeric(type==&#39;Yes&#39;), colour = type)) + geom_point() Usamos \\(20\\) vecinos más cercanos para estimar \\(p_g(x)\\): graf_data &lt;- data_frame(bmi = seq(20,45, 1)) vmc_5 &lt;- kknn(type ~ bmi, train = diabetes_ent, k = 20, test = graf_data, kernel = &#39;rectangular&#39;) graf_data$Yes &lt;- vmc_5$prob[ ,&quot;Yes&quot;] graf_data$No &lt;- vmc_5$prob[ ,&quot;No&quot;] graf_data &lt;- graf_data %&gt;% gather(type, prob, Yes:No) ggplot(diabetes_ent, aes(x = bmi, y= as.numeric(type==&#39;Yes&#39;), colour = type)) + geom_point() + geom_line(data = filter(graf_data, type ==&#39;Yes&#39;) , aes(x=bmi, y = prob, colour=type, group = type)) + ylab(&#39;Probabilidad diabetes&#39;) 3.3 Error para modelos de clasificación En regresión, vimos que la pérdida cuadrática era una buena opción para ajustar modelos (descenso en gradiente, por ejemplo), y también para evaluar su desempeño. Ahora necesitamos una pérdida apropiada para trabajar con modelos de clasificación. Consideremos entonces que tenemos una estimación \\(\\hat{p}_g(x)\\) de las probabilidad de clase \\(P(G=g|X=x)\\). Supongamos que observamos ahora \\((x, g)\\). Si \\(\\hat{p}_{g}(x)\\) es muy cercana a uno, deberíamos penalizar poco, pues dimos probabilidad alta a \\(G=g\\). Si \\(\\hat{p}_{g}(x)\\) es chica, deberíamos penalizar más, pues dimos probabilidad baja a \\(G=g\\). Si \\(\\hat{p}_{g}(x)\\) es muy cercana a cero, y observamos \\(G=g\\), deberíamos hacer una penalización muy alta (convergiendo a \\(\\infty\\), pues no es aceptable que sucedan eventos con probabilidad estimada extremadamente baja). Quisiéramos encontrar una función \\(h\\) apropiada, de forma que la pérdida al observar \\((x, g)\\) sea \\[s(\\hat{p}_{g}(x)),\\] y que cumpla con los puntos arriba señalados. Entonces tenemos que \\(s\\) debe ser una función continua y decreciente en \\([0,1]\\) Podemos poner \\(s(1)=0\\) (no hay pérdida si ocurre algo con probabilidad 1) \\(s(p)\\) debe ser muy grande is \\(p\\) es muy chica. Una opción analíticamente conveniente es \\[s(z) = - 2log(z)\\] s &lt;- function(z){ -2*log(z)} curve(s, 0, 1) Y entonces la pérdida (que llamamos devianza) que construimos está dada, para \\((x,g)\\) observado y probabilidades estimadas \\(\\hat{p}_g(x)\\) por \\[ - 2\\log(\\hat{p}_g(x)) \\] Su valor esperado (según el proceso que genera los datos) es nuestra medición del desempeño del modelo \\(\\hat{p}_g (x)\\): \\[-2E\\left [ \\log(\\hat{p}_G(X)) \\right ]\\] Observaciones: Ojo: el nombre de devianza se utiliza de manera diferente en distintos lugares (pero para cosas similares). Usamos el factor 2 por razones históricas (la medida de devianza definida en estadística tiene un 2, para usar más fácilmente en pruebas de hipótesis relacionadas con comparaciones de modelos). Para nuestros propósitos, podemos usar o no el 2. No es fácil interpretar la devianza, pero es útil para comparar modelos. Veremos otras medidas más fáciles de intrepretar más adelante. Compara la siguiente definición con la que vimos para modelos de regresión: Sea \\[{\\mathcal L}=\\{ (x^{(1)},g^{(1)}),(x^{(2)},g^{(2)}), \\ldots, (x^{(N)}, g^{(N)}) \\}\\] una muestra de entrenamiento, a partir de las cuales construimos mediante un algoritmo funciones estimadas \\(\\hat{p}_{g} (x)\\) para \\(g=1,2,\\ldots, K\\). La devianza promedio de entrenamiento está dada por \\[\\begin{equation} \\overline{err} = - \\frac{2}{N}\\sum_{i=1}^N log(\\hat{p}_{g^{(i)}} (x^{(i)})) \\tag{3.1} \\end {equation}\\] Sea \\[{\\mathcal T}=\\{ (x_0^{(1)},g_0^{(1)}),(x_0^{(2)},g_0^{(2)}), \\ldots, (x_0^{(m)}, g_0^{(m)}) \\}\\] una muestra de prueba. La devianza promedio de prueba es \\[\\begin{equation} \\hat{Err} = - \\frac{2}{m}\\sum_{i=1}^m log(\\hat{p}_{g_0^{(i)}} (x_0^{(i)})) \\end {equation}\\] que es una estimación de la devianza de predicción \\[-2E\\left [ \\log(\\hat{p}_G(X)) \\right ]\\] Ejemplo Regresamos a nuestros ejemplo de impago de tarjetas de crédito. Primero calculamos la devianza de entrenamiento s &lt;- function(x) -2*log(x) vmc &lt;- kknn(g ~ x, train = dat_ent, k = 60, test = dat_ent, kernel = &#39;rectangular&#39;) dat_dev &lt;- dat_ent %&gt;% select(x,g) dat_dev$hat_p_1 &lt;- predict(vmc, type =&#39;prob&#39;)[,1] dat_dev$hat_p_2 &lt;- predict(vmc, type =&#39;prob&#39;)[,2] dat_dev &lt;- dat_dev %&gt;% mutate(hat_p_g = ifelse(g==1, hat_p_1, hat_p_2)) Nótese que dependiendo de qué clase observamos (columna \\(g\\)), extraemos la probabilidad correspondiente a la columna hat_p_g: head(dat_dev, 50) ## # A tibble: 50 x 5 ## x g hat_p_1 hat_p_2 hat_p_g ## &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.532 1 0.967 0.0333 0.967 ## 2 25.4 1 0.883 0.117 0.883 ## 3 37.5 1 0.85 0.15 0.85 ## 4 20.9 1 0.9 0.1 0.9 ## 5 70.9 2 0.6 0.4 0.4 ## 6 14.8 1 0.933 0.0667 0.933 ## 7 49.4 1 0.8 0.2 0.8 ## 8 20.9 1 0.9 0.1 0.9 ## 9 35.5 1 0.75 0.25 0.75 ## 10 9.83 1 0.933 0.0667 0.933 ## # ... with 40 more rows Ahora aplicamos la función \\(s\\) que describimos arriba, y promediamos sobre el conjunto de entrenamiento: dat_dev &lt;- dat_dev %&gt;% mutate(dev = s(hat_p_g)) dat_dev %&gt;% ungroup %&gt;% summarise(dev_entrena = mean(dev)) ## # A tibble: 1 x 1 ## dev_entrena ## &lt;dbl&gt; ## 1 0.700 Recordemos que la devianza de entrenamiento no es la cantidad que evalúa el desempeño del modelo. Hagamos el cálculo entonces para una muestra de prueba: set.seed(1213) x &lt;- pmin(rexp(1000,1/30),100) probs &lt;- p_1(x) g &lt;- ifelse(rbinom(length(x), 1, probs)==1 ,1, 2) dat_prueba &lt;- data_frame(x = x, g = factor(g)) vmc &lt;- kknn(g ~ x, train = dat_ent, k = 60, test = dat_prueba, kernel = &#39;rectangular&#39;) dat_dev &lt;- dat_prueba %&gt;% select(x,g) dat_dev$hat_p_1 &lt;- predict(vmc, type =&#39;prob&#39;)[,1] dat_dev$hat_p_2 &lt;- predict(vmc, type =&#39;prob&#39;)[,2] dat_dev &lt;- dat_dev %&gt;% mutate(hat_p_g = ifelse(g==1, hat_p_1, hat_p_2)) dat_dev &lt;- dat_dev %&gt;% mutate(dev = s(hat_p_g)) dat_dev %&gt;% ungroup %&gt;% summarise(dev_prueba = mean(dev)) ## # A tibble: 1 x 1 ## dev_prueba ## &lt;dbl&gt; ## 1 0.711 3.3.1 Ejercicio Utiliza 5, 20, 60, 200 y 400 vecinos más cercanos para nuestro ejemplo de tarjetas de crédito. ¿Cuál tiene menor devianza de prueba? ¿Cuál tiene menor devianza de entrenamiento? Grafica el mejor que obtengas y otros dos modelos malos. ¿Por qué crees que la devianza es muy grande para los modelos malos? Nota: ten cuidado con probabilidades iguales a 0 o 1, pues en en estos casos la devianza puede dar \\(\\infty\\). Puedes por ejemplo hacer que las probabilidades siempre estén en \\([\\epsilon, 1-\\epsilon]\\) para \\(\\epsilon&gt;0\\) chica. Empieza con el código en clase_3_ejercicio.R. 3.3.2 Error de clasificación y función de pérdida 0-1 Otra medida común para medir el error de un clasificador es el error de clasificación, que también llamamos probabilidad de clasificación incorrecta, o error bajo pérdida 0-1. Si \\(\\hat{G}\\) es un clasificador (que puede ser construido a partir de probabilidades de clase), decimos que su error de clasificación es \\[P(\\hat{G}\\neq G)\\] Aunque esta definición aplica para cualquier clasificador, podemos usarlo para clasificadores construidos con probabilidades de clase de la siguiente forma: Sean \\(\\hat{p}_g(x)\\) probabilidades de clase estimadas. El clasificador asociado está dado por \\[\\hat{G} (x) = \\arg\\max_g \\hat{p}_g(x)\\] Podemos estimar su error de clasificación \\(P(\\hat{G} \\neq G)\\) con una muestra de prueba \\[{\\mathcal T}=\\{ (x_0^{(1)},g_0^{(1)}),(x_0^{(2)},g_0^{(2)}), \\ldots, (x_0^{(m)}, g_0^{(m)})\\] mediante \\[\\hat{Err} = \\frac{1}{m} \\sum_{j=i}^m I(\\hat{G}(x_0^{(i)}) \\neq g_0^{(i)}),\\] es decir, la proporción de casos de prueba que son clasificados incorrectamente. Ejemplo Veamos cómo se comporta en términos de error de clasificación nuestro último modelo: dat_dev$hat_G &lt;- predict(vmc) dat_dev %&gt;% mutate(correcto = hat_G == g) %&gt;% ungroup %&gt;% summarise(p_correctos = mean(correcto)) %&gt;% mutate(error_clasif = 1 - p_correctos) ## # A tibble: 1 x 2 ## p_correctos error_clasif ## &lt;dbl&gt; &lt;dbl&gt; ## 1 0.851 0.149 vmc_2 &lt;- kknn(g ~ x, train = dat_ent, k = 3, test = dat_prueba, kernel = &#39;rectangular&#39;) dat_dev$hat_G &lt;- predict(vmc_2) dat_dev %&gt;% mutate(correcto = hat_G == g) %&gt;% ungroup %&gt;% summarise(p_correctos = mean(correcto)) %&gt;% mutate(error_clasif = 1 - p_correctos) ## # A tibble: 1 x 2 ## p_correctos error_clasif ## &lt;dbl&gt; &lt;dbl&gt; ## 1 0.82 0.18 3.3.3 Discusión: relación entre devianza y error de clasificación Cuando utilizamos devianza, el mejor desempeño se alcanza cuando las probabilidades \\(\\hat{p}_g (x)\\) están bien calibradas, es decir, están cercanas a las probabilidades verdaderas \\(p_g (x)\\). Esto se puede ver demostrando que las probabilidades \\(\\hat{p}_g (x)\\) que minimizan la devianza \\[-2E(\\log (\\hat{p}_G (X))) = -2E_X \\left[ \\sum_{k=1}^K p_g(X)\\log\\hat{p}_g(X) \\right]\\] son precisamente \\(\\hat{p}_g (x)=p_g (x)\\). Por otro lado, si consideramos el error de clasificación \\(P(\\hat{G}\\neq G)\\), es posible demostrar que se minimiza cuando \\(\\hat{G} = G_{bayes}\\), donde \\[{G}_{bayes} (x) = \\arg\\max_g {p}_g(x).\\] En consecuencia, cuando las \\(\\hat{p}_g(x)\\) estimadas están cercanas a las verdaderas \\(p_g (x)\\) (que es lo que intentamos hacer cuando usamos devianza), el clasificador \\(\\hat{G}(x)\\) producido a partir de las \\(\\hat{p}_g(x)\\) deberá estar cercano a \\(G_{bayes}(x)\\), que es el clasificador que minimiza el error de clasificación. Este argumento explica que buscar modelos con devianza baja no está alineado con buscar modelos con error de clasificación bajo. Cuando sea posible, es mejor trabajar con probabilidades de clase y devianza que solamente con clasificadores y error de clasificación. Hay varias razones para esto: Tenemos una medida de qué tan seguros estamos en la clasificación (por ejemplo, \\(p_1 = 0.55\\) en vez de \\(p_1 = 0.995\\)). La salida de probabilides es un insumo más útil para tareas posteriores (por ejemplo, si quisiéramos ofrecer las 3 clases más probables en clasificación de imágenes). Permite hacer selección de modelos de manera más atinada: por ejemplo, dada una misma tasa de correctos, preferimos aquellos modelos que lo hacen con probabilidades que discriminan más (más altas cuando está en lo correcto y más bajas cuando se equivoca). 3.4 Regresión logística En \\(k\\) vecinos más cercanos, intentamos estimar directamente con promedios las probabilidades de clase. Regresión logística (y otros métodos, como redes neuronales), son ajustados intentando minimizar la devianza de entrenamiento. Esto es necesario si queremos aprovechar la estructura adicional que estos modelos aportan (recordemos el caso de regresión lineal: intentamos minimizar el error de entrenamiento para estimar nuestro predictor, y así podíamos explotar apropiadamente la estructura lineal del problema). Regresión logística es un método lineal de clasificación, en el sentido de que produce fronteras lineales de decisión para el clasificador asociado. 3.4.1 Regresión logística simple Vamos a construir el modelo de regresión logística (binaria) para una sola entrada. Suponemos que tenemos una sola entrada \\(X_1\\), y que \\(G\\in\\{1,2\\}\\). Nos convendrá crear una nueva variable \\(Y\\) dada por \\(Y=1\\) si \\(G=2\\), \\(Y=0\\) si \\(G=1\\). Nótese que intentar estimar las probabilidades de clase \\(p_1(x)\\) de forma lineal con \\[p_1(x)=\\beta_0+\\beta_1 x_1\\] tiene el defecto de que el lado derecho puede producir valores fuera de \\([0,1]\\). La idea es entonces aplicar una función \\(h\\) simple que transforme la recta real al intervalo \\([0,1]:\\) \\[p_1(x) = h(\\beta_0+\\beta_1 x_1),\\] donde \\(h\\) es una función que toma valores en \\([0,1]\\). ¿Cúal es la función más simple que hace esto? 3.4.2 Función logística Comenzamos con el caso más simple, poniendo \\(\\beta_0=0\\) y \\(\\beta_1=1\\), de modo que \\[p_1(x)=h(x).\\] ¿Cómo debe ser \\(h\\) para garantizar que \\(h(x)\\) está entre 0 y 1 para toda \\(x\\)? No van a funcionar polinomios, por ejemplo, porque para un polinomio cuando \\(x\\) tiende a infinito, el polinomio tiende a \\(\\infty\\) o a \\(-\\infty\\). Hay varias posibilidades, pero una de las más simples es tomar (ver gráfica al margen): La función logística está dada por \\[h(x)=\\frac{e^x}{1+e^x}\\] h &lt;- function(x){exp(x)/(1+exp(x)) } curve(h, from=-6, to =6) Esta función comprime adecuadamente (para nuestros propósitos) el rango de todos los reales dentro del intervalo \\([0,1]\\). El modelo de regresión logística simple está dado por \\[p_1(x)=p_1(x;\\beta)= h(\\beta_0+\\beta_1x_1)= \\frac{e^{\\beta_0+\\beta_1x_1}}{1+ e^{\\beta_0+\\beta_1x_1}},\\] y \\[p_0(x)=p_0(x;\\beta)=1-p_1(x;\\beta),\\] donde \\(\\beta=(\\beta_0,\\beta_1)\\). Este es un modelo paramétrico con 2 parámetros. Ejercicio Demostrar que, si \\(p_1(x)\\) está dado como en la ecuación anterior, entonces también podemos escribir: \\[p_o(x)=\\frac{1}{1+e^{\\beta_0+\\beta_1x_1}}.\\] Graficar las funciones \\(p_1(x;\\beta)\\) para distintos valores de \\(\\beta_0\\) y \\(\\beta_1\\). 3.4.2.1 Ejemplo En nuestro ejemplo: graf_data &lt;- data_frame(x = seq(0,100, 1)) vmc_graf &lt;- kknn(g ~ x, train = dat_ent, k = 60, test = graf_data, kernel = &#39;rectangular&#39;) graf_data$p_1 &lt;- vmc_graf$prob[ ,1] graf_verdadero &lt;- data_frame(x = 0:100, p_1 = p_1(x)) graf_1 + geom_line(data = graf_data, aes(y = p_1), colour = &#39;red&#39;, size=1.2) + geom_line(data = graf_verdadero, aes(y = p_1)) + ylab(&#39;Probabilidad al corriente&#39;) + xlab(&#39;% crédito usado&#39;) Ahora intentaremos ajustar a mano (intenta cambiar las betas para p_mod_1 y p_mod_2 en el ejemplo de abajo) algunos modelos logísticos para las probabilidades de clase: h &lt;- function(z) exp(z)/(1+exp(z)) p_logistico &lt;- function(beta_0, beta_1){ p &lt;- function(x){ z &lt;- beta_0 + beta_1*x h(z) } } p_mod_1 &lt;- p_logistico(-20, 1) p_mod_2 &lt;- p_logistico(3, -0.04) graf_data &lt;- graf_data %&gt;% mutate(p_mod_1 = p_mod_1(x), p_mod_2 = p_mod_2(x)) graf_1 + geom_line(data = graf_data, aes(y = p_mod_2), colour = &#39;red&#39;, size=1.2) + geom_line(data = graf_data, aes(y = p_mod_1), colour = &#39;orange&#39;, size=1.2) + geom_line(data = graf_verdadero, aes(y = p_1)) + ylab(&#39;Probabilidad al corriente&#39;) + xlab(&#39;% crédito usado&#39;) Podemos usar también la función glm de R para ajustar los coeficientes: mod_1 &lt;- glm(g==1 ~ x, data = dat_ent, family = &#39;binomial&#39;) coef(mod_1) ## (Intercept) x ## 3.24467326 -0.04353428 p_mod_final &lt;- p_logistico(coef(mod_1)[1], coef(mod_1)[2]) graf_data &lt;- graf_data %&gt;% mutate(p_mod_f = p_mod_final(x)) graf_1 + geom_line(data = graf_data, aes(y = p_mod_f), colour = &#39;red&#39;, size=1.2) + geom_line(data = graf_data, aes(y = p_mod_1), colour = &#39;orange&#39;, size=1.2) + geom_line(data = graf_verdadero, aes(y = p_1)) + ylab(&#39;Probabilidad al corriente&#39;) + xlab(&#39;% crédito usado&#39;) 3.4.3 Regresión logística Ahora escribimos el modelo cuando tenemos más de una entrada. La idea es la misma: primero combinamos las variables linealmente usando pesos \\(\\beta\\), y despúes comprimimos a \\([0,1]\\) usando la función logística: El modelo de regresión logística está dado por \\[p_1(x)=p_1(x;\\beta)= h(\\beta_0+\\beta_1x_1 + \\beta_2x_2 +\\cdots + \\beta_p x_p),\\] y \\[p_0(x)=p_0(x;\\beta)=1-p_1(x;\\beta),\\] donde \\(\\beta=(\\beta_0,\\beta_1, \\ldots, \\beta_p)\\). 3.5 Aprendizaje de coeficientes para regresión logística (binomial). Ahora veremos cómo aprender los coeficientes con una muestra de entrenamiento. La idea general es : Usamos la devianza de entrenamiento como medida de ajuste Usamos descenso en gradiente para minimizar esta devianza y aprender los coeficientes. Sea entonces \\({\\mathcal L}\\) una muestra de entrenamiento: \\[{\\mathcal L}=\\{ (x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}), \\ldots, (x^{(N)}, y^{(N)}) \\}\\] Donde \\(y=1\\) o \\(y=0\\) son las dos clases. Escribimos también \\[p_1(x)=p_1(x;\\beta)= h(\\beta_0+\\beta_1x_1 + \\beta_2x_2 +\\cdots + \\beta_p x_p),\\] y definimos la devianza sobre el conjunto de entrenamiento \\[D(\\beta) = -2\\sum_{i=1}^N \\log(p_{y^{(i)}} (x^{(i)})).\\] Los coeficientes estimados por regresión logística están dados por \\[\\hat{\\beta} = \\arg\\min_\\beta D(\\beta)\\] Para minimizar utilizaremos descenso en gradiente (aunque hay más opciones). La última expresión para \\(D(\\beta)\\) puede ser difícil de operar, pero podemos reescribir como: \\[D(\\beta) = -2\\sum_{i=1}^N y^{(i)} \\log(p_{1} (x^{(i)})) + (1-y^{(i)}) \\log(p_{0} (x^{(i)})).\\] Para hacer descenso en gradiente, necesitamos encontrar \\(\\frac{\\partial D}{\\beta_j}\\) para \\(j=1,2,\\ldots,p\\). Igual que en regresión lineal, comenzamos por calcular la derivada de un término: \\[D^{(i)} (\\beta) = y^{(i)} \\log(p_{1} (x^{(i)})) + (1-y^{(i)}) \\log(1-p_{1} (x^{(i)}))\\] Calculamos primero las derivadas de \\(p_1 (x^{(i)};\\beta)\\) (demostrar la siguiente ecuación): \\[\\frac{\\partial p_1}{\\partial \\beta_0} = {p_1(x^{(i)})(1-p_1(x^{(i)}))},\\] y \\[\\frac{\\partial p_1}{\\partial \\beta_j} = p_1(x^{(i)})(1-p_1(x^{(i)}))x_j^{(i)},\\] Así que \\[\\begin{align*} \\frac{\\partial D^{(i)}}{\\partial \\beta_j} &amp;= \\frac{y^{(i)}}{(p_1(x^{(i)}))}\\frac{\\partial p_1}{\\partial \\beta_j} - \\frac{1- y^{(i)}}{(1-p_1(x^{(i)}))}\\frac{\\partial p_1}{\\partial \\beta_j} \\\\ &amp;= \\left( \\frac{y^{(i)} - p_1(x^{(i)})}{(p_1(x^{(i)}))(1-p_1(x^{(i)}))} \\right )\\frac{\\partial p_1}{\\partial \\beta_j} \\\\ &amp; = \\left ( y^{(i)} - p_1(x^{(i)}) \\right ) x_j^{(i)} \\\\ \\end{align*}\\] para \\(j=0,1,\\ldots,p\\), usando la convención de \\(x_0^{(i)}=1\\). Podemos sumar ahora sobre la muestra de entrenamiento para obtener \\[ \\frac{\\partial D}{\\partial\\beta_j} = - 2\\sum_{i=1}^N (y^{(i)}-p(x^{(i)}))x_j^{(i)}\\] De modo que, Para un paso \\(\\eta&gt;0\\) fijo, la iteración de descenso para regresión logística para el coeficiente \\(\\beta_j\\) es: \\[\\beta_{j}^{(k+1)} = \\beta_j^{(k)} + {2\\eta} \\sum_{i=1}^N (y^{(i)}-p(x^{(i)}))x_j^{(i)}\\] para \\(j=0,1,\\ldots, p\\), donde fijamos \\(x_0^{(i)}=1\\). Podríamos usar las siguientes implementaciones, que representan cambios menores de lo que hicimos en regresión lineal: devianza_calc &lt;- function(x, y){ dev_fun &lt;- function(beta){ # usando p #p_beta &lt;- h(as.matrix(cbind(1, x)) %*% beta) #-2*sum(y*log(p_beta) + (1-y)*log(1-p_beta)) # usando x*beta x_beta &lt;- as.matrix(cbind(1, x)) %*% beta -2*sum(y*x_beta - log(1 + exp(x_beta))) } dev_fun } grad_calc &lt;- function(x_ent, y_ent){ salida_grad &lt;- function(beta){ p_beta &lt;- h(as.matrix(cbind(1, x_ent)) %*% beta) e &lt;- y_ent - p_beta grad_out &lt;- -2*as.numeric(t(cbind(1,x_ent)) %*% e) names(grad_out) &lt;- c(&#39;Intercept&#39;, colnames(x_ent)) grad_out } salida_grad } descenso &lt;- function(n, z_0, eta, h_deriv){ z &lt;- matrix(0,n, length(z_0)) z[1, ] &lt;- z_0 for(i in 1:(n-1)){ z[i+1, ] &lt;- z[i, ] - eta * h_deriv(z[i, ]) } z } Ejemplo Probemos nuestros cálculos con el ejemplo de 1 entrada de tarjetas de crédito. dat_ent$y &lt;- as.numeric(dat_ent$g==1) dat_ent &lt;- dat_ent %&gt;% ungroup %&gt;% mutate(x_s = (x - mean(x))/sd(x)) devianza &lt;- devianza_calc(dat_ent[, &#39;x_s&#39;, drop = FALSE], dat_ent$y) grad &lt;- grad_calc(dat_ent[, &#39;x_s&#39;, drop = FALSE], dat_ent$y) grad(c(0,1)) ## Intercept x_s ## -354.2728 363.2408 grad(c(0.5,-0.1)) ## Intercept x_s ## -217.8069 140.9315 Verificamos cálculo de gradiente: (devianza(c(0.5+0.0001,-0.1)) - devianza(c(0.5,-0.1)))/0.0001 ## [1] -217.7951 (devianza(c(0.5,-0.1+0.0001)) - devianza(c(0.5,-0.1)))/0.0001 ## [1] 140.9435 Y hacemos descenso: iteraciones &lt;- descenso(100, z_0=c(0,0), eta = 0.001, h_deriv = grad) tail(iteraciones, 20) ## [,1] [,2] ## [81,] 2.013788 -1.082934 ## [82,] 2.014013 -1.083081 ## [83,] 2.014223 -1.083218 ## [84,] 2.014419 -1.083345 ## [85,] 2.014602 -1.083465 ## [86,] 2.014773 -1.083576 ## [87,] 2.014932 -1.083680 ## [88,] 2.015081 -1.083777 ## [89,] 2.015220 -1.083868 ## [90,] 2.015350 -1.083952 ## [91,] 2.015471 -1.084031 ## [92,] 2.015585 -1.084105 ## [93,] 2.015690 -1.084174 ## [94,] 2.015789 -1.084238 ## [95,] 2.015881 -1.084298 ## [96,] 2.015967 -1.084354 ## [97,] 2.016048 -1.084407 ## [98,] 2.016123 -1.084456 ## [99,] 2.016193 -1.084501 ## [100,] 2.016258 -1.084544 plot(apply(iteraciones, 1, devianza)) matplot(iteraciones) Comparamos con glm: mod_1 &lt;- glm(y~x_s, data=dat_ent, family = &#39;binomial&#39;) coef(mod_1) ## (Intercept) x_s ## 2.017181 -1.085146 mod_1$deviance ## [1] 351.676 devianza(iteraciones[100,]) ## [1] 351.676 Nótese que esta devianza está calculada sin dividir intre entre el número de casos. Podemos calcular la devianza promedio de entrenamiento haciendo: devianza(iteraciones[100,])/nrow(dat_ent) ## [1] 0.703352 3.6 Observaciones adicionales Máxima verosimilitud Es fácil ver que este método de estimación de los coeficientes (minimizando la devianza de entrenamiento) es el método de máxima verosimilitud. La verosimilitud de la muestra de entrenamiento está dada por: \\[L(\\beta) =\\prod_{i=1}^N p_{y^{(i)}} (x^{(i)})\\] Y la log verosimilitud es \\[l(\\beta) =\\sum_{i=1}^N \\log(p_{y^{(i)}} (x^{(i)})).\\] Así que ajustar el modelo minimizando la expresión (3.1) es los mismo que hacer máxima verosimilitud (condicional a los valores de \\(x\\)). Normalización Igual que en regresión lineal, en regresión logística conviene normalizar las entradas antes de ajustar el modelo Desempeño de regresión logística como método de aprendizaje Igual que en regresión lineal, regresión logística supera a métodos más sofisticados o nuevos en numerosos ejemplos. Las razones son similares: la rigidez de regresión logística es una fortaleza cuando la estructura lineal es una buena aproximación. Ejercicio: datos de diabetes Ya están divididos los datos en entrenamiento y prueba diabetes_ent &lt;- as_data_frame(MASS::Pima.tr) diabetes_pr &lt;- as_data_frame(MASS::Pima.te) diabetes_ent ## # A tibble: 200 x 8 ## npreg glu bp skin bmi ped age type ## * &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;fct&gt; ## 1 5 86 68 28 30.2 0.364 24 No ## 2 7 195 70 33 25.1 0.163 55 Yes ## 3 5 77 82 41 35.8 0.156 35 No ## 4 0 165 76 43 47.9 0.259 26 No ## 5 0 107 60 25 26.4 0.133 23 No ## 6 5 97 76 27 35.6 0.378 52 Yes ## 7 3 83 58 31 34.3 0.336 25 No ## 8 1 193 50 16 25.9 0.655 24 No ## 9 3 142 80 15 32.4 0.2 63 No ## 10 2 128 78 37 43.3 1.22 31 Yes ## # ... with 190 more rows diabetes_ent$id &lt;- 1:nrow(diabetes_ent) diabetes_pr$id &lt;- 1:nrow(diabetes_pr) Normalizamos library(dplyr) library(tidyr) datos_norm &lt;- diabetes_ent %&gt;% gather(variable, valor, npreg:age) %&gt;% group_by(variable) %&gt;% summarise(media = mean(valor), de = sd(valor)) normalizar &lt;- function(datos, datos_norm){ datos %&gt;% gather(variable, valor, npreg:age) %&gt;% left_join(datos_norm) %&gt;% mutate(valor_s = (valor - media)/de) %&gt;% select(id, type, variable, valor_s) %&gt;% spread(variable, valor_s) } diabetes_ent_s &lt;- normalizar(diabetes_ent, datos_norm) diabetes_pr_s &lt;- normalizar(diabetes_pr, datos_norm) x_ent &lt;- diabetes_ent_s %&gt;% select(age:skin) %&gt;% as.matrix p &lt;- ncol(x_ent) y_ent &lt;- diabetes_ent_s$type == &#39;Yes&#39; grad &lt;- grad_calc(x_ent, y_ent) iteraciones &lt;- descenso(1000, rep(0, p + 1), 0.001, h_deriv = grad) matplot(iteraciones) diabetes_coef &lt;- data_frame(variable = c(&#39;Intercept&#39;,colnames(x_ent)), coef = iteraciones[1000,]) diabetes_coef ## # A tibble: 8 x 2 ## variable coef ## &lt;chr&gt; &lt;dbl&gt; ## 1 Intercept -0.956 ## 2 age 0.452 ## 3 bmi 0.513 ## 4 bp -0.0547 ## 5 glu 1.02 ## 6 npreg 0.347 ## 7 ped 0.559 ## 8 skin -0.0225 Ahora calculamos devianza de prueba y error de clasificación: x_prueba &lt;- diabetes_pr_s %&gt;% select(age:skin) %&gt;% as.matrix y_prueba &lt;- diabetes_pr_s$type == &#39;Yes&#39; dev_prueba &lt;- devianza_calc(x_prueba, y_prueba) dev_prueba(iteraciones[1000,])/nrow(x_prueba) ## [1] 0.8813972 Y para el error clasificación de prueba, necesitamos las probabilidades de clase ajustadas: beta &lt;- iteraciones[1000, ] p_beta &lt;- h(as.matrix(cbind(1, x_prueba)) %*% beta) y_pred &lt;- as.numeric(p_beta &gt; 0.5) mean(y_prueba != y_pred) ## [1] 0.1987952 3.7 Más sobre problemas de clasificación En esta parte presentamos técnicas adicionales para evaluar el desempeño de un modelo. En la parte anterior vimos que La devianza es una buena medida para ajustar y evaluar el desempeño de un modelo y comparar modelos, y utiliza las probabilidades de clase. Sin embargo, es una medida de dificil de interpretar en cuanto a los errores que podemos esperar del modelo. Por otro lado, la tasa de clasificación incorrecta puede usarse para evaluar el desempeño de un clasificador (incluyendo uno derivado de probabilidades de clase), puede interpretarse con facilidad, pero se queda corta en muchas aplicaciones. Una deficiencia grande de esta medida es que, contrario al problema de regresión, hay errores de clasificación que son cualitativamente diferentes. Ejemplo Por ejemplo, diagnosticar a alguien con una enfermedad cuando no la tiene tiene consecuencias distintas a diagnosticar como libre de enfermedad a alguien que la tiene. Estas consecuencias dependen de cómo son son los tratamientos consecuentes, de y qué tan peligrosa es la enfermedad. Cuando usamos un buscador como Google, es cualitativamente diferente que el buscador omita resultados relevantes a que nos presente resultados irrelevantes. ¿Otros ejemplos? En general, los costos de los distintos errores son distintos, y en muchos problemas quiséramos entenderlos y controlarlos individualmente. Aunque en teoría podríamos asignar costos a los errores y definir una función de pérdida apropiada, en la práctica esto muchas veces no es tan fácil o deseable. Podemos, sin embargo, reportar el tipo de errores que ocurren Matriz de confusión. Sea \\(\\hat{G}\\) un clasificador binario. La matriz de confusión \\(C\\) de \\(\\hat{G}\\) está dada por \\(C_{i,j} = \\text{Número de casos de la clase verdadera j que son clasificados como clase i por el clasificador}\\) Ejemplo En un ejemplo de tres clases, podríamos obtener la matriz de confusión: A B C A.pred 50 2 0 B.pred 20 105 10 C.pred 20 10 30 Esto quiere decir que de 90 casos de clase \\(A\\), sólo clasificamos a 50 en la clase correcta, de 117 casos de clase \\(B\\), acertamos en 105, etcétera. Podemos ver esta tabla de distintas formas, por ejemplo, usando porcentajes por columna, nos dice cómo se distribuyen los casos de cada clase: knitr::kable(round(prop.table(tabla_1, 2),2)) A B C A.pred 0.56 0.02 0.00 B.pred 0.22 0.90 0.25 C.pred 0.22 0.09 0.75 Mientras que una tabla de porcentajes por renglón nos muestra qué pasa cada vez que hacemos una predicción dada: knitr::kable(round(prop.table(tabla_1, 1),2)) A B C A.pred 0.96 0.04 0.00 B.pred 0.15 0.78 0.07 C.pred 0.33 0.17 0.50 Ahora pensemos cómo podría sernos de utilidad esta tabla. Discute El clasificador fuera uno de severidad de emergencias en un hospital, donde A=requiere atención inmediata B=urgente C=puede posponerse. El clasificador fuera de tipos de cliente de un negocio. Por ejemplo, A = cliente de gasto potencial alto, B=cliente medio, C=abandonador. Imagínate que tiene un costo intentar conservar a un abandonador, y hay una inversión alta para tratar a los clientes A. La tasa de incorrectas es la misma en los dos ejemplos, pero la adecuación del clasificador es muy diferente. 3.7.1 Análisis de error para clasificadores binarios Cuando la variable a predecir es binaria (dos clases), podemos etiquetar una clase como positivo y otra como negativo. En el fondo no importa cómo catalogemos cada clase, pero para problemas particulares una asignación puede ser más natural. Por ejemplo, en diagnóstico de enfermedades, positivo=tiene la enfermedad, en análisis de crédito, positivo=cae en impago, en sistemas de recomendacion, positivo = le gusta el producto X, en recuperación de textos, positivo=el documento es relevante a la búsqueda, etc. Hay dos tipos de errores en un clasificador binario (positivo - negativo): Falsos positivos (fp): clasificar como positivo a un caso negativo. Falsos negativos (fn): clasificar como negativo a un caso positivo. A los casos clasificados correctamente les llamamos positivos verdaderos (pv) y negativos verdaderos (nv). La matriz de confusion es entonces tabla &lt;- data_frame(&#39;-&#39; = c(&#39;positivo.pred&#39;,&#39;negativo.pred&#39;,&#39;total&#39;), &#39;positivo&#39;=c(&#39;pv&#39;,&#39;fn&#39;,&#39;pos&#39;), &#39;negativo&#39;=c(&#39;fp&#39;,&#39;nv&#39;,&#39;neg&#39;), &#39;total&#39; = c(&#39;pred.pos&#39;,&#39;pred.neg&#39;,&#39;&#39;)) knitr::kable(tabla) po sitivo ne gativo to tal positivo.pred pv fp pred.pos negativo.pred fn nv pred.neg total pos neg Nótese que un clasificador bueno, en general, es uno que tiene la mayor parte de los casos en la diagonal de la matriz de confusión. Podemos estudiar a nuestro clasificador en términos de las proporciones de casos que caen en cada celda, que dependen del desempeño del clasificador en cuanto a casos positivos y negativos. La nomenclatura es confusa, pues en distintas áreas se usan distintos nombres para estas proporciones: Tasa de falsos positivos \\[\\frac{fp}{fp+nv}=\\frac{fp}{neg}\\] Tasa de falsos negativos \\[\\frac{fn}{pv+fn}=\\frac{fn}{pos}\\] Especificidad \\[\\frac{nv}{fp+nv}=\\frac{nv}{neg}\\] Sensibilidad o Recall \\[\\frac{pv}{pv+fn}=\\frac{pv}{pos}\\] Y también otras que tienen como base las predicciones: Valor predictivo positivo o Precisión \\[\\frac{vp}{vp+fp}=\\frac{vp}{pred.pos}\\] Valor predictivo negativo \\[\\frac{vn}{fn+vn}=\\frac{vn}{pred.neg}\\] Y hay varias medidas resumen que ponderan de distinta forma Tasa de clasificación incorrecta \\[\\frac{fn+fv}{neg+pos}\\] Medida F (media armónica de precisión y recall) \\[2\\frac{precision \\cdot recall}{precision + recall}\\] AUC (area bajo la curva ROC) ver más adelante Kappa \\[\\kappa = \\frac{p_o - p_e}{1-p_e},\\] donde \\(p_o =\\) tasa de correctos, y \\(p_e\\) es la probabilidad de clasificar correctamente al azar, dado por \\[p_e = \\frac{pos}{total}\\frac{pred.pos}{total} + \\frac{neg}{total}\\frac{pred.neg}{total}\\] Dependiendo de el tema y el objetivo hay medidas más naturales que otras: En pruebas clínicas, se usa típicamente sensibilidad y especificidad (proporción de positivos que detectamos y proporción de negativos que descartamos). En búsqueda y recuperación de documentos (positivo=el documento es relevante, negativo=el documento no es relevante), se usa precisión y recall (precisión=de los documentos que entregamos (predicción positiva), cuáles son realmente positivos/relevantes, y recall=de todos los documentos relevantes, cuáles devolvemos). Aquí la tasa de falsos positivos (de todos los negativos, cuáles se predicen positivos), por ejemplo, no es de ayuda pues generalmente son bajas y no discriminan el desempeño de los clasificadores. La razón es que típicamente hay una gran cantidad de negativos, y se devuelven relativamente pocos documentos, de forma que la tasa de falsos positivos generalmente es muy pequeña. \\(\\kappa\\) señala un problema importante cuando interpretamos tasas de correctos. Por ejemplo, supongamos que hay un 85% de positivos y un 15% de negativos. Si nuestro clasificador clasifica todo a positivo, nuestra tasa de correctos sería 85% - pero nuestro clasificador no está aprovechando los datos. En este caso, \\[p_e = 0.85(1) + 0.15(0)= 0.85\\], y tenemos que \\(\\kappa = 0\\) (similar al azar). Supongamos por otra parte que escogemos 50% del tiempo positivo al azar. Esto quiere decir que tendríamos \\(p_o=0.5\\). Pero \\[p_e = 0.85(0.50) + 0.15(0.50) = 0.50,\\] de modo que otra vez \\(\\kappa = 0\\). \\(\\kappa\\) es un valor entre 0 y 1 que mide qué tan superior es nuestro clasificador a uno dado al azar (uno que la predicción no tiene qué ver con la clase verdadera). 3.7.2 Regresión logística para problemas de más de 2 clases Consideramos ahora un problema con más de dos clases, de manera que \\(G ∈ {1,2,...,K}\\) (\\(K\\) clases), y tenemos \\(X = (X1 ...,Xp)\\) entradas. ¿Cómo generalizar el modelo de regresión logística a este problema? Una estrategia es la de uno contra todos: En clasificación uno contra todos, hacemos Para cada clase \\(g\\in\\{1,\\ldots,K\\}\\) entrenamos un modelo de regresión logística (binaria) \\(\\hat{p}^{(g)}(x)\\), tomando como positivos a los casos de 1 clase \\(g\\), y como negativos a todo el resto. Esto lo hacemos como en las secciones anteriores, y de manera independiente para cada clase. Para clasificar un nuevo caso \\(x\\), calculamos \\[\\hat{p}^{(1)}, \\hat{p}^{(2)},\\ldots, \\hat{p}^{(K)}\\] y clasificamos a la clase de máxima probabilidad \\[\\hat{G}(x) = \\arg\\max_g \\hat{p}^{(g)}(x)\\] Nótese que no hay ninguna garantía de que las probabilidades de clase sumen 1, pues se trata de estimaciones independientes de cada clase. En este sentido, produce estimaciones que en realidad no satisfacen las propiedades del modelo de probabilidad establecido. Sin embargo, esta estrategia es simple y en muchos casos funciona bien. 3.7.3 Regresión logística multinomial Si queremos obtener estimaciones de las probabilidades de clase que sumen uno, entonces tenemos que contruir las estimaciones de cada clase de clase de manera conjunta. Como vimos antes, tenemos que estimar, para cada \\(x\\) y \\(g\\in\\{1,\\ldots, K\\}\\), las probabilidades condicionales de clase: \\[p_g(x) = P(G = g|X = x).\\] Podemos generalizar para más de 2 clases usando una idea similar: \\[p_1(x) = \\exp(\\beta_{0,1} + \\beta_{1,1}x_1 + \\ldots + \\beta_{p,1} x_p)/Z\\] \\[p_2(x) = \\exp(\\beta_{0,2} + \\beta_{1,2}x_2 + \\ldots + \\beta_{p.2} x_p)/Z\\] hasta \\[p_{K-1}(x) = \\exp(\\beta_{0,{K-1}} + \\beta_{1,{K-1}}x_2 + \\ldots + \\beta_{p,{K-1}} x_p)/Z\\] y \\[p_K(x) = \\exp(\\beta_{0,{K}} + \\beta_{1,{K}}x_2 + \\ldots + \\beta_{p,{K}} x_p)/Z\\] En este caso, para que las probabilidades sumen 1, necesitamos que \\[Z = \\sum_{j=1}^{K}\\exp(\\beta_0^j + \\beta_1^jx_2 + \\ldots + \\beta_p^j x_p)\\] Para ajustar coeficientes, usamos el mismo criterio de devianza de entrenamiento. Buscamos minimizar: \\[D(\\beta)=−2 \\sum_{i=1}^N p_{g^{(i)}}(x^{(i)}),\\] Donde \\(\\beta\\) contiene todos los coeficientes organizados en un vector de tamaño \\((p+1)(K+1)\\): \\[\\beta = ( \\beta_0^1, \\beta_1^1, \\ldots , \\beta_p^1, \\beta_0^2, \\beta_1^2, \\ldots , \\beta_p^2, \\ldots \\beta_0^{K}, \\beta_1^{K}, \\ldots , \\beta_p^{K} )\\] Y ahora podemos usar algún método númerico para minimizar la devianza (por ejemplo, descenso en gradiente). Cuando es muy importante tener probabilidades bien calibradas, el enfoque multinomial es más apropiado, pero muchas veces, especialmente si sólo nos interesa clasificar, los dos métodos dan resultados similares. "],
["regresion-regularizada.html", "Sección 4 Regresión regularizada 4.1 Regularización ridge 4.2 Entrenamiento, Validación y Prueba 4.3 Regularización lasso", " Sección 4 Regresión regularizada Ejemplo Consideremos dos métodos: regresión lineal y regresión polinomial (pensemos que es un tipo de ajuste de curvas). Para ilustrar los conceptos de sesgo y varianza simularemos varios posibles muestras de entrenamiento: library(tidyverse) theme_set(theme_bw()) cbbPalette &lt;- c(&quot;#000000&quot;, &quot;#E69F00&quot;, &quot;#56B4E9&quot;, &quot;#009E73&quot;, &quot;#F0E442&quot;, &quot;#0072B2&quot;, &quot;#D55E00&quot;, &quot;#CC79A7&quot;) f &lt;- function(x){ sin(6*x)} sim_data &lt;- function(n = 15){ x &lt;- runif(n, 0, 1) y &lt;- f(x) + rnorm(n, 0, 0.4) data_frame(x = x, y = y) } dat &lt;- sim_data(n = 100) plot(dat$x,dat$y) set.seed(92114) sims &lt;- data_frame(rep = 1:10) sims &lt;- sims %&gt;% group_by(rep) %&gt;% mutate(data = list(data = sim_data())) %&gt;% unnest Regresión lineal en \\(x\\) nos da diferencias consistentes entre predicciones y observaciones (es un método que sufre de sesgo): ggplot(sims, aes(x=x, y=y)) + geom_point() + facet_wrap(~rep) + geom_smooth(formula = y~x, method =&#39;lm&#39;, colour = &#39;red&#39;, se = FALSE) + ylim(c(-3,3)) Mientras que regresión polinomial nos da diferencias variables y grandes entre predicciones y observaciones (es un método que sufre de varianza): ggplot(sims, aes(x=x, y=y)) + geom_point() + facet_wrap(~rep) + geom_smooth(formula = y~ poly(x, 5, raw = TRUE), method =&#39;lm&#39;, colour = &#39;red&#39;, se = FALSE) + ylim(c(-3,3)) En este ejemplo, ambos métodos se desempeñan mal, pero por razones distintas: El primer método sufre (ajuste lineal) sufre de sesgo: es un método rígido que no aprende de patrones en los datos. Independientemente de los datos, tienen a sobreestimar o subestimar consistentemente la respuesta en algunos distintas regiones. No importa cuántos datos tenga, podremos observar este patrón de desempeño pobre. En términos de nuestra notación, si \\(Y=f(X) + \\epsilon\\), el predictor \\(\\hat{f}\\) está lejos de \\(f\\) porque \\(\\hat{f}\\) no puede ajustarse a patrones verdaderos en los datos. Otra manera de decir esto es que el modelo no puede capturar señales claras en los datos. Este fonómeno de sesgo alto también se denomina subajuste. El segundo método sufre de varianza: es un método demasiado flexible (para este problema) que aprende aspectos particulares de la muestra de datos que consideramos, en lugar de patrones sólidos de los datos. Su desempeño es malo porque lo que aprende no se repite en muestras futuras. En términos de nuestra notación, si \\(Y=f(X) + \\epsilon\\), el predictor \\(\\hat{f}\\) está lejos de \\(f\\) porque \\(\\hat{f}\\) demasiado influida por valores de \\(\\epsilon\\). Esto hace \\(\\hat{f}\\) esté lejos de la verdadera \\(f\\). El modelo captura aspectos de ruido como si fueran señal. Cada uno de estos problemas requiere soluciones diferentes. Para tener mejor desempeño en la predicción, tenemos que balancear con cuidado el sesgo y la varianza de nuestros métodos. Generalmente cuando reducimos la varianza (usando métodos más rígidos), nos arriesgamos a sufrir más sesgo, y viceversa: cuando reducimos sesgo (usando métodos más flexibles), nos arriesgamos a sufrir por más varianza. Otra manera de ver esto es que debemos encontrar la complejidad adecuada de nuestros modelos para capturar la señal en los datos de manera adecuada -sin ignorar señales claras pero no tomando ruidos como señal. 4.0.1 Sesgo y varianza en modelos lineales Aunque típicamente pensamos que los modelos lineales son métodos simples, con estructura rígida, y que tienden a sufrir más por sesgo que por varianza (parte de la razón por la que existen métodos más flexibles como bosques aleatorios, redes nueronales, etc.), hay varias razones por las que los métodos lineales pueden sufrir de varianza alta: Cuando la muestra de entrenamiento es relativamente chica (\\(N\\) chica), la varianza puede ser alta. Cuando el número de entradas \\(p\\) es grande, podemos también sufrir de varianza grande (pues tenemos muchos parámetros para estimar). Cuando hay variables correlacionadas en las entradas la varianza también puede ser alta. En estos casos, conviene buscar maneras de reducir varianza - generalmente a costa de un incremento de sesgo. Ejemplo Consideramos regresión logística. En primer lugar, supondremos que tenemos un problema con \\(n=400\\) y \\(p=100\\), y tomamos como modelo para los datos (sin ordenada al origen): \\[p_1(x)=h\\left(\\sum_{j=1}^{100} \\beta_j x_j\\right ),\\] donde \\(h\\) es la función logística. Nótese que este es el verdadero modelo para los datos. Para producir datos de entrenamiento, primero generamos las betas fijas, y después, utilizando estas betas, generamos 400 casos de entrenamiento. Generamos las betas: h &lt;- function(x){ 1 / (1 + exp(-x))} set.seed(2805) beta &lt;- rnorm(100,0,0.1) names(beta) &lt;- paste0(&#39;V&#39;, 1:length(beta)) head(beta, 5) ## V1 V2 V3 V4 V5 ## -0.11987553 0.03462759 -0.08181807 0.01492096 0.04016015 Con esta función simulamos datos de entrenamiento (400) y datos de prueba (5000). sim_datos &lt;- function(n, m, beta){ p &lt;- length(beta) #n = casos de entrenamiento, m= casos de prueba, p=num variables mat &lt;- matrix(rnorm((n+m)*p, 0, 0.5), n+m, p) + rnorm(n + m) prob &lt;- h(mat %*% beta) y &lt;- rbinom(n + m, 1, prob) dat &lt;- as.data.frame(mat) dat$y &lt;- y dat$entrena &lt;- FALSE dat$entrena[1:n] &lt;- TRUE dat } set.seed(9921) datos &lt;- sim_datos(n = 500, m = 2000, beta = beta) Y ahora ajustamos el modelo de regresión logística (no usamos ordenada al origen para simplificar): mod_1 &lt;- glm(y ~ -1 + ., datos %&gt;% filter(entrena) %&gt;% select(-entrena), family = &#39;binomial&#39;) ¿Qué tan buenas fueron nuestras estimaciones? qplot(beta, mod_1$coefficients) + xlab(&#39;Coeficientes&#39;) + ylab(&#39;Coeficientes estimados&#39;) + geom_abline(intercept=0, slope =1) + xlim(c(-1.5,1.5))+ ylim(c(-1.5,1.5)) Y notamos que las estimaciones no son muy buenas, y tienen dispersión alta. Podemos hacer otra simulación para confirmar que el problema es que las estimaciones son muy variables. Simulamos otra muestra de entrenamiento, y vemos cómo se comparan los coeficientes de las dos muestras: datos_2 &lt;- sim_datos(n = 500, m = 10, beta = beta) mod_2 &lt;- glm(y ~ -1 + ., datos_2 %&gt;% filter(entrena) %&gt;% select(-entrena), family = &#39;binomial&#39;) qplot(mod_1$coefficients, mod_2$coefficients) + xlab(&#39;Coeficientes mod 1&#39;) + ylab(&#39;Coeficientes mod 2&#39;) + geom_abline(intercept=0, slope =1) + xlim(c(-1.5,1.5))+ ylim(c(-1.5,1.5)) Si repetimos varias veces: dat_sim &lt;- lapply(1:20, function(i){ salida &lt;- sim_datos(n=500, m=10, beta) mod &lt;- glm(y ~ -1 + ., salida %&gt;% filter(entrena) %&gt;% select(-entrena), family = &#39;binomial&#39;) data_frame(rep = i, vars = names(coef(mod)), coefs = coef(mod)) }) %&gt;% bind_rows head(dat_sim) ## # A tibble: 6 x 3 ## rep vars coefs ## &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 V1 -0.0527 ## 2 1 V2 0.427 ## 3 1 V3 -0.0772 ## 4 1 V4 -0.249 ## 5 1 V5 0.355 ## 6 1 V6 0.514 Vemos que hay mucha variabilidad en la estimación de los coeficientes (en rojo están los verdaderos): dat_sim &lt;- dat_sim %&gt;% mutate(vars = reorder(vars, coefs, mean)) ggplot(dat_sim, aes(x=vars, y=coefs)) + geom_boxplot() + geom_line(data=data_frame(coefs=beta, vars=names(beta)), aes(y=beta, group=1), col=&#39;red&#39;,size=1.1) + coord_flip() En la práctica, nosotros tenemos una sola muestra de entrenamiento. Así que, con una muestra de tamaño \\(n=500\\) como en este ejemplo, obtendremos típicamente resultados no muy buenos. Estos coeficientes ruidosos afectan nuestras predicciones de manera negativa. Vemos ahora lo que pasa con nuestra \\(\\hat{p}_1(x)\\) estimadas, comparándolas con \\(p_1(x)\\) (las probabilidades reales), para la primera simulación: dat_e &lt;- datos %&gt;% filter(entrena) dat_p &lt;- datos %&gt;% filter(!entrena) x_e &lt;- dat_e %&gt;% select(-entrena, -y) %&gt;% as.matrix x_p &lt;- dat_p %&gt;% select(-entrena, -y) %&gt;% as.matrix p_entrena &lt;- data_frame(prob_hat_1 = mod_1$fitted.values, prob_1 = as.numeric(h(x_e %*% beta)), clase = dat_e$y) p_prueba &lt;- data_frame(prob_hat_1 = h(x_p %*% (mod_1$coefficients))[,1], prob_1 = h(x_p %*% beta)[,1], clase = dat_p$y) Para los datos de entrenamiento: ggplot(p_entrena, aes(x=prob_1, y=prob_hat_1, colour=factor(clase))) + geom_point()+ xlab(&quot;Probabilidades verdaderas&quot;) + ylab(&quot;Probabilidades estimadas&quot;) Y con la muestra de prueba: ggplot(p_prueba, aes(x=prob_1, y=prob_hat_1, colour=factor(clase))) + geom_point()+ xlab(&quot;Probabilidades verdaderas&quot;) + ylab(&quot;Probabilidades estimadas&quot;) Si la estimación fuera perfecta, esta gráfica sería una diagonal. Vemos entonces que cometemos errores grandes. El problema no es que nuestro modelo no sea apropiado (logístico), pues ese es el modelo real. El problema es la variabilidad en la estimación de los coeficientes que notamos arriba. La matriz de confusión de prueba está dada por (normalizando por columnas): tab &lt;- table(p_prueba$prob_hat_1 &gt; 0.5, p_prueba$clase) prop.table(tab, margin=2) ## ## 0 1 ## FALSE 0.6587302 0.3467742 ## TRUE 0.3412698 0.6532258 Así que para los ejemplos de tipo 1 tenemos un error de alrededor de 34%, y para los de tipo 0 un error cerca de 34%. La tasa de clasificación incorrecta en la muestra de prueba es: mean((p_prueba$prob_hat_1 &gt; 0.5) != (p_prueba$clase == 1)) ## [1] 0.344 Veremos ahora que podemos mejorar este modelo controlando la varianza que coeficientes que acabamos de observar. 4.0.2 Reduciendo varianza de los coeficientes Como el problema es la varianza, podemos atacar este problema poniendo restricciones a los coeficientes, de manera que caigan en rangos más aceptables. Una manera de hacer esto es sustituir el problema de minimización de regresión logística, que es minimizar la devianza: \\[\\min_{\\beta} D(\\beta)\\] con un problema penalizado \\[\\min_{\\beta} D(\\beta) + \\lambda\\sum_{i=1}^p \\beta_j^2\\] escogiendo un valor apropiado de \\(\\lambda\\). También es posible poner restricciones sobre el tamaño de \\(\\sum_{i=1}^p \\beta_j^2\\), lo cual es equivalente al problema de penalización. En este caso obtenemos (veremos más del paquete glmnet): library(glmnet) mod_restringido &lt;- glmnet(x = x_e, y = dat_e$y, alpha = 0, family=&#39;binomial&#39;, intercept = FALSE, lambda = 0.1) beta_penalizado &lt;- coef(mod_restringido)[-1] # quitar intercept Y podemos ver que el tamaño de los coeficientes se redujo considerablemente: sum(beta_penalizado^2) ## [1] 0.3185858 sum(coef(mod_1)^2) ## [1] 13.62839 Los nuevos coeficientes estimados: qplot(beta, beta_penalizado) + xlab(&#39;Coeficientes&#39;) + ylab(&#39;Coeficientes estimados&#39;) + geom_abline(intercept=0, slope =1) + xlim(c(-0.5,0.5))+ ylim(c(-0.5,0.5)) p_entrena$prob_hat_pen &lt;- h(x_e %*% as.numeric(beta_penalizado)) p_prueba$prob_hat_pen &lt;- h(x_p %*% as.numeric(beta_penalizado)) Para los datos de entrenamiento: ggplot(p_entrena, aes(x=prob_1, y=prob_hat_pen, colour=factor(clase))) + geom_point() Y con la muestra de prueba: ggplot(p_prueba, aes(x=prob_1, y=prob_hat_pen, colour=factor(clase))) + geom_point() La matriz de confusión es ahora: tab &lt;- table(p_prueba$prob_hat_pen &gt; 0.5, p_prueba$clase) prop.table(tab, margin=2) ## ## 0 1 ## FALSE 0.6994048 0.3094758 ## TRUE 0.3005952 0.6905242 Y vemos que logramos reducir considerablemente el error de clasificación de prueba. Sin embargo, vemos que en la muestra de entrenamiento se desempeña mejor el modelo sin penalización, como es de esperarse (¿Por qué?). Si ingenuamente escogemos nuestro modelo según el error de entrenamiento, empeoraríamos nuestro desempeño para muestras futuras: error_entrena &lt;- mean((p_entrena$prob_hat_1 &gt; 0.5) != (p_entrena$clase==1)) error_entrena_penalizado &lt;- mean((p_entrena$prob_hat_pen &gt; 0.5) != (p_entrena$clase==1)) error_entrena ## [1] 0.21 error_entrena_penalizado ## [1] 0.246 4.1 Regularización ridge Arriba vimos un ejemplo de regresión penalizada tipo ridge. Recordemos que para regresión lineal, buscábamos minimizar la cantidad \\[D(\\beta)=\\frac{1}{n}\\sum_{i=1}^n (y_i -\\beta_0 - \\sum_{j=1}^p \\beta_j x_{ij})^2\\] y en regresión logística, \\[D(\\beta)=-\\frac{2}{n}\\sum_{i=1}^n y_i \\log p_{\\beta}(x^{(i)}) + (1-y_i) \\log(1 - p_{\\beta}(x^{(i)})).\\] En regresión ridge (lineal/logística), para \\(\\lambda&gt;0\\) fija minimizamos \\[D_{\\lambda}^{ridge} (\\beta)=D(\\beta) + \\lambda\\sum_{i=1}^p \\beta_j^2\\], donde suponemos que las entradas están estandarizadas (centradas y escaladas por la desviación estándar). Observaciones La idea de regresión penalizada consiste en estabilizar la estimación de los coeficientes, especialmente en casos donde tenemos muchas variables en relación a los casos de entrenamiento. La penalización no permite que varíen tan fuertemente los coeficientes. Cuando \\(\\lambda\\) es mas grande, los coeficientes se encogen más fuertemente hacia cero con respecto al problema no regularizado. En este caso, estamos reduciendo la varianza pero potencialmente incrementando el sesgo. Cuando \\(\\lambda\\) es mas chico, los coeficientes se encogen menos fuertemente hacia cero, y quedan más cercanos a los coeficientes de mínimos cuadrados/máxima verosimilitud. En este caso, estamos reduciendo el sesgo pero incrementando la varianza. Nótese que no penalizamos \\(\\beta_0\\). Es posible hacerlo, pero típicamente no lo hacemos. En regresión lineal, de esta forma garantizamos que la predicción \\(\\hat{y}\\), cuando todas las variables \\(x_j\\) toman su valor en la media, es el promedio de las \\(y_i\\)’s de entrenamiento. Igualmente en regresión logística, la probabilidad ajustada cuando las entradas toman su valor en la media es igual a \\(h(\\beta_0)\\). Que las variables estén estandarizadas es importante para que tenga sentido la penalización. Si las variables \\(x_j\\) están en distintas escalas (por ejemplo pesos y dólares), entonces también los coeficientes \\(\\beta_j\\) están en distintas escalas, y una penalización fija no afecta de la misma forma a cada coeficiente. Resolver este problema por descenso en gradiente no tienen dificultad, pues: \\[\\frac{\\partial D_{\\lambda}^{ridge} (\\beta)}{\\partial\\beta_j} = \\frac{\\partial D(\\beta)}{\\beta_j} + 2\\lambda\\beta_j\\] para \\(j=1,\\ldots, p\\), y \\[\\frac{\\partial D_{\\lambda}^{ridge} (\\beta)}{\\partial\\beta_0} = \\frac{\\partial D(\\beta)}{\\beta_0}.\\] De forma que sólo hay que hacer una modificación mínima al algoritmo de descenso en gradiente para el caso no regularizado. 4.1.1 Selección de coeficiente de regularización Seleccionamos \\(\\lambda\\) para minimizar el error de predicción, es decir, para mejorar nuestro modelo ajustado en cuanto a sus predicciones. No tiene sentido intentar escoger \\(\\lambda&gt;0\\) usando el error de entrenamiento. La razón es que siempre que aumentamos \\(\\lambda\\), obtenemos un valor mayor de la suma de cuadrados / devianza del modelo, pues \\(\\lambda\\) más grande implica que pesa menos la minimización de la suma de cuadrados /devianza en el problema de la minimización. En otras palabras, los coeficientes tienen una penalización más fuerte, de modo que el mínimo que se alcanza es mayor en términos de devianza. Intentamos escoger \\(\\lambda\\) de forma que se minimice el error de predicción, o el error de prueba (que estima el error de predicción). Ejemplo (simulación) Regresamos a nuestro problema original simulado de clasificación. La función glmnet se encarga de estandarizar variables y escoger un rango adecuado de penalizaciones \\(\\lambda\\). La función glmnet ajusta varios modelos (parámetro nlambda) para un rango amplio de penalizaciones \\(\\lambda\\). En lo que sigue, agregamos el intercept (ordenada al origen), como normalmente hacemos: library(glmnet) mod_ridge &lt;- glmnet(x = x_e, y = dat_e$y, alpha = 0, #ridge family=&#39;binomial&#39;, nlambda=50) dim(coef(mod_ridge)) ## [1] 101 50 En primer lugar, observamos cómo se encogen los coeficientes para distintos valores de \\(\\lambda\\): plot(mod_ridge, xvar=&#39;lambda&#39;) Para escoger el valor adecuado de \\(\\lambda\\), calculamos la devianza bajo la muestra de prueba: devianza &lt;- function(p, y){ -2*mean(y * log(p) + (1-y) * log(1 - p)) } # predict en glmnet produce probabilidades para los 50 modelos preds_ridge &lt;- predict(mod_ridge, newx = x_p, type = &#39;response&#39;) %&gt;% data.frame %&gt;% mutate(id = 1:nrow(x_p)) %&gt;% gather(modelo, prob, -id) %&gt;% left_join(dat_p %&gt;% mutate(id=1:nrow(dat_p)) %&gt;% select(id, y)) ## Joining, by = &quot;id&quot; head(preds_ridge) ## id modelo prob y ## 1 1 s0 0.484 0 ## 2 2 s0 0.484 0 ## 3 3 s0 0.484 0 ## 4 4 s0 0.484 1 ## 5 5 s0 0.484 0 ## 6 6 s0 0.484 0 tail(preds_ridge) ## id modelo prob y ## 99995 1995 s49 0.60302538 1 ## 99996 1996 s49 0.85778751 1 ## 99997 1997 s49 0.22064914 0 ## 99998 1998 s49 0.70152154 1 ## 99999 1999 s49 0.62870419 0 ## 100000 2000 s49 0.07961955 0 df_lambdas &lt;- data_frame(modelo = attr(mod_ridge$a0, &#39;names&#39;), lambda = mod_ridge$lambda) devianzas_prueba &lt;- preds_ridge %&gt;% group_by(modelo) %&gt;% summarise( devianza = devianza(prob, y)) %&gt;% left_join(df_lambdas) ## Joining, by = &quot;modelo&quot; ggplot(devianzas_prueba, aes(x = lambda, y= devianza)) + scale_x_log10(breaks = round(2^seq(-5,5,1),2)) + geom_point() Buscamos entonces minimizar la devianza (evaluada en la muestra de prueba), que corresponde a tomar un valor de \\(\\lambda\\) alrededor de exp(-2). Discusión: ¿por qué la devianza de prueba tiene esta forma, que es típica para problemas de regularización? El modelo final queda como sigue: df_lambdas ## # A tibble: 50 x 2 ## modelo lambda ## &lt;chr&gt; &lt;dbl&gt; ## 1 s0 247. ## 2 s1 205. ## 3 s2 170. ## 4 s3 141. ## 5 s4 116. ## 6 s5 96.5 ## 7 s6 80.0 ## 8 s7 66.3 ## 9 s8 54.9 ## 10 s9 45.5 ## # ... with 40 more rows coefs_selec &lt;- coef(mod_ridge)[ , &#39;s40&#39;] pred_prueba_final &lt;- h(cbind(1, x_p) %*% coefs_selec) tab_confusion &lt;- table(pred_prueba_final &gt; 0.5, dat_p$y) tab_confusion ## ## 0 1 ## FALSE 746 344 ## TRUE 262 648 prop.table(tab_confusion, margin=2) ## ## 0 1 ## FALSE 0.7400794 0.3467742 ## TRUE 0.2599206 0.6532258 Ejemplo: variables correlacionadas Ridge es efectivo para reducir varianza inducida por variables correlacionadas. library(readr) dat_grasa &lt;- read_csv(file = &#39;datos/bodyfat.csv&#39;) head(dat_grasa) ## # A tibble: 6 x 14 ## grasacorp edad peso estatura cuello pecho abdomen cadera muslo rodilla ## &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 12.3 23 154. 67.8 36.2 93.1 85.2 94.5 59 37.3 ## 2 6.1 22 173. 72.2 38.5 93.6 83 98.7 58.7 37.3 ## 3 25.3 22 154 66.2 34 95.8 87.9 99.2 59.6 38.9 ## 4 10.4 26 185. 72.2 37.4 102. 86.4 101. 60.1 37.3 ## 5 28.7 24 184. 71.2 34.4 97.3 100 102. 63.2 42.2 ## 6 20.9 24 210. 74.8 39 104. 94.4 108. 66 42 ## # ... with 4 more variables: tobillo &lt;dbl&gt;, biceps &lt;dbl&gt;, antebrazo &lt;dbl&gt;, ## # muñeca &lt;dbl&gt; nrow(dat_grasa) ## [1] 252 set.seed(127) dat_grasa$unif &lt;- runif(nrow(dat_grasa), 0, 1) dat_grasa &lt;- arrange(dat_grasa, unif) dat_grasa$id &lt;- 1:nrow(dat_grasa) bfat_e &lt;- dat_grasa[1:100,] bfat_p &lt;- dat_grasa[101:252,] xbf_e &lt;- bfat_e %&gt;% select(estatura, peso, abdomen, muslo, biceps) %&gt;% as.matrix cor(xbf_e) ## estatura peso abdomen muslo biceps ## estatura 1.00000000 0.2534694 0.0928379 0.04835578 0.1857616 ## peso 0.25346939 1.0000000 0.9059227 0.86412005 0.8273691 ## abdomen 0.09283790 0.9059227 1.0000000 0.78986726 0.7308348 ## muslo 0.04835578 0.8641200 0.7898673 1.00000000 0.7899550 ## biceps 0.18576161 0.8273691 0.7308348 0.78995504 1.0000000 ridge_bodyfat &lt;- glmnet(x = xbf_e, y = bfat_e$grasacorp, alpha=0, lambda = exp(seq(-2, 7, 0.25))) plot(ridge_bodyfat, xvar = &#39;lambda&#39;, label=TRUE) coef(ridge_bodyfat)[, 37] ## (Intercept) estatura peso abdomen muslo biceps ## -38.3881059 -0.1814424 -0.1318539 0.9867113 -0.1983769 0.4374818 coef(ridge_bodyfat)[, 15] ## (Intercept) estatura peso abdomen muslo biceps ## -2.84440852 -0.04789201 0.02175931 0.10472079 0.09757134 0.18222422 Donde notamos que las variables con correlaciones altas se “encogen” juntas hacia valores similares conforme aumentamos la constante de penalización \\(\\lambda\\). Nótese que para regularización muy baja, peso y abdomen por ejemplo, tienen signos opuestos y valores altos: esto es posible pues tienen correlación alta, de modo que la función de predicción está pobremente determinada: hay un espacio grande de pares de parámetros que dan predicciones similares, y esto resulta en coeficientes con varianza alta y predicciones inestables y ruidosas. Nótese, adicionalmente, que los coeficientes parecen tener más sentido en relación al problema con regularización. Regularización, en este tipo de problemas, es una de las componentes necesarias (pero no suficiente) para ir hacia interpretación del fenómeno que nos interesa. 4.2 Entrenamiento, Validación y Prueba El enfoque que vimos arriba, en donde dividemos la muestra en dos partes al azar, es la manera más fácil de seleccionar modelos. En general, el proceso es el siguiente: Una parte con los que ajustamos todos los modelos que nos interesa. Esta es la muestra de entrenamiento Una parte como muestra de prueba, con el que evaluamos el desempeño de cada modelo ajustado en la parte anterior. En este contexto, a esta muestra se le llama muestra de validación}. Posiblemente una muestra adicional independiente, que llamamos muestra de prueba, con la que hacemos una evaluación final del modelo seleccionado arriba. Es una buena idea apartar esta muestra si el proceso de validación incluye muchos métodos con varios parámetros afinados (como la \\(\\lambda\\) de regresión ridge). knitr::include_graphics(&quot;./imagenes/div_muestra.png&quot;) Cuando tenemos datos abundantes, este enfoque es el usual. Por ejemplo, podemos dividir la muestra en 50-25-25 por ciento. Ajustamos modelos con el primer 50%, evaluamos y seleccionamos con el segundo 25% y finalmente, si es necesario, evaluamos el modelo final seleccionado con la muestra final de 25%. La razón de este proceso es que así podemos ir y venir entre entrenamiento y validación, buscando mejores enfoques y modelos, y no ponemos en riesgo la estimación final del error. (Pregunta: ¿por qué probar agresivamente buscando mejorar el error de validación podría ponder en riesgo la estimación final del error del modelo seleccionado? ) 4.2.1 Validación cruzada En muchos casos, no queremos apartar una muestra de validación para seleccionar modelos, pues no tenemos muchos datos (al dividir la muestra obtendríamos un modelo relativamente malo en relación al que resulta de todos los datos). Un criterio para seleccionar la regularización adecuada es el de **validación cruzada*, que es un método computacional para producir una estimación interna (usando sólo muestra de entrenamiento) del error de predicción. En validación cruzada (con \\(k\\) vueltas), construimos al azar una partición, con tamaños similares, de la muestra de entrenamiento \\({\\mathcal L}=\\{ (x_i,y_i)\\}_{i=1}^n\\): \\[ {\\mathcal L}={\\mathcal L}_1\\cup {\\mathcal L}_2\\cup\\cdots\\cup {\\mathcal L}_k.\\] knitr::include_graphics(&quot;./imagenes/div_muestra_cv.png&quot;) Construimos \\(k\\) modelos distintos, digamos \\(\\hat{f}_j\\), usando solamente la muestra \\({\\mathcal L}-{\\mathcal L}_j\\). Este modelo lo evaluamos usando la parte que no usamos, \\({\\mathcal L}_j\\), para obtener una estimación honesta del error del modelo \\(\\hat{f}_k\\), a la que denotamos por \\(\\hat{e}_j\\). Notemos entonces que tenemos \\(k\\) estimaciones del error \\(\\hat{e}_1,\\ldots, \\hat{e}_k\\), una para cada uno de los modelos que construimos. La idea ahora es que Cada uno de los modelos \\(\\hat{f}_j\\) es similar al modelo ajustado con toda la muestra \\(\\hat{f}\\), de forma que podemos pensar que cada una de las estimaciones \\(\\hat{e}_j\\) es un estimador del error de \\(\\hat{f}\\). Dado el punto anterior, podemos construir una mejor estimación promediando las \\(k\\) estimaciones anteriores, para obtener: \\[\\widehat{cv} = \\frac{1}{k} \\sum_{j=1}^k \\hat{e}_j.\\] ¿Cómo escoger \\(k\\)? Usualmente se usan \\(k=5,10,20\\), y \\(k=10\\) es el más popular. La razón es que cuando \\(k\\) es muy chico, tendemos a evaluar modelos construidos con pocos datos (comparado al modelo con todos los datos de entrenamiento). Por otra parte, cuando \\(k\\) es grande el método puede ser muy costoso (por ejemplo, si \\(k=N\\), hay que entrenar un modelo para cada dato de entrada). Por ejemplo, el paquete glmnet incluye la función cv.glmnet, que hace los \\(k\\) ajustes para cada una de las lambdas: library(glmnet) set.seed(291) cv_mod_ridge &lt;- cv.glmnet(x = x_e, y=dat_e$y, alpha = 0, family=&#39;binomial&#39;, intercept = F, nfolds = 10, nlambda=50) plot(cv_mod_ridge) cv_mod_ridge$lambda.min ## [1] 0.2837257 cv_mod_ridge$lambda.1se ## [1] 6.928732 Nótese que la estimación del error de predicción por validación cruzada incluye un error de estimación (intervalos). Esto nos da dos opciones para escoger la lambda final: Escoger la que de el mínimo valor de error por validación cruzada Escoger la lambda más grande que no esté a más de 1 error estándar del mínimo. En la gráfica anterior se muestran las dos posibilidades. La razón del segundo criterio es tomar el modelo más simple que tenga error consistente con el mejor modelo. ¿Cómo se desempeña validación cruzada como estimación del error? cross_valid &lt;- data_frame(devianza_cv = cv_mod_ridge$cvm, modelo = attr(cv_mod_ridge$glmnet.fit$a0, &#39;names&#39;)[1:49]) devs &lt;- devianzas_prueba %&gt;% left_join(cross_valid) %&gt;% rename(devianza_prueba = devianza) %&gt;% gather(tipo, devianza, devianza_prueba, devianza_cv) ## Joining, by = &quot;modelo&quot; ggplot(devs, aes(x=log(lambda), y=devianza, colour=tipo)) + geom_point() ## Warning: Removed 1 rows containing missing values (geom_point). Vemos que la estimación en algunos casos no es tan buena, aún cuando todos los datos fueron usados. Pero el mínimo se encuentra en lugares muy similares. La razón es que validación cruzada en realidad considera perturbaciones del conjunto de entrenamiento, de forma que lo que intenta evaluar el error producido, para cada lambda, sobre distintas muestras de entrenamiento. En realidad nosotros queremos evaluar el error de predicción del modelo que ajustamos. Validación cruzada es más un estimador del error esperado de predicción sobre los modelos que ajustaríamos con distintas muestras de entrenamiento. El resultado es que: Usamos validación cruzada para escoger la complejidad adecuada de la familia de modelos que consideramos. Como estimación del error de predicción del modelo que ajustamos, validación cruzada es más seguro que usar el error de entrenamiento, que muchas veces puede estar fuertemente sesgado hacia abajo. Sin embargo, lo mejor en este caso es utilizar una muestra de prueba. Ejercicio Consideremos el ejemplo de reconocimiento de dígitos. library(readr) digitos_entrena &lt;- read_csv(&#39;datos/zip-train.csv&#39;) digitos_prueba &lt;- read_csv(&#39;datos/zip-test.csv&#39;) names(digitos_entrena)[1] &lt;- &#39;digito&#39; names(digitos_entrena)[2:257] &lt;- paste0(&#39;pixel_&#39;, 1:256) names(digitos_prueba)[1] &lt;- &#39;digito&#39; names(digitos_prueba)[2:257] &lt;- paste0(&#39;pixel_&#39;, 1:256) set.seed(2912) digitos_entrena_s &lt;- sample_n(digitos_entrena, size = 1000) x_e &lt;- digitos_entrena_s %&gt;% select(-digito) %&gt;% as.matrix x_p &lt;- digitos_prueba %&gt;% select(-digito) %&gt;% as.matrix digitos_cv &lt;- cv.glmnet(x = x_e, y = factor(digitos_entrena_s$digito), family = &#39;multinomial&#39;, alpha = 0, parallel = FALSE, nfolds = 5, lambda = exp(seq(-12, 2, 1))) plot(digitos_cv) preds_prueba &lt;- predict(digitos_cv, newx = x_p, s = &#39;lambda.min&#39;)[,,1] # solo un grupo de coeficientes dim(preds_prueba) ## [1] 2007 10 preds_clase &lt;- apply(preds_prueba, 1, which.max) table(preds_clase, digitos_prueba$digito) ## ## preds_clase 0 1 2 3 4 5 6 7 8 9 ## 1 348 0 5 3 3 12 7 1 7 0 ## 2 0 253 0 0 2 0 0 1 1 3 ## 3 3 0 164 3 5 1 3 0 8 1 ## 4 2 3 5 142 0 17 0 2 11 0 ## 5 3 3 7 1 165 2 2 7 4 5 ## 6 0 0 0 10 0 112 5 1 3 1 ## 7 1 3 8 0 6 1 150 0 0 0 ## 8 0 0 3 1 1 0 0 130 1 2 ## 9 1 1 6 4 7 11 3 0 129 1 ## 10 1 1 0 2 11 4 0 5 2 164 mean(preds_clase -1 != digitos_prueba$digito) ## [1] 0.124564 Este modelo mejora considerablemente al modelo sin regularización. Observación: Cuando vimos regresión multinomial, la última clase es uno menos la suma del resto de probabilidades de clase (\\((K-1)(p+1)\\) parámetros). La salida de glmnet, sin embargo, tiene coeficientes para todas las clases (\\(K(p+1)\\) parámetros). ¿Por qué en regresión ridge no está sobreparametrizado el modelo? 4.3 Regularización lasso Otra forma de regularización es el lasso, que en lugar de penalizar con la suma de cuadrados en los coeficientes, penaliza por la suma de su valor absoluto. En regresión lasso (lineal/logística), para \\(\\lambda&gt;0\\) fija minimizamos \\[D_{\\lambda}^2 (\\beta)=D(\\beta) + \\lambda\\sum_{i=1}^p |\\beta_j|\\], donde suponemos que las entradas están estandarizadas (centradas y escaladas por la desviación estándar). El problema de minimización de ridge y de lasso se pueden reescribir como problemas de restricción: En regresión lasso (lineal/logística), para \\(s&gt;0\\) fija minimizamos \\[D(\\beta), \\] sujeto a \\[\\sum_{i=1}^p |\\beta_j|&lt; s\\] donde suponemos que las entradas están estandarizadas (centradas y escaladas por la desviación estándar). En regresión ridge (lineal/logística), para \\(t&gt;0\\) fija minimizamos \\[D(\\beta), \\] sujeto a \\[\\sum_{i=1}^p \\beta_j^2 &lt; t\\] donde suponemos que las entradas están estandarizadas (centradas y escaladas por la desviación estándar). \\(s\\) y \\(t\\) chicas corresponden a valores de penalización \\(\\lambda\\) grandes. En un principio, puede parecer que ridge y lasso deben dar resultados muy similares, pues en ambos casos penalizamos por el tamaño de los coeficientes. Sin embargo, son distintos de una manera muy importante. En la siguiente gráfica regresentamos las curvas de nivel de \\(D(\\beta)\\). Recordemos que en mínimos cuadrados o regresión logística intentamos minimizar esta cantidad sin restricciones, y este mínimo se encuentra en el centro de estas curvas de nivel. Para el problema restringido, buscamos más bien la curva de nivel más baja que intersecta la restricción: knitr::include_graphics(&#39;./imagenes/ridge_lasso.png&#39;) Y obsérvese ahora que la solución de lasso puede hacer algunos coeficientes igual a 0. Es decir, En regresión ridge, los coeficientes se encogen gradualmente desde la solución no restringida hasta el origen. Ridge es un método de encogimiento de coeficientes. En regresión lasso, los coeficientes se encogen gradualmente, pero también se excluyen variables del modelo. Por eso lasso es un método de encogimiento y selección de variables. Regresión ridge es especialmente útil cuando tenemos varias variables de entrada fuertemente correlacionadas. Regresión ridge intenta encoger juntos coeficientes de variables correlacionadas para reducir varianza en las predicciones. Lasso encoge igualmente coeficientes para reducir varianza, pero también comparte similitudes con regresión de mejor subconjunto, en donde para cada número de variables \\(l\\) buscamos escoger las \\(l\\) variables que den el mejor modelo. Sin embargo, el enfoque de lasso es más escalable y puede calcularse de manera más simple. Descenso en gradiente no es apropiado para regresión lasso (ver documentación de glmnet para ver cómo se hace en este paquete). El problema es que los coeficientes nunca se hacen exactamente cero, pues la restricción no es diferenciable en el origen (coeficientes igual a cero). Ejemplo Consideramos el ejemplo de bodyfat: library(readr) dat_grasa &lt;- read_csv(file = &#39;datos/bodyfat.csv&#39;) head(dat_grasa) ## # A tibble: 6 x 14 ## grasacorp edad peso estatura cuello pecho abdomen cadera muslo rodilla ## &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 12.3 23 154. 67.8 36.2 93.1 85.2 94.5 59 37.3 ## 2 6.1 22 173. 72.2 38.5 93.6 83 98.7 58.7 37.3 ## 3 25.3 22 154 66.2 34 95.8 87.9 99.2 59.6 38.9 ## 4 10.4 26 185. 72.2 37.4 102. 86.4 101. 60.1 37.3 ## 5 28.7 24 184. 71.2 34.4 97.3 100 102. 63.2 42.2 ## 6 20.9 24 210. 74.8 39 104. 94.4 108. 66 42 ## # ... with 4 more variables: tobillo &lt;dbl&gt;, biceps &lt;dbl&gt;, antebrazo &lt;dbl&gt;, ## # muñeca &lt;dbl&gt; nrow(dat_grasa) ## [1] 252 set.seed(127) dat_grasa$unif &lt;- runif(nrow(dat_grasa), 0, 1) dat_grasa &lt;- arrange(dat_grasa, unif) dat_grasa$id &lt;- 1:nrow(dat_grasa) dat_e &lt;- dat_grasa[1:150,] dat_p &lt;- dat_grasa[151:252,] x_e &lt;- dat_e %&gt;% select(-grasacorp, -id, -unif) %&gt;% as.matrix x_p &lt;- dat_p %&gt;% select(-grasacorp, -id, -unif) %&gt;% as.matrix mod_bodyfat &lt;- cv.glmnet(x = x_e, y = dat_e$grasacorp, alpha = 1) #alpha=1 para lasso plot(mod_bodyfat) coeficientes &lt;- predict(mod_bodyfat, s =&#39;lambda.1se&#39;, type=&#39;coefficients&#39;) coeficientes ## 14 x 1 sparse Matrix of class &quot;dgCMatrix&quot; ## 1 ## (Intercept) -20.75924245 ## edad 0.05179279 ## peso . ## estatura -0.09936002 ## cuello . ## pecho . ## abdomen 0.58019360 ## cadera . ## muslo . ## rodilla . ## tobillo . ## biceps . ## antebrazo . ## muñeca -0.51756816 pred_prueba &lt;- predict(mod_bodyfat, newx = x_p, s =&#39;lambda.1se&#39;) sqrt(mean((pred_prueba-dat_p$grasacorp)^2)) ## [1] 4.374339 Comparado con regresión lineal: pred_prueba &lt;- predict(lm(grasacorp ~., data = dat_e %&gt;% select(-id, -unif)), newdata=dat_p) sqrt(mean((pred_prueba-dat_p$grasacorp)^2)) ## [1] 4.311924 "],
["descenso-estocastico.html", "Sección 5 Descenso estocástico 5.1 Algoritmo de descenso estocástico 5.2 ¿Por qué usar descenso estocástico por minilotes? 5.3 Escogiendo la tasa de aprendizaje 5.4 Mejoras al algoritmo de descenso estocástico.", " Sección 5 Descenso estocástico En esta sección discutiremos estrategias para ajustar modelos como los que vimos en secciones anteriores. Estos métodos también se utilizarán en el tutorial de redes neuronales más adelante. El algoritmo más popular para ajustar modelos grandes es descenso estocástico, que es una modificación de nuestro algoritmo de descenso en gradiente de las secicones anteriores. Antes de presentar las razones para usarlo, veremos cómo funciona para problemas con regresión lineal o logística. En descenso estocástico (por minilotes), el cálculo del gradiente se hace sobre una submuestra relativamente chica de la muestra de entrenamiento. En este contexto, a esta submuestra se le llama un minilote. En cada iteración, nos movemos en la dirección de descenso para ese minilote. La muestra de entrenamiento se divide entonces (al azar) en minilotes, y recorremos todos los minilotes haciendo una actualización de nuestros parámetros en cada minilote. Un recorrido sobre todos los minilotes se llama una época (las iteraciones se entienden sobre los minilotes). Antes de escribir el algoritmo mostramos una implementación para regresión logística. Usamos las mismas funciones para calcular devianza y gradiente. library(tidyverse) theme_set(theme_bw()) library(plotly) h &lt;- function(x){1/(1+exp(-x))} devianza_calc &lt;- function(x, y){ dev_fun &lt;- function(beta){ p_beta &lt;- h(as.matrix(cbind(1, x)) %*% beta) -2*mean(y*log(p_beta) + (1-y)*log(1-p_beta)) } dev_fun } grad_calc &lt;- function(x_ent, y_ent){ salida_grad &lt;- function(beta){ p_beta &lt;- h(as.matrix(cbind(1, x_ent)) %*% beta) e &lt;- y_ent - p_beta grad_out &lt;- -2*as.numeric(t(cbind(1,x_ent)) %*% e)/nrow(x_ent) names(grad_out) &lt;- c(&#39;Intercept&#39;, colnames(x_ent)) grad_out } salida_grad } Y comparamos la implementación de los dos algoritmos: descenso &lt;- function(n, z_0, eta, h_deriv){ z &lt;- matrix(0,n, length(z_0)) z[1, ] &lt;- z_0 for(i in 1:(n-1)){ z[i+1, ] &lt;- z[i, ] - eta * h_deriv(z[i, ]) } z } # esta implementación es solo para este ejemplo: descenso_estocástico &lt;- function(n_epocas, z_0, eta, minilotes){ #minilotes es una lista m &lt;- length(minilotes) z &lt;- matrix(0, m*n_epocas, length(z_0)) z[1, ] &lt;- z_0 for(i in 1:(m*n_epocas-1)){ k &lt;- i %% m + 1 if(i %% m == 0){ #comenzar nueva época y reordenar minilotes al azar minilotes &lt;- minilotes[sample(1:m, m)] } h_deriv &lt;- grad_calc(minilotes[[k]]$x, minilotes[[k]]$y) z[i+1, ] &lt;- z[i, ] - eta * h_deriv(z[i, ]) } z } Usaremos el ejemplo simulado de regresión para hacer algunos experimentos: p_1 &lt;- function(x){ ifelse(x &lt; 30, 0.9, 0.9 - 0.007 * (x - 15)) } set.seed(143) sim_datos &lt;- function(n){ x &lt;- pmin(rexp(n, 1/30), 100) probs &lt;- p_1(x) g &lt;- rbinom(length(x), 1, probs) # con dos variables de ruido: dat &lt;- data_frame(x_1 = (x - mean(x))/sd(x), x_2 = rnorm(length(x),0,1), x_3 = rnorm(length(x),0,1), p_1 = probs, g ) dat %&gt;% select(x_1, x_2, x_3, g) } dat_ent &lt;- sim_datos(100) dat_valid &lt;- sim_datos(1000) glm(g ~ x_1 + x_2+ x_3 , data = dat_ent, family = &#39;binomial&#39;) %&gt;% coef ## (Intercept) x_1 x_2 x_3 ## 1.8082362 -0.7439627 0.2172971 0.3711973 Hacemos descenso en gradiente: iter_descenso &lt;- descenso(80, rep(0,4), 0.9, h_deriv = grad_calc(x_ent = as.matrix(dat_ent[,c(&#39;x_1&#39;,&#39;x_2&#39;,&#39;x_3&#39;), drop =FALSE]), y_ent=dat_ent$g)) %&gt;% data.frame %&gt;% rename(beta_0 = X1, beta_1 = X2, beta_2 = X3, beta_3 = X4) iter_descenso$tipo &lt;- &quot;descenso&quot; source(&quot;scripts/graficar_traza.R&quot;) graficar_traza(iter_descenso) ## Joining, by = c(&quot;tipo&quot;, &quot;n&quot;) ## Warning in RColorBrewer::brewer.pal(N, &quot;Set2&quot;): minimal value for n is 3, returning requested palette with 3 different levels Y ahora hacemos descenso estocástico. Vamos a hacer minilotes de tamaño 5: dat_ent$minilote &lt;- rep(1:10, each=5) split_ml &lt;- split(dat_ent %&gt;% sample_n(nrow(dat_ent)), dat_ent$minilote) minilotes &lt;- lapply(split_ml, function(dat_ml){ list(x = as.matrix(dat_ml[, c(&#39;x_1&#39;,&#39;x_2&#39;,&#39;x_3&#39;), drop=FALSE]), y = dat_ml$g) }) length(minilotes) ## [1] 10 Ahora iteramos. Nótese cómo descenso en gradiente tiene un patrón aleatorio de avance hacia el mínimo, y una vez que llega a una región oscila alrededor de este mínimo. iter_estocastico &lt;- descenso_estocástico(15, rep(0, 4), 0.1, minilotes) %&gt;% data.frame %&gt;% rename(beta_0 = X1, beta_1 = X2, beta_2 = X3, beta_3 = X4) %&gt;% mutate(tipo =&quot;descenso estocástico&quot;) #veremos más adelante por qué repetimos cada renglón varias veces iter &lt;- bind_rows(iter_descenso, iter_estocastico) graficar_traza(iter) ## Joining, by = c(&quot;tipo&quot;, &quot;n&quot;) ## Warning in RColorBrewer::brewer.pal(N, &quot;Set2&quot;): minimal value for n is 3, returning requested palette with 3 different levels Nótese que cada iteración de descenso en gradiente evalúa el gradiente en 100 casos (los de entrenamiento), mientras que cada iteración de descenso estocástico por minilotes solamente evalúa el gradiente en 5 casos (de modo que es un 5% del trabajo). Ajustando por la cantidad de trabajo: iter_descenso_sub &lt;- iter_descenso[1:10, ] iter_descenso_rep &lt;- iter_descenso_sub[rep(1:nrow(iter_descenso_sub), each = 20),] iter_2 &lt;- bind_rows(iter_descenso_rep, iter_estocastico) graficar_traza(iter_2) ## Joining, by = c(&quot;tipo&quot;, &quot;n&quot;) ## Warning in RColorBrewer::brewer.pal(N, &quot;Set2&quot;): minimal value for n is 3, returning requested palette with 3 different levels Podemos ver cómo se ve la devianza de entrenamiento: dev_ent &lt;- devianza_calc(x = as.matrix(dat_ent[,c(&#39;x_1&#39;,&#39;x_2&#39;,&#39;x_3&#39;), drop =FALSE]), y=dat_ent$g) dev_valid &lt;- devianza_calc(x = as.matrix(dat_valid[,c(&#39;x_1&#39;,&#39;x_2&#39;,&#39;x_3&#39;), drop =FALSE]), y=dat_valid$g) dev_datos &lt;- graficar_devianza(iter, dat_ent, dat_valid) y vemos que descenso estocástico también converge a una buena solución. 5.1 Algoritmo de descenso estocástico Descenso estocástico por minilotes. Separamos al azar los datos de entrenamiento en \\(n\\) minilotes de tamaño \\(m\\). Para épocas \\(e =1,2,\\ldots, n_e\\) Calcular el gradiente sobre el minilote y hacer actualización, sucesivamente para cada uno de los minilotes \\(k=1,2,\\ldots, n/m\\): \\[\\beta_{i+1} = \\beta_{i} - \\eta\\sum_{j=1}^m \\nabla D^{(k)}_j (\\beta_i)\\] donde \\(D^{(k)}_j (\\beta_i)\\) es la devianza para el \\(j\\)-ésimo caso del minilote \\(k\\). Repetir para la siguiente época (opcional: reordenar antes al azar los minibatches, para evitar ciclos). Cuando el minilote es de tamaño 1, este algoritmo se llama simplemente descenso estocástico. 5.2 ¿Por qué usar descenso estocástico por minilotes? Las propiedades importantes de descenso estocástico son: Muchas veces no es necesario usar todos los datos para encontrar una buena dirección de descenso. Podemos ver la dirección de descenso en gradiente como un valor esperado sobre la muestra de entrenamiento (pues la pérdida es un promedio sobre el conjunto de entrenamiento). Una submuestra (minilote) puede ser suficiente para estimar ese valor esperado, con costo menor de cómputo. Adicionalmente, quizá no es tan buena idea intentar estimar el gradiente con la mejor precisión pues es solamente una dirección de descenso local (así que quizá no da la mejor decisión de a dónde moverse en cada punto). Es mejor hacer iteraciones más rápidas con direcciones estimadas. Desde este punto de vista, calcular el gradiente completo para descenso en gradiente es computacionalmente ineficiente. Si el conjunto de entrenamiento es masivo, descenso en gradiente no es factible. ¿Cuál es el mejor tamaño de minilote? Por un lado, minilotes más grandes nos dan mejores eficiencias en paralelización (multiplicación de matrices), especialmente en GPUs. Por otro lado, con minilotes más grandes puede ser que hagamos trabajo de más, por las razones expuestas en los incisos anteriores, y tengamos menos iteraciones en el mismo tiempo. El mejor punto está entre minilotes demasiado chicos (no aprovechamos paralelismo) o demasiado grande (hacemos demasiado trabajo por iteración). 4.La propiedad más importante de descenso estocástico en minilotes es entonces que su convergencia no depende del tamaño del conjunto de entrenamiento, es decir, el tiempo de iteración para descenso estocástico no crece con el número de casos totales. Podemos tener obtener buenos ajustes incluso con tamaños muy grandes de conjuntos de entrenamiento (por ejemplo, antes de procesar todos los datos de entrenamiento). Descenso estocástico escala bien en este sentido: el factor limitante es el tamaño de minilote y el número de iteraciones. Es importante permutar al azar los datos antes de hacer los minilotes, pues órdenes naturales en los datos pueden afectar la convergencia. Se ha observado también que permutar los minibatches en cada iteración típicamente acelera la convergencia (si se pueden tener los datos en memoria). Ejemplo En el ejemplo anterior nota que las direcciones de descenso de descenso estocástico son muy razonables (punto 1). Nota también que obtenemos una buena aproximación a la solución con menos cómputo (punto 2 - mismo número de iteraciones, pero cada iteración con un minilote). ggplot(filter(dev_datos, iteracion &gt;= 2), aes(x=iteracion, y=devianza, colour=tipo)) + geom_line() + geom_point(size=0.5)+ facet_wrap(~muestra, ncol=1) 5.3 Escogiendo la tasa de aprendizaje Para escoger la tasa, monitoreamos las curvas de error de entrenamiento y de validación. Si la tasa es muy grande, habrá oscilaciones grandes y muchas veces incrementos grandes en la función objectivo (error de entrenamiento). Algunas oscilaciones suaves no tienen problema -es la naturaleza estocástica del algoritmo. Si la tasa es muy baja, el aprendizaje es lento y podemos quedarnos en un valor demasiado alto. Conviene monitorear las primeras iteraciones y escoger una tasa más alta que la mejor que tengamos acutalmente, pero no tan alta que cause inestabilidad. Una gráfica como la siguiente es útil. En este ejemplo, incluso podríamos detenernos antes para evitar el sobreajuste de la última parte de las iteraciones: ggplot(filter(dev_datos, tipo==&#39;descenso estocástico&#39;), aes(x=iteracion, y=devianza, colour=muestra)) + geom_line() + geom_point() Por ejemplo: tasa demasiado alta: iter_estocastico &lt;- descenso_estocástico(20, rep(0,4), 0.95, minilotes) %&gt;% data.frame %&gt;% rename(beta_0 = X1, beta_1 = X2, beta_2=X3, beta_3=X4) %&gt;% mutate(tipo = &quot;descenso estocástico&quot;) iter &lt;- bind_rows(iter_descenso, iter_estocastico) dev_datos &lt;- graficar_devianza(iter, dat_ent, dat_valid) Tasa demasiado chica ( o hacer más iteraciones): iter_estocastico &lt;- descenso_estocástico(20, rep(0,4), 0.01, minilotes) %&gt;% data.frame %&gt;% rename(beta_0 = X1, beta_1 = X2, beta_2=X3, beta_3=X4) %&gt;% mutate(tipo = &quot;descenso estocástico&quot;) iter &lt;- bind_rows(iter_descenso, iter_estocastico) dev_datos &lt;- graficar_devianza(iter, dat_ent, dat_valid) Para redes neuronales, es importante explorar distintas tasas de aprendizaje, aún cuando no parezca haber oscilaciones grandes o convergencia muy lenta. En algunos casos, si la tasa es demasiado grande, puede ser que el algoritmo llegue a lugares con gradientes cercanos a cero (por ejemplo, por activaciones demasiado grandes) y tenga dificultad para moverse. 5.4 Mejoras al algoritmo de descenso estocástico. 5.4.1 Decaimiento de tasa de aprendizaje Hay muchos algoritmos derivados de descenso estocástico. La primera mejora consiste en reducir gradualmente la tasa de aprendizaje para aprender rápido al principio, pero filtrar el ruido de la estimación de minilotes más adelante en las iteraciones y permitir que el algoritmo se asiente en un mínimo. descenso_estocástico &lt;- function(n_epocas, z_0, eta, minilotes, decaimiento = 0.0){ #minilotes es una lista m &lt;- length(minilotes) z &lt;- matrix(0, m*n_epocas, length(z_0)) z[1, ] &lt;- z_0 for(i in 1:(m*n_epocas-1)){ k &lt;- i %% m + 1 if(i %% m == 0){ #comenzar nueva época y reordenar minilotes al azar minilotes &lt;- minilotes[sample(1:m, m)] } h_deriv &lt;- grad_calc(minilotes[[k]]$x, minilotes[[k]]$y) z[i+1, ] &lt;- z[i, ] - eta * h_deriv(z[i, ]) eta &lt;- eta*(1/(1+decaimiento*i)) } z } Y ahora vemos qué pasa con decaimiento: iter_estocastico &lt;- descenso_estocástico(20, c(0,0, 0, 0), 0.3, minilotes, decaimiento = 0.0005) %&gt;% data.frame %&gt;% rename(beta_0 = X1, beta_1 = X2, beta_2 = X3, beta_3 = X4) %&gt;% mutate(tipo = &quot;descenso estocástico&quot;) iter &lt;- bind_rows(iter_descenso, iter_estocastico) dev_datos &lt;- graficar_devianza(iter, dat_ent, dat_valid) graficar_traza(iter) ## Joining, by = c(&quot;tipo&quot;, &quot;n&quot;) ## Warning in RColorBrewer::brewer.pal(N, &quot;Set2&quot;): minimal value for n is 3, returning requested palette with 3 different levels La tasa de aprendizaje es uno de los parámetros en redes neuronales más importantes de afinar. Generalmente se empieza con una tasa de aprendizaje con un valor bajo (0.01, o. 0.1), pero es necesario experimentar. Un valor muy alto puede provocar oscilaciones muy fuertes en la pérdida Un valor alto también puede provocar que el algoritmo se detenga en lugar con función pérdida alta (sobreajusta rápidamente). Un valor demasiado bajo produce convergencia lenta. 5.4.2 Momento También es posible utilizar una idea adicional que acelera la convergencia. La idea es que muchas veces la aleatoriedad del algoritmo puede producir iteraciones en direcciones que no son tan buenas (pues la estimación del gradiente es mala). Esto es parte del algoritmo. Sin embargo, si en varias iteraciones hemos observado movimientos en direcciones consistentes, quizá deberíamos movernos en esas direcciones consistentes, y reducir el peso de la dirección del minilote (que nos puede llevar en una dirección mala). El resultado es un suavizamiento de las curvas de aprendizaje. Esto es similar al movimiento de una canica en una superficie: la dirección de su movimiento está dada en parte por la dirección de descenso (el gradiente) y en parte la velocidad actual de la canica. La canica se mueve en un promedio de estas dos direcciones Descenso estocástico con momento Separamos al azar los datos de entrenamiento en \\(n\\) minilotes de tamaño \\(m\\). Para épocas \\(e =1,2,\\ldots, n_e\\) Calcular el gradiente sobre el minilote y hacer actualización, sucesivamente para cada uno de los minilotes \\(k=1,2,\\ldots, n/m\\): \\[\\beta_{i+1} = \\beta_{i} + v,\\] \\[v= \\alpha v - \\eta\\sum_{j=1}^m \\nabla D^{(k)}_j\\] donde \\(D^{(k)}_j (\\beta_i)\\) es la devianza para el \\(j\\)-ésimo caso del minilote \\(k\\). A \\(v\\) se llama la velocidad Repetir para la siguiente época descenso_estocástico &lt;- function(n_epocas, z_0, eta, minilotes, momento = 0.0, decaimiento = 0.0){ #minilotes es una lista m &lt;- length(minilotes) z &lt;- matrix(0, m*n_epocas, length(z_0)) z[1, ] &lt;- z_0 v &lt;- 0 for(i in 1:(m*n_epocas-1)){ k &lt;- i %% m + 1 if(i %% m == 0){ #comenzar nueva época y reordenar minilotes al azar minilotes &lt;- minilotes[sample(1:m, m)] v &lt;- 0 } h_deriv &lt;- grad_calc(minilotes[[k]]$x, minilotes[[k]]$y) z[i+1, ] &lt;- z[i, ] + v v &lt;- momento*v - eta * h_deriv(z[i, ]) eta &lt;- eta*(1/(1+decaimiento*i)) } z } Y ahora vemos que usando momento el algoritmo es más parecido a descenso en gradiente usual (pues tenemos cierta memoria de direcciones anteriores de descenso): set.seed(231) iter_estocastico &lt;- descenso_estocástico(15, c(0,0, 0, 0), 0.2, minilotes, momento = 0.7, decaimiento = 0.001) %&gt;% data.frame %&gt;% rename(beta_0 = X1, beta_1 = X2, beta_2 = X3, beta_3 = X4) %&gt;% mutate(tipo = &quot;descenso estocástico + momento&quot;) iter_momento &lt;- bind_rows(iter_descenso, iter_estocastico) dev_datos &lt;- graficar_devianza(iter_momento, dat_ent, dat_valid) graficar_traza(iter_momento) ## Joining, by = c(&quot;tipo&quot;, &quot;n&quot;) ## Warning in RColorBrewer::brewer.pal(N, &quot;Set2&quot;): minimal value for n is 3, returning requested palette with 3 different levels Nótese cómo llegamos más rápido a una buena solución (comparado con el ejemplo sin momento). Adicionalmente, error de entrenamiento y validación lucen más suaves, producto de promediar velocidades a lo largo de iteraciones. Valores típicos para momento son 0,0.5,0.9 o 0.99. 5.4.3 Otras variaciones Otras variaciones incluyen usar una tasa adaptativa de aprendizaje por cada parámetro (algoritmos adagrad, rmsprop, adam y adamax), o actualizaciones un poco diferentes (nesterov). Los más comunes son descenso estocástico, descenso estocástico con momento, rmsprop y adam (Capítulo 8 del Deep Learning Book, (???)). "],
["diagnostico-y-mejora-de-modelos.html", "Sección 6 Diagnóstico y mejora de modelos 6.1 Aspectos generales 6.2 ¿Qué hacer cuando el desempeño no es satisfactorio? 6.3 Pipeline de procesamiento 6.4 Diagnósticos: sesgo y varianza 6.5 Refinando el pipeline 6.6 Consiguiendo más datos 6.7 Usar datos adicionales 6.8 Examen de modelo y Análisis de errores", " Sección 6 Diagnóstico y mejora de modelos 6.1 Aspectos generales Al comenzar un proyecto de machine learning, las primeras consideraciones deben ser: Establecer métricas de error apropiadas para el problema, y cuál es el máximo valor de este error requerido para nuestra aplicación. Construir un pipeline lo antes posible que vaya de datos hasta medición de calidad de los modelos. Este pipeline deberá, al menos, incluir cálculos de entradas, medición de desempeño de los modelos y cálculos de otros diagnósticos (como error de entrenamiento, convergencia de algoritmos, etc.) En general, es difícil preveer exactamente qué va a funcionar para un problema particular, y los diagnósticos que veremos requieren de haber ajustado modelos. Nuestra primera recomendación para ir hacia un modelo de mejor desempeño es: Es mejor y más rápido comenzar rápido, aún con un modelo simple, con entradas {} (no muy refinadas), y con los datos que tenemos a mano. De esta forma podemos aprender más rápido. Demasiado tiempo pensando, discutiendo, o diseñando qué algoritmo deberíamos usar, cómo deberíamos construir las entradas, etc. es muchas veces tiempo perdido. Con el pipeline establecido, si el resultado no es satisfactorio, entonces tenemos que tomar decisiones para mejorar. 6.2 ¿Qué hacer cuando el desempeño no es satisfactorio? Supongamos que tenemos un clasificador construido con regresión logística regularizada, y que cuando lo aplicamos a nuestra muestra de prueba el desempeño es malo. ¿Qué hacer? Algunas opciones: Conseguir más datos de entrenamiento. Reducir el número de entradas por algún método (eliminación manual, componentes principales, etc.) Construir más entradas utilizando distintos enfoques o fuentes de datos. Incluir variables derivadas adicionales e interacciones. Intentar construir una red neuronal para predecir (otro método). Aumentar la regularización. Disminuir la regularización. Correr más tiempo el algoritmo de ajuste. ¿Con cuál empezar? Cada una de estas estrategias intenta arreglar distintos problemas. En lugar de intentar al azar distintas cosas, que consumen tiempo y dinero y no necesariamente nos van a llevar a mejoras, a continuación veremos diagnósticos y recetas que nos sugieren la mejor manera de usar nuestro tiempo para mejorar nuestros modelos. Usaremos el siguiente ejemplo para ilustrar los conceptos: Ejemplo Nos interesa hacer una predicción de polaridad de críticas o comentarios de pelíıculas: buscamos clasificar una reseña como positiva o negativa dependiendo de su contenido. Tenemos dos grupos de reseñas separadas en positivas y negativas (estos datos fueron etiquetados por una persona). Cada reseña está un archivo de texto, y tenemos 1000 de cada tipo: negativos &lt;- list.files(&#39;./datos/sentiment/neg&#39;, full.names = TRUE) positivos &lt;- list.files(&#39;./datos/sentiment/pos&#39;, full.names = TRUE) head(negativos) ## [1] &quot;./datos/sentiment/neg/cv000_29416.txt&quot; ## [2] &quot;./datos/sentiment/neg/cv001_19502.txt&quot; ## [3] &quot;./datos/sentiment/neg/cv002_17424.txt&quot; ## [4] &quot;./datos/sentiment/neg/cv003_12683.txt&quot; ## [5] &quot;./datos/sentiment/neg/cv004_12641.txt&quot; ## [6] &quot;./datos/sentiment/neg/cv005_29357.txt&quot; head(positivos) ## [1] &quot;./datos/sentiment/pos/cv000_29590.txt&quot; ## [2] &quot;./datos/sentiment/pos/cv001_18431.txt&quot; ## [3] &quot;./datos/sentiment/pos/cv002_15918.txt&quot; ## [4] &quot;./datos/sentiment/pos/cv003_11664.txt&quot; ## [5] &quot;./datos/sentiment/pos/cv004_11636.txt&quot; ## [6] &quot;./datos/sentiment/pos/cv005_29443.txt&quot; length(negativos) ## [1] 1000 length(positivos) ## [1] 1000 read_file(negativos[1]) [1] “plot : two teen couples go to a church party , drink and then drive . get into an accident . of the guys dies , but his girlfriend continues to see him in her life , and has nightmares . ’s the deal ? the movie and &quot; sorta &quot; find out . . . : a mind-fuck movie for the teen generation that touches on a very cool idea , but presents it in a very bad package . is what makes this review an even harder one to write , since i generally applaud films which attempt to break the mold , mess with your head and such ( lost highway &amp; memento ) , but there are good and bad ways of making all types of films , and these folks just didn’t snag this one correctly . seem to have taken this pretty neat concept , but executed it terribly . what are the problems with the movie ? , its main problem is that it’s simply too jumbled . starts off &quot; normal &quot; but then downshifts into this &quot; fantasy &quot; world in which you , as an audience member , have no idea what’s going on . are dreams , there are characters coming back from the dead , there are others who look like the dead , there are strange apparitions , there are disappearances , there are a looooot of chase scenes , there are tons of weird things that happen , and most of it is simply not explained . i personally don’t mind trying to unravel a film every now and then , but when all it does is give me the same clue over and over again , i get kind of fed up after a while , which is this film’s biggest problem . ’s obviously got this big secret to hide , but it seems to want to hide it completely until its final five minutes . do they make things entertaining , thrilling or even engaging , in the meantime ? really . sad part is that the arrow and i both dig on flicks like this , so we actually figured most of it out by the half-way point , so all of the strangeness after that did start to make a little bit of sense , but it still didn’t the make the film all that more entertaining . guess the bottom line with movies like this is that you should always make sure that the audience is &quot; into it &quot; even before they are given the secret password to enter your world of understanding . mean , showing melissa sagemiller running away from visions for about 20 minutes throughout the movie is just plain lazy ! ! , we get it . . . there people chasing her and we don’t know who they are . we really need to see it over and over again ? about giving us different scenes offering further insight into all of the strangeness going down in the movie ? , the studio took this film away from its director and chopped it up themselves , and it shows . might’ve been a pretty decent teen mind-fuck movie in here somewhere , but i guess &quot; the suits &quot; decided that turning it into a music video with little edge , would make more sense . actors are pretty good for the most part , although wes bentley just seemed to be playing the exact same character that he did in american beauty , only in a new neighborhood . my biggest kudos go out to sagemiller , who holds her own throughout the entire film , and actually has you feeling her character’s unraveling . , the film doesn’t stick because it doesn’t entertain , it’s confusing , it rarely excites and it feels pretty redundant for most of its runtime , despite a pretty cool ending and explanation to all of the craziness that came before it . , and by the way , this is not a horror or teen slasher flick . . . it’s packaged to look that way because someone is apparently assuming that the genre is still hot with the kids . also wrapped production two years ago and has been sitting on the shelves ever since . . . . skip ! ’s joblo coming from ? nightmare of elm street 3 ( 7/10 ) - blair witch 2 ( 7/10 ) - the crow ( 9/10 ) - the crow : salvation ( 4/10 ) - lost highway ( 10/10 ) - memento ( 10/10 ) - the others ( 9/10 ) - stir of echoes ( 8/10 ) ” read_file(positivos[1]) [1] “films adapted from comic books have had plenty of success , whether they’re about superheroes ( batman , superman , spawn ) , or geared toward kids ( casper ) or the arthouse crowd ( ghost world ) , but there’s never really been a comic book like from hell before . starters , it was created by alan moore ( and eddie campbell ) , who brought the medium to a whole new level in the mid ‘80s with a 12-part series called the watchmen . say moore and campbell thoroughly researched the subject of jack the ripper would be like saying michael jackson is starting to look a little odd . book ( or &quot; graphic novel , &quot; if you will ) is over 500 pages long and includes nearly 30 more that consist of nothing but footnotes . other words , don’t dismiss this film because of its source . you can get past the whole comic book thing , you might find another stumbling block in from hell’s directors , albert and allen hughes . the hughes brothers to direct this seems almost as ludicrous as casting carrot top in , well , anything , but riddle me this : who better to direct a film that’s set in the ghetto and features really violent street crime than the mad geniuses behind menace ii society ? ghetto in question is , of course , whitechapel in 1888 london’s east end . ’s a filthy , sooty place where the whores ( called &quot; unfortunates &quot; ) are starting to get a little nervous about this mysterious psychopath who has been carving through their profession with surgical precision . the first stiff turns up , copper peter godley ( robbie coltrane , the world is not enough ) calls in inspector frederick abberline ( johnny depp , blow ) to crack the case . , a widower , has prophetic dreams he unsuccessfully tries to quell with copious amounts of absinthe and opium . arriving in whitechapel , he befriends an unfortunate named mary kelly ( heather graham , say it isn’t so ) and proceeds to investigate the horribly gruesome crimes that even the police surgeon can’t stomach . don’t think anyone needs to be briefed on jack the ripper , so i won’t go into the particulars here , other than to say moore and campbell have a unique and interesting theory about both the identity of the killer and the reasons he chooses to slay . the comic , they don’t bother cloaking the identity of the ripper , but screenwriters terry hayes ( vertical limit ) and rafael yglesias ( les mis ? rables ) do a good job of keeping him hidden from viewers until the very end . ’s funny to watch the locals blindly point the finger of blame at jews and indians because , after all , an englishman could never be capable of committing such ghastly acts . from hell’s ending had me whistling the stonecutters song from the simpsons for days ( &quot; who holds back the electric car/who made steve guttenberg a star ? &quot; ) . ’t worry - it’ll all make sense when you see it . onto from hell’s appearance : it’s certainly dark and bleak enough , and it’s surprising to see how much more it looks like a tim burton film than planet of the apes did ( at times , it seems like sleepy hollow 2 ) . print i saw wasn’t completely finished ( both color and music had not been finalized , so no comments about marilyn manson ) , but cinematographer peter deming ( don’t say a word ) ably captures the dreariness of victorian-era london and helped make the flashy killing scenes remind me of the crazy flashbacks in twin peaks , even though the violence in the film pales in comparison to that in the black-and-white comic . winner martin childs’ ( shakespeare in love ) production design turns the original prague surroundings into one creepy place . the acting in from hell is solid , with the dreamy depp turning in a typically strong performance and deftly handling a british accent . holm ( joe gould’s secret ) and richardson ( 102 dalmatians ) log in great supporting roles , but the big surprise here is graham . cringed the first time she opened her mouth , imagining her attempt at an irish accent , but it actually wasn’t half bad . film , however , is all good . 2 : 00 - r for strong violence/gore , sexuality , language and drug content ” Consideremos primero la métrica de error, que depende de nuestra aplicación. En este caso, quisiéramos hacer dar una calificación a cada película basada en el % de reseñas positivas que tiene. Supongamos que se ha decidido que necesitamos al menos una tasa de correctos de 90% para que el score sea confiable (cómo calcularías algo así?). Ahora necesitamos construir un pipeline para obtener las primeras predicciones. Tenemos que pensar qué entradas podríamos construir. 6.3 Pipeline de procesamiento Empezamos por construir funciones para leer datos (ver script). Construimos un data frame: source(&#39;./scripts/funciones_sentiment.R&#39;) df &lt;- prep_df(&#39;./datos/sentiment/&#39;) %&gt;% unnest(texto) nrow(df) [1] 2000 str_sub(df$texto[1], 1, 200) [1] “Review films adapted from comic books have had plenty of success , whether they’re about superheroes ( batman , superman , spawn ) , or geared toward kids ( casper ) or the arthouse crowd ( ghost wor” Ahora separamos una muestra de prueba (y una de entrenamiento más chica para simular después el proceso de recoger más datos): set.seed(94512) df$muestra &lt;- sample(c(&#39;entrena&#39;, &#39;prueba&#39;), 2000, prob = c(0.8, 0.2), replace = TRUE) table(df$muestra) ## ## entrena prueba ## 1575 425 df_ent &lt;- df %&gt;% filter(muestra == &#39;entrena&#39;) df_pr &lt;- df %&gt;% filter(muestra == &#39;prueba&#39;) df_ent &lt;- sample_n(df_ent, nrow(df_ent)) #permutamos al azar df_ent_grande &lt;- df_ent df_ent &lt;- df_ent %&gt;% sample_n(700) Intentemos algo simple para empezar: consideramos qué palabras contiene cada reseña, e intentamos clasificar en base esas palabras. Así que en primer lugar dividimos cada texto en tokens (pueden ser palabras, o sucesiones de caracteres o de palabras de tamaño fijo (n-gramas), oraciones, etc.). En este caso, usamos el paquete tidytext. La función unnest_tokens elimina signos de puntuación, convierte todo a minúsculas, y separa las palabras: Vamos a calcular los tokens y ordernarlos por frecuencia. Empezamos calculando nuestro vocabulario. Supongamos que usamos las 50 palabras más comunes, y usamos poca regularización: vocabulario &lt;- calc_vocabulario(df_ent, 50) head(vocabulario) ## # A tibble: 6 x 2 ## palabra frec ## &lt;chr&gt; &lt;int&gt; ## 1 a 12904 ## 2 about 1228 ## 3 all 1464 ## 4 an 2000 ## 5 and 12173 ## 6 are 2359 tail(vocabulario) ## # A tibble: 6 x 2 ## palabra frec ## &lt;chr&gt; &lt;int&gt; ## 1 what 1006 ## 2 when 1091 ## 3 which 1153 ## 4 who 1870 ## 5 with 3705 ## 6 you 1565 Todas las etapas de preprocesamiento deben hacerse en función de los datos de entrenamiento. En este ejemplo, podríamos cometer el error de usar todos los datos para calcular el vocabulario. Nuestras entradas aquí no se ven muy buenas: los términos más comunes son en su mayoría palabras sin significado, de modo que no esperamos un desempeño muy bueno. En este momento no nos preocupamos mucho por eso, queremos correr los primeros modelos. library(glmnet) mod_x &lt;- correr_modelo(df_ent, df_pr, vocabulario, lambda = 1e-1) ## [1] &quot;Error entrenamiento: 0.31&quot; ## [1] &quot;Error prueba: 0.36&quot; ## [1] &quot;Devianza entrena:1.148&quot; ## [1] &quot;Devianza prueba:1.271&quot; 6.4 Diagnósticos: sesgo y varianza Y notamos que El error de entrenamiento no es satisfactorio: está muy por arriba de nuestro objetivo (10%) Hay algo de brecha entre entrenamiento y prueba, de modo que disminuir varianza puede ayudar. ¿Qué hacer? Nuestro clasificador ni siquiera puede clasificar bien la muestra de entrenamiento, lo que implica que nuestro modelo tiene sesgo demasiado alto. Controlar la varianza no nos va a ayudar a resolver nuestro problema en este punto. Podemos intentar un modelo más flexible. Error de entrenamiento demasiado alto indica que necesitamos probar con modelos más flexibles (disminuir el sesgo). Para disminuir el sesgo podemos: Expander el vocabulario (agregar más entradas) Crear nuevas entradas a partir de los datos (más informativas) Usar un método más flexible (como redes neuronales) Regularizar menos Cosas que no van a funcionar (puede bajar un poco el error de validación, pero el error de entrenamiento es muy alto): Conseguir más datos de entrenamiento (el error de entrenamiento va a subir, y el de validación va a quedar muy arriba, aunque disminuya) Regularizar más (misma razón) Usar un vocabulario más chico, eliminar entradas (misma razón) Por ejemplo, si juntáramos más datos de entrenamiento (con el costo que esto implica), obtendríamos: mod_x &lt;- correr_modelo(df_ent_grande, df_pr, vocabulario, lambda = 1e-1) ## [1] &quot;Error entrenamiento: 0.31&quot; ## [1] &quot;Error prueba: 0.35&quot; ## [1] &quot;Devianza entrena:1.187&quot; ## [1] &quot;Devianza prueba:1.246&quot; Vemos que aunque bajó ligeramente el error de prueba, el error es demasiado alto. Esta estrategia no funcionó con este modelo, y hubiéramos perdido tiempo y dinero (por duplicar el tamaño de muestra) sin obtener mejoras apreciables. Observación: el error de entrenamiento subió. ¿Puedes explicar eso? Esto sucede porque típicamente el error para cada caso individual de la muestra original sube, pues la optimización se hace sobre más casos. Es más difícil ajustar los datos de entrenamiento cuando tenemos más datos. En lugar de eso, podemos comenzar quitando regularización, por ejemplo mod_x &lt;- correr_modelo(df_ent, df_pr, vocabulario, lambda =1e-10) ## [1] &quot;Error entrenamiento: 0.29&quot; ## [1] &quot;Error prueba: 0.37&quot; ## [1] &quot;Devianza entrena:1.099&quot; ## [1] &quot;Devianza prueba:1.32&quot; Y notamos que reducimos un poco el sesgo. Por el momento, seguiremos intentando reducir sesgo. Podemos ahora incluir más variables vocabulario &lt;- calc_vocabulario(df_ent, 3000) mod_x &lt;- correr_modelo(df_ent, df_pr, vocabulario, lambda=1e-10) ## [1] &quot;Error entrenamiento: 0&quot; ## [1] &quot;Error prueba: 0.38&quot; ## [1] &quot;Devianza entrena:0&quot; ## [1] &quot;Devianza prueba:7.66&quot; El sesgo ya no parece ser un problema: Ahora tenemos un problema de varianza. Una brecha grande entre entrenamiento y validación muchas veces indica sobreajuste (el problema es varianza). Podemos regularizar más: mod_x &lt;- correr_modelo(df_ent, df_pr, vocabulario, lambda=1e-5) ## [1] &quot;Error entrenamiento: 0&quot; ## [1] &quot;Error prueba: 0.2&quot; ## [1] &quot;Devianza entrena:0&quot; ## [1] &quot;Devianza prueba:1.387&quot; mod_x &lt;- correr_modelo(df_ent, df_pr, vocabulario, lambda=0.01) ## [1] &quot;Error entrenamiento: 0&quot; ## [1] &quot;Error prueba: 0.18&quot; ## [1] &quot;Devianza entrena:0.021&quot; ## [1] &quot;Devianza prueba:0.797&quot; Y logramos reducir considerablemente el error y devianza de prueba. 6.5 Refinando el pipeline Refinar el pipeline para producir mejores entradas, o corridas más rápidas, generalmente es una buena inversión de tiempo (aunque es mejor no hacerlo prematuramente). El error de entrenamiento es satisfactorio todavía, y nos estamos acercando a nuestro objetivo (intenta regularizar más para verificar que el problema ahora es sesgo). En este punto, podemos intentar reducir varianza (reducir error de prueba con algún incremento en error de entrenamiento). Buscar más casos de entrenamiento: si son baratos, esto podría ayudar (aumentar al doble o 10 veces más). Redefinir entradas más informativas, para reducir el número de variables pero al mismo tiempo no aumentar el sesgo. Intentaremos por el momento el segundo camino (reducción de varianza). Podemos intentar tres cosas: Eliminar los términos que son demasiado frecuentes (son palabras no informativas, como the, a, he, she, etc.). Esto podría reducir varianza sin afectar mucho el sesgo. Usar raíces de palabras en lugar de palabras (por ejemplo, transfomar defect, defects, defective -&gt; defect y boring,bored, bore -&gt; bore, etc.). De esta manera, controlamos la proliferación de entradas que indican lo mismo y aumentan varianza - y quizá el sesgo no aumente mucho. Intentar usar bigramas - esto reduce el sesgo, pero quizá la varianza no aumente mucho. data(&quot;stop_words&quot;) head(stop_words) ## # A tibble: 6 x 2 ## word lexicon ## &lt;chr&gt; &lt;chr&gt; ## 1 a SMART ## 2 a&#39;s SMART ## 3 able SMART ## 4 about SMART ## 5 above SMART ## 6 according SMART head(calc_vocabulario(df_ent, 100)) ## # A tibble: 6 x 2 ## palabra frec ## &lt;chr&gt; &lt;int&gt; ## 1 a 12904 ## 2 about 1228 ## 3 after 569 ## 4 all 1464 ## 5 also 704 ## 6 an 2000 head(calc_vocabulario(df_ent, 100, remove_stop = TRUE)) ## # A tibble: 6 x 2 ## palabra frec ## &lt;chr&gt; &lt;int&gt; ## 1 2 179 ## 2 acting 224 ## 3 action 418 ## 4 actor 165 ## 5 actors 256 ## 6 american 193 vocabulario &lt;- calc_vocabulario(df_ent, 2000, remove_stop = TRUE) head(vocabulario %&gt;% arrange(desc(frec)),20) ## # A tibble: 20 x 2 ## palabra frec ## &lt;chr&gt; &lt;int&gt; ## 1 film 2991 ## 2 movie 1844 ## 3 time 797 ## 4 review 788 ## 5 story 749 ## 6 character 639 ## 7 characters 631 ## 8 life 527 ## 9 films 515 ## 10 plot 490 ## 11 bad 484 ## 12 people 484 ## 13 scene 482 ## 14 movies 455 ## 15 scenes 443 ## 16 action 418 ## 17 director 413 ## 18 love 393 ## 19 real 329 ## 20 world 323 tail(vocabulario %&gt;% arrange(desc(frec)),20) ## # A tibble: 20 x 2 ## palabra frec ## &lt;chr&gt; &lt;int&gt; ## 1 shock 18 ## 2 sir 18 ## 3 sleep 18 ## 4 sole 18 ## 5 spot 18 ## 6 stays 18 ## 7 stereotypical 18 ## 8 strip 18 ## 9 supergirl 18 ## 10 taylor 18 ## 11 threat 18 ## 12 thrillers 18 ## 13 tradition 18 ## 14 tree 18 ## 15 trial 18 ## 16 trio 18 ## 17 triumph 18 ## 18 visit 18 ## 19 warning 18 ## 20 werewolf 18 Este vocabulario parece que puede ser más útil. Vamos a tener que ajustar la regularización de nuevo (y también el número de entradas). Usaremos ahora validación cruzada para seleccionar modelos. Nota: este proceso también lo podemos hacer con cv.glmnet de manera más rápida. mod_x &lt;- correr_modelo_cv(df_ent, df_pr, vocabulario, lambda = exp(seq(-10,5,0.1))) saveRDS(mod_x, file = &#39;./cache_obj/mod_sentiment_1.rds&#39;) describir_modelo_cv(mod_x) ## [1] &quot;Lambda min: 0.201896517994655&quot; ## [1] &quot;Error entrenamiento: 0&quot; ## [1] &quot;Error prueba: 0.21&quot; ## [1] &quot;Devianza entrena:0.261&quot; ## [1] &quot;Devianza prueba:0.879&quot; No estamos mejorando. Podemos intentar con un número diferente de entradas: vocabulario &lt;- calc_vocabulario(df_ent, 4000, remove_stop = TRUE) mod_x &lt;- correr_modelo_cv(df_ent, df_pr, vocabulario, lambda = exp(seq(-10,5,0.1))) saveRDS(mod_x, file = &#39;./cache_obj/mod_sentiment_2.rds&#39;) describir_modelo_cv(mod_x) ## [1] &quot;Lambda min: 0.49658530379141&quot; ## [1] &quot;Error entrenamiento: 0&quot; ## [1] &quot;Error prueba: 0.18&quot; ## [1] &quot;Devianza entrena:0.295&quot; ## [1] &quot;Devianza prueba:0.883&quot; Y parece que nuestra estrategia no está funcionando muy bien. Regresamos a nuestro modelo con ridge vocabulario &lt;- calc_vocabulario(df_ent, 3000, remove_stop = FALSE) mod_x &lt;- correr_modelo_cv(df_ent, df_pr, vocabulario, lambda = exp(seq(-5,2,0.1))) saveRDS(mod_x, file = &#39;./cache_obj/mod_sentiment_3.rds&#39;) describir_modelo_cv(mod_x) ## [1] &quot;Lambda min: 0.110803158362334&quot; ## [1] &quot;Error entrenamiento: 0&quot; ## [1] &quot;Error prueba: 0.18&quot; ## [1] &quot;Devianza entrena:0.128&quot; ## [1] &quot;Devianza prueba:0.775&quot; Podemos intentar aumentar el número de palabras y aumentar también la regularización vocabulario &lt;- calc_vocabulario(df_ent, 4000, remove_stop = FALSE) mod_x &lt;- correr_modelo_cv(df_ent, df_pr, vocabulario, lambda = exp(seq(-5,2,0.1))) saveRDS(mod_x, file = &#39;./cache_obj/mod_sentiment_4.rds&#39;) describir_modelo_cv(mod_x) ## [1] &quot;Lambda min: 0.22313016014843&quot; ## [1] &quot;Error entrenamiento: 0&quot; ## [1] &quot;Error prueba: 0.16&quot; ## [1] &quot;Devianza entrena:0.173&quot; ## [1] &quot;Devianza prueba:0.776&quot; 6.6 Consiguiendo más datos Si nuestro problema es varianza, conseguir más datos de entrenamiento puede ayudarnos, especialmente si producir estos datos es relativamente barato y rápido. Como nuestro principal problema es varianza, podemos mejorar buscando más datos. Supongamos que hacemos eso en este caso, conseguimos el doble casos de entrenamiento. En este ejemplo, podríamos etiquetar más reviews: esto es relativamente barato y rápido vocabulario &lt;- calc_vocabulario(df_ent_grande, 3000, remove_stop = FALSE) mod_x &lt;- correr_modelo_cv(df_ent_grande, df_pr, vocabulario, lambda = exp(seq(-5,2,0.1))) ## Joining, by = &quot;palabra&quot; ## Joining, by = &quot;palabra&quot; ## Warning: Trying to compute distinct() for variables not found in the data: ## - `row_col`, `column_col` ## This is an error, but only a warning is raised for compatibility reasons. ## The operation will return the input unchanged. ## Warning: Trying to compute distinct() for variables not found in the data: ## - `row_col`, `column_col` ## This is an error, but only a warning is raised for compatibility reasons. ## The operation will return the input unchanged. saveRDS(mod_x, file = &#39;./cache_obj/mod_sentiment_5.rds&#39;) describir_modelo_cv(mod_x) ## [1] &quot;Lambda min: 0.0907179532894125&quot; ## [1] &quot;Error entrenamiento: 0&quot; ## [1] &quot;Error prueba: 0.12&quot; ## [1] &quot;Devianza entrena:0.18&quot; ## [1] &quot;Devianza prueba:0.653&quot; Y ya casi logramos nuestro objetivo. Podemos intentar con más palabras vocabulario &lt;- calc_vocabulario(df_ent_grande, 4000, remove_stop = FALSE) mod_x &lt;- correr_modelo_cv(df_ent_grande, df_pr, vocabulario, lambda = exp(seq(-5,2,0.1))) ## Joining, by = &quot;palabra&quot; ## Joining, by = &quot;palabra&quot; ## Warning: Trying to compute distinct() for variables not found in the data: ## - `row_col`, `column_col` ## This is an error, but only a warning is raised for compatibility reasons. ## The operation will return the input unchanged. ## Warning: Trying to compute distinct() for variables not found in the data: ## - `row_col`, `column_col` ## This is an error, but only a warning is raised for compatibility reasons. ## The operation will return the input unchanged. saveRDS(mod_x, file = &#39;./cache_obj/mod_sentiment_6.rds&#39;) mod_x &lt;- readRDS(&#39;./cache_obj/mod_sentiment_6.rds&#39;) describir_modelo_cv(mod_x) ## [1] &quot;Lambda min: 0.0742735782143339&quot; ## [1] &quot;Error entrenamiento: 0&quot; ## [1] &quot;Error prueba: 0.12&quot; ## [1] &quot;Devianza entrena:0.127&quot; ## [1] &quot;Devianza prueba:0.621&quot; Y esto funcionó bien. Subir más la regularización no ayuda mucho (pruébalo). Parece que el sesgo lo podemos hacer chico (reducir el error de entrenamiento considerablemente), pero tenemos un problema más grande con la varianza. Quizá muchas palabras que estamos usando no tienen qué ver con la calidad de positivo/negativo, y eso induce varianza. Estos modelos no utilizan la estructura que hay en las reseñas, simplemente cuentan qué palabras aparecen. Quizá aprovechar esta estructura podemos incluir variables más informativas que induzcan menos varianza sin aumentar el sesgo. Podemos conseguir más datos. Obsérvese que: ¿Podríamos intentar con una red neuronal totalmente conexa? Probablemente esto no va a ayudar, pues es un modelo más complejo y nuestro problema es varianza. 6.7 Usar datos adicionales Considerar fuentes adicionales de datos muchas veces puede ayudar a mejorar nuestras entradas, lo cual puede tener beneficios en predicción (tanto sesgo como varianza). Intentemos el primer camino. Probamos usar palabras que tengan afinidad como parte de su significado (positivas y negativas). Estos datos están incluidos en el paquete tidytext. bing &lt;- filter(sentiments, lexicon == &#39;bing&#39;) tail(bing) ## # A tibble: 6 x 4 ## word sentiment lexicon score ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 zealous negative bing NA ## 2 zealously negative bing NA ## 3 zenith positive bing NA ## 4 zest positive bing NA ## 5 zippy positive bing NA ## 6 zombie negative bing NA dim(vocabulario) ## [1] 4106 2 vocabulario &lt;- calc_vocabulario(df_ent_grande, 8000, remove_stop = FALSE) voc_bing &lt;- vocabulario %&gt;% inner_join(bing %&gt;% rename(palabra = word)) ## Joining, by = &quot;palabra&quot; dim(voc_bing) ## [1] 1476 5 mod_x &lt;- correr_modelo_cv(df_ent_grande, df_pr, voc_bing, alpha=0, lambda = exp(seq(-5,2,0.1))) ## Joining, by = &quot;palabra&quot; ## Joining, by = &quot;palabra&quot; ## Warning: Trying to compute distinct() for variables not found in the data: ## - `row_col`, `column_col` ## This is an error, but only a warning is raised for compatibility reasons. ## The operation will return the input unchanged. ## Warning: Trying to compute distinct() for variables not found in the data: ## - `row_col`, `column_col` ## This is an error, but only a warning is raised for compatibility reasons. ## The operation will return the input unchanged. describir_modelo_cv(mod_x) ## [1] &quot;Lambda min: 0.135335283236613&quot; ## [1] &quot;Error entrenamiento: 0.02&quot; ## [1] &quot;Error prueba: 0.18&quot; ## [1] &quot;Devianza entrena:0.399&quot; ## [1] &quot;Devianza prueba:0.775&quot; Estas variables solas no dan un resultado tan bueno (tenemos tanto sesgo como varianza altas). Podemos combinar: vocabulario &lt;- calc_vocabulario(df_ent_grande, 3000, remove_stop =FALSE) voc &lt;- bind_rows(vocabulario, voc_bing %&gt;% select(palabra, frec)) %&gt;% unique dim(voc) ## [1] 4021 2 mod_x &lt;- correr_modelo_cv(df_ent_grande, df_pr, voc, alpha=0, lambda = exp(seq(-5,2,0.1))) ## Joining, by = &quot;palabra&quot; ## Joining, by = &quot;palabra&quot; ## Warning: Trying to compute distinct() for variables not found in the data: ## - `row_col`, `column_col` ## This is an error, but only a warning is raised for compatibility reasons. ## The operation will return the input unchanged. ## Warning: Trying to compute distinct() for variables not found in the data: ## - `row_col`, `column_col` ## This is an error, but only a warning is raised for compatibility reasons. ## The operation will return the input unchanged. describir_modelo_cv(mod_x) ## [1] &quot;Lambda min: 0.110803158362334&quot; ## [1] &quot;Error entrenamiento: 0&quot; ## [1] &quot;Error prueba: 0.13&quot; ## [1] &quot;Devianza entrena:0.168&quot; ## [1] &quot;Devianza prueba:0.64&quot; Este camino no se ve mal, pero no hemos logrado mejoras. Aunque quizá valdría la pena intentar refinar más y ver qué pasa. 6.8 Examen de modelo y Análisis de errores Ahora podemos ver qué errores estamos cometiendo, y cómo está funcionando el modelo. Busquemos los peores. Corremos el mejor modelo hasta ahora: vocabulario &lt;- calc_vocabulario(df_ent_grande, 4000, remove_stop = FALSE) mod_x &lt;- correr_modelo_cv(df_ent_grande, df_pr, vocabulario, lambda = exp(seq(-5,2,0.1))) ## Joining, by = &quot;palabra&quot; ## Joining, by = &quot;palabra&quot; ## Warning: Trying to compute distinct() for variables not found in the data: ## - `row_col`, `column_col` ## This is an error, but only a warning is raised for compatibility reasons. ## The operation will return the input unchanged. ## Warning: Trying to compute distinct() for variables not found in the data: ## - `row_col`, `column_col` ## This is an error, but only a warning is raised for compatibility reasons. ## The operation will return the input unchanged. describir_modelo_cv(mod_x) ## [1] &quot;Lambda min: 0.0742735782143339&quot; ## [1] &quot;Error entrenamiento: 0&quot; ## [1] &quot;Error prueba: 0.12&quot; ## [1] &quot;Devianza entrena:0.127&quot; ## [1] &quot;Devianza prueba:0.621&quot; coeficientes &lt;- predict(mod_x$mod, lambda = &#39;lambda.min&#39;, type = &#39;coefficients&#39;) coef_df &lt;- data_frame(palabra = rownames(coeficientes), coef = coeficientes[,1]) arrange(coef_df, coef) %&gt;% print(n=20) ## # A tibble: 4,107 x 2 ## palabra coef ## &lt;chr&gt; &lt;dbl&gt; ## 1 (Intercept) -0.520 ## 2 tiresome -0.318 ## 3 sloppy -0.317 ## 4 tedious -0.313 ## 5 designed -0.287 ## 6 profanity -0.286 ## 7 forgot -0.285 ## 8 insulting -0.273 ## 9 redeeming -0.268 ## 10 ludicrous -0.267 ## 11 asleep -0.264 ## 12 embarrassing -0.260 ## 13 alas -0.254 ## 14 miserably -0.252 ## 15 lifeless -0.247 ## 16 random -0.242 ## 17 abilities -0.238 ## 18 ridiculous -0.235 ## 19 inept -0.234 ## 20 stupidity -0.231 ## # ... with 4,087 more rows arrange(coef_df, desc(coef)) %&gt;% print(n=20) ## # A tibble: 4,107 x 2 ## palabra coef ## &lt;chr&gt; &lt;dbl&gt; ## 1 refreshing 0.306 ## 2 beings 0.289 ## 3 underneath 0.287 ## 4 commanding 0.260 ## 5 outstanding 0.245 ## 6 marvelous 0.236 ## 7 finest 0.230 ## 8 identify 0.228 ## 9 enjoyment 0.228 ## 10 ralph 0.224 ## 11 exceptional 0.220 ## 12 threatens 0.218 ## 13 mature 0.216 ## 14 anger 0.216 ## 15 luckily 0.214 ## 16 enters 0.213 ## 17 overall 0.210 ## 18 breathtaking 0.208 ## 19 popcorn 0.207 ## 20 portrait 0.205 ## # ... with 4,087 more rows Y busquemos las diferencias más grandes del la probabilidad ajustada con la clase observada y &lt;- mod_x$prueba$y x &lt;- mod_x$prueba$x probs &lt;- predict(mod_x$mod, newx = x, type = &#39;response&#39;, s =&#39;lambda.min&#39;) df_1 &lt;- data_frame(id = rownames(x), y=y, prob = probs[,1]) %&gt;% mutate(error = y - prob) %&gt;% arrange(desc(abs(error))) df_1 ## # A tibble: 425 x 4 ## id y prob error ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1508 1 0.0370 0.963 ## 2 1461 1 0.0459 0.954 ## 3 1490 1 0.0900 0.910 ## 4 222 0 0.896 -0.896 ## 5 1933 1 0.106 0.894 ## 6 1642 1 0.131 0.869 ## 7 25 0 0.864 -0.864 ## 8 728 0 0.860 -0.860 ## 9 1050 1 0.146 0.854 ## 10 415 0 0.850 -0.850 ## # ... with 415 more rows filter(df_pr, id == 1461) %&gt;% pull(texto) %&gt;% str_sub(1, 500) [1] “Review deep rising is one of &quot; those &quot; movies . the kind of movie which serves no purpose except to entertain us . it does not ask us to think about important questions like life on other planets or the possibility that there is no god . . . screw that , it says boldly , let’s see some computer generated monsters rip into , decapitate and generally cause irreparable booboos to a bunch of little known actors . heh ! them wacky monsters , gotta love ’em . of course , since we can rent about” filter(df_pr, id == 1508) %&gt;% pull(texto) %&gt;% str_sub(1, 1000) [1] “Review capsule : side-splitting comedy that follows its own merciless logic almost through to the end . . . but not without providing a good deal of genuine laughs . most comedies these days have one flaw . they’re not funny . they think they’re funny , but they are devoid of anything really penetrating or dastardly . occasionally a good funny movie sneaks past the deadening hollywood preconceptions of humor and we get a real gem : ruthless people , for instance , which established a microcosm of a setup and played it out to the bitter end . liar liar is built the same way and is just about as funny . this is one of the few movies i’ve seen where i was laughing consistently almost all the way through : instead of a couple of set-pieces that inspired a laugh ( think of the dismal fatal instinct ) , the whole movie works like clockwork . jim carrey playes a high-powered lawyer , to whom lying is as natural as breathing . there is one thing he takes seriously , though : his son” Estas últimas son reseñas positivas que clasificamos incorrectamente como negativas. Vemos que en ambas el tono es irónico: por ejemplo, la primera argumenta que la película es mala, pero disfrutable. Esta fue etiquetada como una reseña positiva. Este fenómeno se puede ver como un problema difícil de sesgo: nuestro modelo simple difícilmente podrá captar esta estructura compleja de ironía. El problema es diferente para las reseñas negativas. Veamos algunas de las reseñas negativas peor clasificadas: filter(df_pr, id == 222) %&gt;% pull(texto) %&gt;% str_sub(1, 1000) #negativa [1] “Review it’s probably inevitable that the popular virtual reality genre ( &quot; the matrix , &quot; &quot; existenz &quot; ) would collide with the even more popular serial-killer genre ( &quot; kiss the girls , &quot; &quot; se7en &quot; ) . the result should have been more interesting than &quot; the cell . &quot; as the movie opens , therapist catharine deane ( jennifer lopez ) treats a catatonic boy ( colton james ) by entering his mind through some sort of virtual reality technique that’s never fully explained . after months of therapy sessions in a surreal desert , catharine has no success to report . meanwhile , killer carl stargher ( vincent d’onofrio ) has claimed another victim . his particular hobby is to kidnap young women , keep them in a glass cell overnight , and drown them . he takes the corpse and soaks it in bleach , then suspends himself over the body and jerks off while watching a video tape of the drowning . although carl’s been doing this for awhile , he’s recently become sloppy , and fbi agent peter nova” filter(df_pr, id == 728) %&gt;% pull(texto) %&gt;% str_sub(1, 1000) #negativa [1] “Review girl 6 is , in a word , a mess . i was never able to determine what spike lee was trying to accomplish with this film . there was no sense of where the film was going , or any kind of coherent narrative . if there was a point to the film , i missed it . girl 6 , by the way , is the way theresa randle’s character is addressed in the phone sex workplace ; all the girls are known by their numbers . the plot , such as it is : theresa randle is a struggling n . y . actress , and eventually takes a job as a phone-sex operator . she begins to lose contact with reality , as her job consumes her . also , she must deal with the advances of her ex-husband ( isiah washington ) . he is an ex- con thief , and she tries to keep him away , while at the same time , it’s clear that she still harbors feelings for him . her neighbor , jimmy ( spike lee ) functions as the observer ; mediating between the ex- husband and girl 6 . he also functions as a point of stability , as he watches he” No está totalmente claro por qué nos equivocamos en estas dos reseñas. Podemos hacer un examen más cuidadoso de la construcción del predictor, obteniendo los coeficientes \\(\\beta\\) y el vector \\(x\\) con los que se construyen el predictor: beta &lt;- coef(mod_x$mod) %&gt;% as.numeric nombres &lt;- rownames(x) head(sort(x[nombres == &quot;222&quot;, ], decreasing = TRUE), 100) ## the in of to a and is ## 52 21 17 17 16 14 10 ## cell mind have that this as been ## 9 7 5 5 5 4 4 ## has his horse killer more she than ## 4 4 4 4 4 4 4 ## with all an another by could fast ## 4 3 3 3 3 3 3 ## for glass out peter seems should video ## 3 3 3 3 3 3 3 ## after at before boy can computer developed ## 2 2 2 2 2 2 2 ## find from generated genre go he him ## 2 2 2 2 2 2 2 ## i into it it&#39;s keep like movie ## 2 2 2 2 2 2 2 ## no not off on one or own ## 2 2 2 2 2 2 2 ## popular promise reality really room surreal them ## 2 2 2 2 2 2 2 ## time universe virtual well acting agent although ## 2 2 2 2 1 1 1 ## apart attack be because become begin best ## 1 1 1 1 1 1 1 ## bizarre body bottom brings but catch center ## 1 1 1 1 1 1 1 ## character closing costumes creates dark darkness day ## 1 1 1 1 1 1 1 ## depth desert ## 1 1 predictor &lt;- beta * c(1, x[nombres==&quot;222&quot;,]) # beta*x sum(predictor) ## [1] 1.437326 sort(predictor[predictor != 0]) %&gt;% knitr::kable() x -0.5202993 sloppy -0.3172574 promise -0.2760900 video -0.1501897 dull -0.1331210 catch -0.1169287 should -0.1159415 suffers -0.1128175 trapped -0.1111792 could -0.1011409 pulling -0.1003304 bottom -0.0939438 fast -0.0911754 been -0.0908088 save -0.0876571 explained -0.0808605 have -0.0796675 mtv -0.0714969 talking -0.0639503 kidnapped -0.0600789 water -0.0600346 vince -0.0571824 begin -0.0547786 jennifer -0.0528719 virtual -0.0519579 twisted -0.0508402 center -0.0505813 provided -0.0492090 psycho -0.0489186 off -0.0482361 recently -0.0482342 result -0.0476513 women -0.0472648 point -0.0472133 within -0.0458799 forward -0.0456438 exercise -0.0452252 no -0.0410514 technique -0.0405685 director -0.0358213 focus -0.0351205 acting -0.0345010 interesting -0.0334681 style -0.0332168 thomas -0.0322831 kept -0.0316398 hardly -0.0309470 another -0.0307244 attack -0.0302758 explored -0.0292849 then -0.0292602 or -0.0290317 victim -0.0276020 fill -0.0267911 hope -0.0266701 even -0.0250174 enough -0.0249711 woman -0.0244227 fall -0.0234435 apart -0.0233941 out -0.0230786 this -0.0196350 to -0.0184586 premise -0.0180929 she’s -0.0179955 killer -0.0173511 left -0.0173469 development -0.0172162 how -0.0165661 into -0.0162641 at -0.0153004 discover -0.0150697 them -0.0133533 would -0.0129188 james -0.0124600 on -0.0124260 where -0.0121713 sort -0.0121419 much -0.0114857 costumes -0.0111567 turns -0.0110439 so -0.0108164 movie -0.0108057 end -0.0107060 review -0.0105867 be -0.0104210 don’t -0.0102111 had -0.0100659 like -0.0100186 because -0.0099953 seems -0.0096492 girls -0.0096262 tape -0.0089222 through -0.0089024 character -0.0087373 all -0.0081031 room -0.0078808 long -0.0074416 get -0.0068225 some -0.0054598 thought -0.0052326 fbi -0.0052078 bizarre -0.0050159 opportunity -0.0048392 house -0.0047232 forty -0.0037017 after -0.0036686 minds -0.0035547 doing -0.0035518 my -0.0030584 hours -0.0030343 scene -0.0029061 girl -0.0026162 i -0.0024423 psychotic -0.0014919 next -0.0013199 singer -0.0012470 that -0.0007843 watching -0.0000763 but 0.0001236 standing 0.0002228 himself 0.0003255 pieces 0.0003999 popular 0.0007742 its 0.0017265 she 0.0022264 can 0.0025564 think 0.0025935 they 0.0027960 over 0.0029586 part 0.0036062 personality 0.0037015 he’s 0.0039892 one 0.0040252 existenz 0.0040481 never 0.0042116 it 0.0042247 substance 0.0042565 that’s 0.0045095 kiss 0.0054557 an 0.0056231 known 0.0057068 really 0.0057512 element 0.0058064 not 0.0059663 place 0.0060158 horse 0.0070165 go 0.0072319 without 0.0073540 time 0.0078486 however 0.0078614 for 0.0081780 their 0.0088714 first 0.0093176 closing 0.0100908 serial 0.0104635 of 0.0108933 rather 0.0113546 opens 0.0114884 him 0.0115767 michael 0.0115885 he 0.0116202 living 0.0126425 fate 0.0126835 meanwhile 0.0129676 though 0.0129746 his 0.0136937 slow 0.0141722 peter 0.0144512 vincent 0.0148222 young 0.0150035 day 0.0150646 does 0.0152965 it’s 0.0154444 by 0.0156547 depth 0.0156696 importance 0.0159429 while 0.0163877 will 0.0164211 world 0.0165024 has 0.0168118 particular 0.0174925 more 0.0176460 a 0.0189342 effect 0.0193250 agent 0.0199253 creates 0.0209483 leaves 0.0215036 see 0.0217573 with 0.0231662 role 0.0232334 from 0.0234281 body 0.0234823 than 0.0237709 probably 0.0239042 developed 0.0240430 elaborate 0.0243947 suddenly 0.0247735 logic 0.0249532 most 0.0265502 line 0.0271946 music 0.0273477 as 0.0278241 still 0.0292254 months 0.0294009 shows 0.0296746 psychological 0.0313499 head 0.0321303 boy 0.0340266 darkness 0.0342972 become 0.0346070 very 0.0348716 father 0.0352316 although 0.0354252 sound 0.0358830 finds 0.0375483 matrix 0.0377628 particularly 0.0390302 brings 0.0400255 success 0.0403674 before 0.0412008 directing 0.0413102 viewer 0.0421106 sidney 0.0425819 best 0.0432040 the 0.0439582 is 0.0443391 takes 0.0448486 dark 0.0449853 inside 0.0476245 separate 0.0479765 in 0.0487678 find 0.0500643 great 0.0523020 together 0.0581238 computer 0.0586483 genre 0.0593194 own 0.0625957 reality 0.0627538 disturbing 0.0636809 keep 0.0642032 and 0.0648463 offer 0.0736850 strangely 0.0743557 inevitable 0.0759366 fully 0.0789776 jake 0.0797114 frightened 0.0824091 provoking 0.0846733 well 0.0880060 desert 0.0899893 treats 0.0985579 losing 0.0990976 religion 0.1298072 generated 0.1304031 universe 0.1438618 madness 0.1580777 sharp 0.1604157 enters 0.2131698 surreal 0.2394179 mind 0.2858087 glass 0.4687988 cell 0.7086423 beta &lt;- coef(mod_x$mod) %&gt;% as.numeric nombres &lt;- rownames(x) predictor &lt;- beta * c(1, x[nombres==&quot;728&quot;,]) # beta*x sum(predictor) ## [1] 1.177288 sort(predictor[predictor != 0]) %&gt;% knitr::kable() x -0.5202993 mess -0.2022808 impression -0.1506333 grade -0.1503932 struggling -0.1301878 there -0.1228140 loud -0.1042231 point -0.0944266 onscreen -0.0910190 nothing -0.0838901 tries -0.0810926 stuck -0.0777950 seemed -0.0768979 numbers -0.0716475 bad -0.0704995 confused -0.0645791 con -0.0619718 missed -0.0598450 sex -0.0582862 wasn’t -0.0534325 even -0.0500348 phone -0.0499893 plot -0.0488645 women -0.0472648 lose -0.0471523 stone -0.0467291 middle -0.0416681 lee -0.0414526 trying -0.0402636 should -0.0386472 was -0.0380697 any -0.0374969 sequences -0.0373245 only -0.0365272 buddy -0.0357364 he’d -0.0345297 acting -0.0345010 interesting -0.0334681 i’d -0.0325935 kept -0.0316398 be -0.0312630 if -0.0309857 fan -0.0303648 becomes -0.0292044 or -0.0290317 idea -0.0261244 die -0.0243408 such -0.0222690 i’m -0.0215163 actress -0.0205609 no -0.0205257 hard -0.0196748 character -0.0174746 some -0.0163793 away -0.0162291 have -0.0159335 girl -0.0156973 happens -0.0150229 make -0.0141744 to -0.0130296 background -0.0129527 where -0.0121713 this -0.0117810 setup -0.0115887 much -0.0114857 d -0.0113921 made -0.0112626 gave -0.0109618 going -0.0106231 might -0.0105983 review -0.0105867 scenes -0.0100794 had -0.0100659 like -0.0100186 later -0.0097639 girls -0.0096262 up -0.0090409 course -0.0089834 just -0.0083408 her -0.0082487 into -0.0081321 out -0.0076929 at -0.0076502 jimmy -0.0071043 when -0.0057891 work -0.0054795 seems -0.0032164 my -0.0030584 thing -0.0029429 scene -0.0029061 all -0.0027010 i -0.0024423 that -0.0015686 altogether -0.0006508 opening 0.0001563 but 0.0002473 amusing 0.0003099 songs 0.0007721 fans 0.0014369 which 0.0015447 she 0.0022264 begins 0.0022827 really 0.0028756 past 0.0029292 an 0.0037487 time 0.0039243 more 0.0044115 are 0.0047948 ex 0.0049676 they 0.0055921 me 0.0057067 known 0.0057068 than 0.0059427 not 0.0059663 one 0.0060378 who 0.0067409 other 0.0076092 it’s 0.0077222 however 0.0078614 types 0.0080658 for 0.0081780 same 0.0082892 has 0.0084059 determine 0.0084183 never 0.0084232 sense 0.0084978 thief 0.0094086 it 0.0105618 of 0.0108933 rather 0.0113546 him 0.0115767 grows 0.0122519 sequence 0.0122732 dollar 0.0123269 love 0.0130239 a 0.0142007 kind 0.0150748 use 0.0150783 lives 0.0152753 you 0.0153545 must 0.0160841 what 0.0161985 while 0.0163877 will 0.0164211 world 0.0165024 their 0.0177427 feelings 0.0178434 word 0.0180196 washington 0.0198875 grant 0.0199556 by 0.0208729 parts 0.0210454 prince 0.0216244 taking 0.0221986 with 0.0231662 from 0.0234281 probably 0.0239042 way 0.0242771 i’ve 0.0245634 worked 0.0249386 in 0.0255450 few 0.0262726 done 0.0263053 the 0.0287419 n 0.0287966 still 0.0292254 biggest 0.0296875 is 0.0310374 reality 0.0313769 keep 0.0321016 good 0.0340647 film 0.0344213 always 0.0348183 very 0.0348716 and 0.0370550 moments 0.0371737 between 0.0372559 though 0.0389237 particularly 0.0390302 agree 0.0441769 takes 0.0448486 able 0.0480575 i’ll 0.0480974 eventually 0.0484890 born 0.0494355 shot 0.0500720 different 0.0507236 several 0.0510954 he 0.0522909 killers 0.0530381 clear 0.0549046 attention 0.0549228 contact 0.0574982 as 0.0626043 multi 0.0640192 deal 0.0648396 also 0.0659141 become 0.0692140 fairly 0.0745365 narrative 0.0791347 performances 0.0816109 music 0.0820430 neighbor 0.0848025 watches 0.0876229 broke 0.0936433 natural 0.0969546 reminiscent 0.1004395 voices 0.1151647 excellent 0.1228298 intense 0.1262374 frightening 0.1264323 oliver 0.1275805 job 0.1327543 husband 0.1379187 distracting 0.1526334 soundtrack 0.1612572 industry 0.2074668 6 0.4226458 Y notamos que en primer caso, palabras “cell” es consideradas como positivas y en el segundo caso, se considera la ocurrencia de “6” como positiva. Sin embargo, observamos que en ambos casos la palabra problemática es usada de manera distinta en estas reseñas que en el resto (la primera es la película The Cell, y la segunda es Girl 6). La frecuencia alta de estas palabras en estas dos reseñas contribuye incorrectamente a denotar estas reseñas como positivas. Estas películas extrapolan demasiado lejos de los datos de entrenamiento. Típicamente, la extrapolación fuerte produce problemas tanto de sesgo (modelo poco apropiado para los valores que observamos) como varianza, pues estamos haciendo predicciones donde hay pocos datos. En este caso, podemos intentar reducir el sesgo tomando el logaritmo de los conteos de palabras en lugar de los conteos crudos. Esto reduce la influencia de conteos altos de palabras en relación a conteos altos (también podemos intentar usar indicadoras 0-1 en lugar de conteos). Después de algunos experimentos, podemos mejorar un poco: usar_cache &lt;- TRUE vocabulario &lt;- calc_vocabulario(df_ent_grande, 8500, remove_stop = FALSE) if(!usar_cache){ mod_x &lt;- correr_modelo_cv(df_ent_grande, df_pr, vocabulario, alpha = 0.01, lambda = exp(seq(-5, 2, 0.1)), log_transform = TRUE) saveRDS(mod_x, file = &quot;./cache_obj/mod_sentiment_log.rds&quot;) } else { mod_x &lt;- readRDS(&quot;./cache_obj/mod_sentiment_log.rds&quot;) } describir_modelo_cv(mod_x) ## [1] &quot;Lambda min: 0.0273237224472926&quot; ## [1] &quot;Error entrenamiento: 0&quot; ## [1] &quot;Error prueba: 0.11&quot; ## [1] &quot;Devianza entrena:0.045&quot; ## [1] &quot;Devianza prueba:0.565&quot; "],
["metodos-basados-en-arboles.html", "Sección 7 Métodos basados en árboles 7.1 Árboles para regresión y clasificación. 7.2 Bagging de árboles 7.3 Bosques aleatorios", " Sección 7 Métodos basados en árboles 7.1 Árboles para regresión y clasificación. La idea básica de los árboles es buscar puntos de cortes en las variables de entrada para hacer predicciones, ir dividiendo la muestra, y encontrar cortes sucesivos para refinar las predicciones. Ejemplo Buscamos clasificar hogares según su ingreso, usando como entradas características de los hogares. Podríamos tener, por ejemplo: knitr::include_graphics(&#39;./imagenes/arboles_1.png&#39;) Con este árbol podemos clasificar nuevos hogares. Nótese que los árboles pueden capturar interacciones entre las variables de entradas. En nuestro ejemplo ficticio, “automóvil” nos da información acerca del ingreso, pero solo caundo el nivel de educación del jefe de familia es bajo. (Ejercicio: si el ingreso fuera una cantidad numérica, ¿cómo escribirías este modelo con una suma de términos que involucren las variables mostradas en el diagrama?) Los árboles también pueden aproximar relaciones no lineales entre entradas y variable de salida (es similar a los ejemplos donde haciamos categorización de variables de entrada). Igual que en redes neuronales, en lugar de buscar puntos de corte o interacciones a mano, con los árboles intentamos encontrarlos de manera automática. 7.1.1 Árboles para clasificación Un árbol particiona el espacio de entradas en rectángulos paralelos a los ejes, y hace predicciones basadas en un modelo simple dentro de cada una de esas particiones. Por ejemplo: knitr::include_graphics(&#39;./imagenes/arboles_2.png&#39;) El proceso de partición binaria recursiva (con una entrada a la vez) puede representarse mediante árboles binarios. Los nodos terminales representan a la partición obtenida. Para definir el proceso de construcción de los árboles, debemos definir: ¿Cómo escoger las particiones? Idea: buscar hacer los nodos sucesivamente más puros (que una sola clase domine). ¿Cuándo declarar a un nodo como terminal? ¿Cuándo particionar más profundamente? Idea: dependiendo de la aplicación, buscamos hacer árboles chicos, o en otras árboles grandes que después podamos para no sobreajustar. ¿Cómo hacer predicciones en nodos terminales? Idea: escoger la clase más común en cada nodo terminal (la de máxima probabilidad). 7.1.2 Tipos de partición Supongamos que tenemos variables de entrada \\((X_1,\\ldots, X_p)\\). Recursivamente particionamos cada nodo escogiendo entre particiones tales que: Dependen de una sola variable de entrada \\(X_i\\) Si \\(X_i\\) es continua, la partición es de la forma \\(\\{X_i\\leq c\\},\\{X_i&gt; c\\}\\), para alguna \\(c\\) (punto de corte) Si \\(X_i\\) es categórica, la partición es de la forma \\(\\{X_i\\in S\\},\\{X_i\\notin S\\}\\), para algún subconjunto \\(S\\) de categorías de \\(X_i\\). En cada nodo candidato, escogemos uno de estos cortes para particionar. ¿Cómo escogemos la partición en cada nodo? En cada nodo, la partición se escoge de una manera miope o local, intentando separar las clases lo mejor que se pueda (sin considerar qué pasa en cortes hechos más adelante). En un nodo dado, escogemos la partición que reduce lo más posible su impureza. 7.1.3 Medidas de impureza Consideramos un nodo \\(t\\) de un árbol \\(T\\), y sean \\(p_1(t),\\ldots, p_K(t)\\) las proporciones de casos de \\(t\\) que caen en cada categoría. La impureza de un nodo \\(t\\) está dada por \\[i(t) = -\\sum_{j=1}^K p_j(t)\\log p_j(t)\\] Este medida se llama entropía. Hay otras posibilidades como medida de impureza (por ejemplo, coeficiente de Gini). 7.1.3.1 Ejemplo Graficamos la medida de impureza para dos clases: impureza &lt;- function(p){ -(p*log(p) + (1-p)*log(1-p)) } curve(impureza, 0,1) Donde vemos que la máxima impureza se alcanza cuando las proporciones de clase en un nodo so 50-50, y la mínima impureza (máxima pureza) se alcanza cuando en el nodo solo hay casos de una clase. Nótese que esta cantidad es proporcional a la devianza del nodo, donde tenemos porbabilidad constante de clase 1 igual a \\(p\\). 7.1.4 Reglas de partición y tamaño del árobl Podemos escribir la regla de partición, que se aplica a cada nodo de un árbol Regla de partición En cada nodo, buscamos entre todas las variables \\(X_i\\) y todos los puntos de corte \\(c\\) la que da la mayor reducción de impureza posible (donde la impureza de un corte es el promedio ponderado por casos de las impurezas de los nodos resultantes). Ejemplo Consideremos un nodo \\(t\\), cuyos casos de entrenamiento son: n_t &lt;- c(200,100, 150) impureza &lt;- function(p){ -sum(p*log(p)) } impureza(n_t/sum(n_t)) ## [1] 1.060857 Y comparamos con n_t &lt;- c(300,10, 140) impureza &lt;- function(p){ p &lt;- p[p&gt;0] -sum(p*log(p)) } impureza(n_t/sum(n_t)) ## [1] 0.7181575 Ahora supongamos que tenemos un posible corte, el primero resulta en n_t &lt;- c(300,10, 140) n_1 = c(300,0,0) n_2 = c(0,10,140) (sum(n_1)/sum(n_t))*impureza(n_1/sum(n_1)) + (sum(n_2)/sum(n_t))*impureza(n_2/sum(n_2)) ## [1] 0.08164334 Un peor corte es: n_t &lt;- c(300,10, 140) n_1 = c(200,0,40) n_2 = c(100,10,100) (sum(n_1)/sum(n_t))*impureza(n_1/sum(n_1)) + (sum(n_2)/sum(n_t))*impureza(n_2/sum(n_2)) ## [1] 0.6377053 Lo que resta explicar es qué criterio de paro utilizamos para dejar de particionar. Regla de paro Cuando usemos árboles en ótros métodos, generalmente hay dos opciones: Particionar hasta cierta profundidad fija (por ejemplo, máximo 8 nodos terminales). Este enfoque generalmente usa árboles relativamente chicos (se usa en boosting de árboles). Dejar de particionar cuando encontramos un número mínimo de casos en un nodo (por ejemplo, 5 o 10 casos). Este enfoque resulta en árboles grandes, probablemente sobreajustados (se usa en bosques aleatorios). Y cuando utilizamos los árboles por sí solos para hacer predicciones: Podemos probar distintos valores de tamaño de árbol, y escogemos por validación (muestra o cruzada) el tamaño final. Podemos usar el método CART de Breiman, que consiste en construir un árbol grande y luego podar al tamaño correcto. Ejemplo Construímos algunos árboles con los datos de spam: library(rpart) library(rpart.plot) library(ggplot2) library(dplyr) library(tidyr) spam_entrena &lt;- read.csv(&#39;./datos/spam-entrena.csv&#39;) spam_prueba &lt;- read.csv(&#39;./datos/spam-prueba.csv&#39;) head(spam_entrena) ## X wfmake wfaddress wfall wf3d wfour wfover wfremove wfinternet wforder ## 1 1 0.00 0.57 0.00 0 0.00 0 0 0 0.00 ## 2 2 1.24 0.41 1.24 0 0.00 0 0 0 0.00 ## 3 3 0.00 0.00 0.00 0 0.00 0 0 0 0.00 ## 4 4 0.00 0.00 0.48 0 0.96 0 0 0 0.48 ## 5 5 0.54 0.00 0.54 0 1.63 0 0 0 0.00 ## 6 6 0.00 0.00 0.00 0 0.00 0 0 0 0.00 ## wfmail wfreceive wfwill wfpeople wfreport wfaddresses wffree wfbusiness ## 1 0 0.57 0.57 1.15 0 0 0.00 0.00 ## 2 0 0.00 0.41 0.00 0 0 0.41 0.00 ## 3 0 0.00 0.00 0.00 0 0 0.00 0.00 ## 4 0 0.00 0.00 0.00 0 0 0.96 0.96 ## 5 0 0.00 0.54 0.00 0 0 0.54 0.54 ## 6 0 0.00 0.00 0.00 0 0 0.00 0.00 ## wfemail wfyou wfcredit wfyour wffont wf000 wfmoney wfhp wfhpl wfgeorge ## 1 1.73 3.46 0 1.15 0 0.00 0.00 0 0 0.0 ## 2 0.82 3.73 0 1.24 0 0.00 0.41 0 0 0.0 ## 3 0.00 12.19 0 4.87 0 0.00 9.75 0 0 0.0 ## 4 0.00 1.44 0 0.48 0 0.96 0.00 0 0 0.0 ## 5 0.00 2.17 0 5.97 0 0.54 0.00 0 0 0.0 ## 6 0.00 5.00 0 0.00 0 0.00 0.00 0 0 2.5 ## wf650 wflab wflabs wftelnet wf857 wfdata wf415 wf85 wftechnology wf1999 ## 1 0 0 0 0 0 0 0 0 0 0 ## 2 0 0 0 0 0 0 0 0 0 0 ## 3 0 0 0 0 0 0 0 0 0 0 ## 4 0 0 0 0 0 0 0 0 0 0 ## 5 0 0 0 0 0 0 0 0 0 0 ## 6 0 0 0 0 0 0 0 0 0 0 ## wfparts wfpm wfdirect wfcs wfmeeting wforiginal wfproject wfre wfedu ## 1 0 0 0 0 0 0 0 0.00 0 ## 2 0 0 0 0 0 0 0 0.41 0 ## 3 0 0 0 0 0 0 0 0.00 0 ## 4 0 0 0 0 0 0 0 0.48 0 ## 5 0 0 0 0 0 0 0 0.00 0 ## 6 0 0 0 0 0 0 0 0.00 0 ## wftable wfconference cfsc cfpar cfbrack cfexc cfdollar cfpound ## 1 0 0 0 0.000 0.000 0.107 0.000 0.000 ## 2 0 0 0 0.065 0.000 0.461 0.527 0.000 ## 3 0 0 0 0.000 0.000 0.000 0.000 0.000 ## 4 0 0 0 0.133 0.066 0.468 0.267 0.000 ## 5 0 0 0 0.000 0.000 0.715 0.318 0.000 ## 6 0 0 0 0.000 0.000 0.833 0.000 0.416 ## crlaverage crllongest crltotal spam ## 1 1.421 7 54 1 ## 2 3.166 19 114 1 ## 3 1.000 1 7 0 ## 4 3.315 61 242 1 ## 5 2.345 22 129 1 ## 6 1.937 8 31 0 Podemos construir un árbol grande. En este caso, buscamos que los nodos resultantes tengan al menos un caso y para particionar pedimos que el nodo tenga al menos 10 casos: set.seed(22) control_completo &lt;- rpart.control(cp=0, minsplit=10, minbucket=1, xval=10, maxdepth=30) spam_tree_completo&lt;-rpart(spam ~ ., data = spam_entrena, method = &quot;class&quot;, control = control_completo) prp(spam_tree_completo, type=4, extra=4) ## Warning: labs do not fit even at cex 0.15, there may be some overplotting Podemos examinar la parte de arriba del árbol: arbol.chico.1 &lt;- prune(spam_tree_completo, cp=0.07) prp(arbol.chico.1, type = 4, extra = 4) Podemos hacer predicciones con este árbol grande. Por ejemplo, en entrenamiento tenemos: prop &lt;- predict(spam_tree_completo, newdata = spam_entrena) table(prop[,2]&gt;0.5, spam_entrena$spam ) ## ## 0 1 ## FALSE 1835 34 ## TRUE 26 1172 y en prueba: prop_arbol_grande &lt;- predict(spam_tree_completo, newdata = spam_prueba) tab_confusion &lt;- table(prop_arbol_grande[,2]&gt;0.5, spam_prueba$spam ) prop.table(tab_confusion, 2) ## ## 0 1 ## FALSE 0.90507012 0.11202636 ## TRUE 0.09492988 0.88797364 Y notamos la brecha grande entre prueba y entrenamiento, lo que sugiere sobreajuste. Este árbol es demasiado grande. 7.1.5 Costo - Complejidad (Breiman) Una manera de escoger árboles del tamaño correcto es utilizando una medida inventada por Breiman para medir la calidad de un árbol. La complejidad de un árbol \\(T\\) está dada por (para \\(\\alpha\\) fija): \\[C_\\alpha (T) = \\overline{err}(T) + \\alpha \\vert T\\vert\\] donde \\(\\overline{err}(T)\\) es el error de clasificación de \\(T\\) \\(\\vert T\\vert\\) es el número de nodos terminales del árbol \\(\\alpha&gt;0\\) es un parámetro de penalización del tamaño del árbol. Esta medida de complejidad incluye qué tan bien clasifica el árbol en la muestra de entrenamiento, pero penaliza por el tamaño del árbol. Para escoger el tamaño del árbol correcto, definimos \\(T_\\alpha \\subset T\\) como el subárbol de \\(T\\) que minimiza la medida \\(C_\\alpha (T_\\alpha)\\). Para entender esta decisión, obsérvese que: Un subárbol grande de \\(T\\) tiene menor valor de \\(\\overline{err}(T)\\) (pues usa más cortes) Pero un subárbol grande de \\(T\\) tiene más penalización por complejidad \\(\\alpha\\vert T\\vert\\). De modo que para \\(\\alpha\\) fija, el árbol \\(T_\\alpha\\) hace un balance entre error de entrenamiento y penalización por complejidad. 7.1.5.1 Ejemplo Podemos ver subárboles más chicos creados durante el procedimiento de división de nodos (prp está el paquete rpart.plot). En este caso pondemos \\(\\alpha = 0.2\\) (cp = \\(\\alpha\\) = complexity parameter): arbol.chico.1 &lt;- prune(spam_tree_completo, cp=0.2) prp(arbol.chico.1, type = 4, extra = 4) Si disminuimos el coeficiente \\(\\alpha\\). arbol.chico.1 &lt;- prune(spam_tree_completo, cp=0.07) prp(arbol.chico.1, type = 4, extra = 4) y vemos que en efecto el árbol \\(T_{0.07}\\) contiene al árbol \\(T_{0.2}\\), y ambos son subárboles del árbol gigante que construimos al principio. Para podar un árbol con costo-complejidad, encontramos para cada \\(\\alpha&gt;0\\) (coeficiente de complejidad) un árbol \\(T_\\alpha\\subset T\\) que minimiza el costo-complejidad. Esto resulta en una sucesión de árboles \\(T_0\\subset T_1\\subset T_2\\subset \\cdots T_m\\subset T\\), de donde podemos escoger con validación el árbol óptimo. Nota: Esto es un teorema que hace falta demostrar: el resultado principal es que conforme aumentamos \\(\\alpha\\), vamos eliminiando ramas del árbol, de manera que los arbol.chico.1 &lt;- prune(spam_tree_completo, cp=0.05) prp(arbol.chico.1, type = 4, extra = 4) arbol.chico.1 &lt;- prune(spam_tree_completo, cp=0.02) prp(arbol.chico.1, type = 4, extra = 4) source(&#39;./scripts/fancyRpartPlot.R&#39;) fancyRpartPlot(arbol.chico.1, sub=&#39;&#39;) ## Loading required package: RColorBrewer Nota: Enfoques de predicción basados en un solo árbol para clasificación y regresión son típicamente superados en predicción por otros métodos. ¿Cuál crees que sea la razón? ¿Es un problema de varianza o sesgo? 7.1.6 (Opcional) Predicciones con CART Podemos hacer predicciones con un sólo árbol. En el caso de spam, haríamos set.seed(9293) # para hacer reproducible la validación cruzada spam_tree &lt;-rpart(spam ~ ., data = spam_entrena, method = &quot;class&quot;, control=list(cp=0, minsplit=5,minbucket=1)) Ahora mostramos los resultados de cada árbol para cada valor de \\(\\alpha\\). La siguiente función nos da una estimación de validación cruzada del error: printcp(spam_tree) ## ## Classification tree: ## rpart(formula = spam ~ ., data = spam_entrena, method = &quot;class&quot;, ## control = list(cp = 0, minsplit = 5, minbucket = 1)) ## ## Variables actually used in tree construction: ## [1] cfbrack cfdollar cfexc cfpar cfsc ## [6] crlaverage crllongest crltotal wf1999 wf3d ## [11] wf650 wfaddress wfall wfbusiness wfconference ## [16] wfcredit wfdata wfdirect wfedu wfemail ## [21] wffont wffree wfgeorge wfhp wfhpl ## [26] wfinternet wflabs wfmail wfmake wfmeeting ## [31] wfmoney wforder wforiginal wfour wfover ## [36] wfpeople wfpm wfproject wfre wfreceive ## [41] wfremove wfreport wftechnology wfwill wfyou ## [46] wfyour X ## ## Root node error: 1206/3067 = 0.39322 ## ## n= 3067 ## ## CP nsplit rel error xerror xstd ## 1 0.49087894 0 1.000000 1.00000 0.022431 ## 2 0.13681592 1 0.509121 0.54975 0.018903 ## 3 0.05223881 2 0.372305 0.44942 0.017516 ## 4 0.03980100 3 0.320066 0.34163 0.015659 ## 5 0.03150912 4 0.280265 0.30514 0.014922 ## 6 0.01160862 5 0.248756 0.28275 0.014436 ## 7 0.01077944 6 0.237148 0.27612 0.014286 ## 8 0.00663350 7 0.226368 0.25954 0.013901 ## 9 0.00497512 9 0.213101 0.24046 0.013436 ## 10 0.00414594 18 0.166667 0.21227 0.012701 ## 11 0.00331675 20 0.158375 0.21144 0.012679 ## 12 0.00276396 24 0.145108 0.20481 0.012496 ## 13 0.00248756 27 0.136816 0.19320 0.012167 ## 14 0.00165837 31 0.126036 0.18740 0.011997 ## 15 0.00130301 44 0.104478 0.18408 0.011899 ## 16 0.00124378 52 0.092869 0.18657 0.011973 ## 17 0.00118455 54 0.090381 0.18740 0.011997 ## 18 0.00110558 61 0.082090 0.18740 0.011997 ## 19 0.00082919 67 0.075456 0.18823 0.012022 ## 20 0.00066335 100 0.048093 0.19569 0.012238 ## 21 0.00041459 107 0.043118 0.19652 0.012262 ## 22 0.00033167 121 0.037313 0.20896 0.012611 ## 23 0.00031095 126 0.035655 0.21144 0.012679 ## 24 0.00027640 140 0.029851 0.21393 0.012746 ## 25 0.00020730 146 0.028192 0.21393 0.012746 ## 26 0.00010365 150 0.027363 0.21725 0.012836 ## 27 0.00000000 158 0.026534 0.21725 0.012836 Y usamos la regla de mínimo error o a una desviación estándar del error mínimo: arbol_podado &lt;- prune(spam_tree, cp = 0.00130301) prp(arbol_podado) Cuyo error de predicción es: prop_arbol_podado &lt;- predict(arbol_podado, newdata=spam_prueba) head(prop_arbol_podado) ## 0 1 ## 1 0.02578797 0.974212 ## 2 0.02578797 0.974212 ## 3 0.03703704 0.962963 ## 4 0.12500000 0.875000 ## 5 0.02578797 0.974212 ## 6 0.02578797 0.974212 prop.table(table((prop_arbol_podado[,2]&gt;0.5),spam_prueba$spam),2) ## ## 0 1 ## FALSE 0.94282632 0.12191104 ## TRUE 0.05717368 0.87808896 7.1.7 Árboles para regresión Para problemas de regresión, el criterio de pureza y la predicción en cada nodo terminal es diferente: En los nodos terminales usamos el promedio los casos de entrenamiento que caen en tal nodo (en lugar de la clase más común) La impureza de define como varianza: si \\(t\\) es un nodo, su impureza está dada por \\(\\frac{1}{n(t)}\\sum (y - m)^2\\), donde la suma es sobre los casos que están en el nodo y \\(m\\) es la media de las \\(y\\)’s del nodo. 7.1.8 Variabilidad en el proceso de construcción Existe variabilidad considerable en el proceso de división, lo cual es una debilidad de los árboles. Por ejemplo: set.seed(9923) muestra.1 &lt;- spam_entrena[sample(1:nrow(spam_entrena), nrow(spam_entrena), replace=T), ] spam.tree.completo.1 &lt;-rpart(spam ~ ., data = muestra.1, method = &quot;class&quot;, control = control_completo) arbol.chico.1 &lt;- prune(spam.tree.completo.1, cp=0.03) prp(arbol.chico.1, type = 4, extra = 4) muestra.1 &lt;- spam_entrena[sample(1:nrow(spam_entrena), nrow(spam_entrena), replace=T), ] spam.tree.completo.1 &lt;-rpart(spam ~ ., data = muestra.1, method = &quot;class&quot;, control = control_completo) arbol.chico.1 &lt;- prune(spam.tree.completo.1, cp=0.03) prp(arbol.chico.1, type = 4, extra = 4) Pequeñas diferencias en la muestra de entrenamiento produce distintas selecciones de variables y puntos de corte, y estructuras de árboles muchas veces distintas. Esto introduce varianza considerable en las predicciones. 7.1.9 Relaciones lineales Los árboles pueden requerir ser muy grandes para estimar apropiadamente relaciones lineales. x &lt;- runif(200,0,1) y &lt;- 2*x + rnorm(200,0,0.1) arbol &lt;- rpart(y~x, data=data_frame(x=x, y=y), method = &#39;anova&#39;) x_pred &lt;- seq(0,1,0.05) y_pred &lt;- predict(arbol, newdata = data_frame(x=x_pred)) y_verdadera &lt;- 2*x_pred dat &lt;- data_frame(x_pred=x_pred, y_pred=y_pred, y_verdadera=y_verdadera) %&gt;% gather(y, valor, y_pred:y_verdadera) ggplot(dat, aes(x=x_pred, y=valor, colour=y)) + geom_line() 7.1.10 Ventajas y desventajas de árboles Ventajas: Árboles chicos son fáciles de explicar e interpretar Capturan interacciones entre las variables de entrada Son robustos en el sentido de que valores numéricos atípicos no hacen fallar al método no es necesario transformar variables hay formas fáciles de lidiar con datos faltantes (cortes sucedáneos) Se ajustan rápidamente yson relativamente fáciles de interpretar (por ejemplo, son útiles para clasificar en campo) Árboles grandes generalmente no sufren de sesgo. Desventajas: Tienen dificultades en capturar estructuras lineales En la interpretación, tienen la dificultad de que muchas veces algunas variables de entrada “enmascaran” a otras. Que una variable de entrada no esté en el árbol no quiere decir que no sea “importante” para predecir (regresión ridge lidia mejor con esto). Son inestables (varianza alta) por construcción: es local/miope, basada en cortes duros si/no. Esto produce desempeño predictivo relativamente malo (p ej: una pequeña diferencia en cortes iniciales puede resultar en estructuras de árbol totalmente distintas). Adicoinalmente, no son apropiados cuando hay variables categóricas con muchas niveles: en estos casos, el árbol sobreajusta desde los primeros cortes, y las predicciones son malas. 7.2 Bagging de árboles Bosques aleatorios es un método de predicción que utiliza familias de árboles para hacer predicciones. Los árboles grandes tienen la ventaja de tener sesgo bajo, pero sufren de varianza alta. Podemos explotar el sesgo bajo si logramos controlar la varianza. Una idea primera para lograr esto es es hacer bagging de árboles: Perturbar la muestra de entrenamiento de distintas maneras y producir árboles distintos (grandes). La perturbación más usada es tomar muestras bootstrap de los datos y ajustar un árbol a cada muestra bootstrap Promediar el resultado de todos estos árboles para hacer predicciones. El proceso de promediar reduce la varianza, sin tener pérdidas en sesgo. La idea básica de bagging (bootstrap aggregation) es la siguiente: Consideramos el proceso \\({\\mathcal L} \\to T_{\\mathcal L}\\), que representa el proceso de ajuste de un árbol \\(T_{\\mathcal L}\\) a partir de la muestra de entrenamiento \\({\\mathcal L}\\). Si pudiéramos obtener distintas muestras de entrenamiento \\[{\\mathcal L}_1, {\\mathcal L}_2, \\ldots, {\\mathcal L}_B,\\] y supongamos que construimos los árboles (que suponemos de regresión) \\[T_1, T_2, \\ldots, T_B,\\] Podríamos mejorar nuestras predicciones construyendo el árbol promedio \\[T(x) = \\frac{1}{B}\\sum_{i=b}^B T_b (x)\\] ¿Por qué es mejor este árbol promedio que cualquiera de sus componentes? Veamos primero el sesgo. El valor esperado del árbol promedio es \\[E[T(x)] = \\frac{1}{B}\\sum_{i=b}^B E[T_b (x)]\\] y como cada \\(T_b(x)\\) se construye de la misma manera a partir de \\({\\mathcal L}_b\\), y todas las muestras \\({\\mathcal L}_b\\) se extraen de la misma forma, todos los términos de la suma de la derecha son iguales: \\[E[T(x)] = E[T_1 (x)],\\] lo que implica que el sesgo del promedio es igual al sesgo de un solo árbol (que es bajo, pues suponemos que los árboles son grandes). Ahora veamos la varianza. Como las muestras \\({\\mathcal L}_b\\) se extraen de manera independiente, entonces \\[Var[T(x)] = Var\\left( \\frac{1}{B}\\sum_{i=b}^B T_b (x)\\right) = \\frac{1}{B^2}\\sum_{i=b}^B Var[T_b (x)],\\] pues los distintos \\(T_b(x)\\) no están correlacionados (en ese caso, varianza de la suma es la suma de las varianzas), y las constantes salen de la varianza al cuadrado. Por las mismas razones que arriba, todos los términos de la derecha son iguales, y \\[Var[T(x)] = \\frac{1}{B}\\ Var[T_1 (x)]\\] de modo que la varianza del árbol promedio es mucho más chica que la varianza de un árbol dado (si \\(B\\) es grande). Sin embargo, no podemos tomar muestras de entrenamiento repetidamente para ajustar estos árboles. ¿Cómo podemos simular extraer distintas muestras de entrenamiento? Sabemos que si tenemos una muestra de entrenamiento fija \\({\\mathcal L}\\), podemos evaluar la variación de esta muestra tomando muestras bootstrap de \\({\\mathcal L}\\), que denotamos por \\[{\\mathcal L}_1^*, {\\mathcal L}_2^*, \\ldots, {\\mathcal L}_B^*,\\] Recordatorio: una muestra bootstrap de \\(\\mathcal L\\) es una muestra con con reemplazo de \\({\\mathcal L}\\) del mismo tamaño que \\({\\mathcal L}\\). Entonces la idea es que construimos los árboles (que suponemos de regresión) \\[T_1^*, T_2^*, \\ldots, T_B^*,\\] podríamos mejorar nuestras predicciones construyendo el árbol promedio \\[T^*(x) = \\frac{1}{B}\\sum_{i=b}^B T_b^* (x)\\] para suavizar la variación de cada árbol individual. El argumento del sesgo aplica en este caso, pero el de la varianza no exactamente, pues las muestras bootstrap no son independientes (están correlacionadas a través de la muestra de entrenamiento de donde se obtuvieron),a pesar de que las muestras bootstrap se extraen de manera independiente de \\({\\mathcal L}\\). De esta forma, no esperamos una reducción de varianza tan grande como en el caso de muestras independientes. Bagging Sea \\({\\mathcal L} =\\{(x^{(i)}, y^{(i)})\\}_{i=1}^n\\) una muestra de entrenamiento, y sean \\[{\\mathcal L}_1^*, {\\mathcal L}_2^*, \\ldots, {\\mathcal L}_B^*,\\] muestras bootstrap de \\({\\mathcal L}\\) (muestreamos con reemplazo los pares \\((x^{(i)}, y^{(i)})\\), para obtener una muestra de tamaño \\(n\\)). Para cada muestra bootstrap construimos un árbol \\[{\\mathcal L}_b^* \\to T_b^*\\]. (Regresión) Promediamos árboles para reducir varianza \\[T^*(x) = \\frac{1}{B}\\sum_{i=b}^B T_b^*(x)\\] (Clasificación) Tomamos votos sobre todos los árboles: \\[T^*(x) = argmax_g \\{ \\# \\{i|T_b^*(x)=g\\}\\}.\\] Podemos también calcular probabilidades promedio sobre todos los árboles. Bagging muchas veces reduce el error de predicción gracias a una reducción modesta de varianza. Nota: No hay garantía de bagging reduzca el error de entrenamiento, especialmente si los árboles base son muy malos clasificadores ¿Puedes pensar en un ejemplo donde empeora? 7.2.1 Ejemplo Probemos con el ejemplo de spam. Construimos árboles con muestras bootstrap de los datos originales de entrenamiento: muestra_bootstrap &lt;- function(df){ df %&gt;% sample_n(nrow(df), replace = TRUE) } arboles_bagged &lt;- lapply(1:30, function(i){ muestra &lt;- muestra_bootstrap(spam_entrena) arbol &lt;- rpart(spam ~ ., data = muestra, method = &quot;class&quot;, control=list(cp=0, minsplit=5,minbucket=1)) arbol }) Examinemos la parte de arriba de algunos de estos árboles: prp(prune(arboles_bagged[[1]], cp =0.01)) prp(prune(arboles_bagged[[2]], cp =0.01)) prp(prune(arboles_bagged[[3]], cp =0.01)) Ahora probemos hacer predicciones con los 30 árboles: library(purrr) preds_clase &lt;- lapply(arboles_bagged, function(arbol){ preds &lt;- predict(arbol, newdata = spam_prueba)[,2] }) preds &lt;- preds_clase %&gt;% reduce(cbind) dim(preds) ## [1] 1534 30 prop_bagging &lt;- apply(preds, 1, mean) prop.table(table(prop_bagging &gt; 0.5, spam_prueba$spam),2) ## ## 0 1 ## FALSE 0.96224380 0.09555189 ## TRUE 0.03775620 0.90444811 Y vemos que tenemos una mejora inmediata con respecto un sólo árbol grande (tanto un árbol grande como uno podado con costo-complejidad). El único costo es el cómputo adicional para procesar las muestras bootstrap ¿Cuántas muestras bootstrap? Bagging generalmente funciona mejor cuando tomamos tantas muestras como sea razonable - aunque también es un parámetro que se puede afinar. Bagging por sí solo se usa rara vez. El método más potente es bosques aleatorios, donde el proceso básico es bagging de árboles, pero añadimos ruido adicional en la construcción de árboles. 7.2.2 Mejorando bagging El factor que limita la mejora de desempeño de bagging es que los árboles están correlacionados a través de la muestra de entrenamiento. Como vimos, si los árboles fueran independientes, entonces mejoramos por un factor de \\(B\\) (número de muestras independientes). Veamos un argumento para entender cómo esa correlación limita las mejoras: Quiséramos calcular (para una \\(x\\) fija) \\[Var(T(x)) = Var\\left(\\frac{1}{B}\\sum_{i=1}^B T^*_i\\right)\\] donde cada \\(T^*_i\\) se construye a partir de una muestra bootstrap de \\({\\mathcal L}\\). Nótese que esta varianza es sobre la muestra de entrenamiento \\({\\mathcal L}\\). Usando la fórmula de la varianza para sumas generales: \\[\\begin{equation} Var(T(x)) = Var\\left(\\frac{1}{B}\\sum_{i=1}^B T^*_i\\right) = \\sum_{i=1}^B \\frac{1}{B^2} Var(T^*_i(x)) + \\frac{2}{B^2}\\sum_{i &lt; j} Cov(T_i^*, T_j^*) \\tag{7.1} \\end{equation}\\] Ponemos ahora \\[\\sigma^2(x) = Var(T_i^*)\\] que son todas iguales porque los árboles bootstrap se extraen de la misma manera (\\({\\mathcal L}\\to {\\mathcal L}^*\\to T^*\\)). Escribimos ahora \\[\\rho(x) = corr(T_i^*, T_j^*)\\] que es una correlación sobre \\({\\mathcal L}\\) (asegúrate que entiendes este término). Todas estas correlaciones son iguales pues cada par de árboles se construye de la misma forma. Así que la fórmula (7.1) queda \\[\\begin{equation} Var(T(x)) = \\frac{1}{B} \\sigma^2(x) + \\frac{B-1}{B} \\rho(x)\\sigma^2(x) = \\sigma^2(x)\\left(\\frac{1}{B} + \\left(1-\\frac{1}{B}\\right )\\rho(x) \\right) \\tag{7.2} \\end{equation}\\] En el límite (cuando B es muy grande, es decir, promediamos muchos árboles): \\[\\begin{equation} Var(T(x)) = Var\\left(\\frac{1}{B}\\sum_{i=1}^B T^*_i\\right) \\approx \\sigma^2(x)\\rho(x) \\tag{7.3} \\end{equation}\\] Si \\(\\rho(x)=0\\) (árboles no correlacionados), la varianza del ensemble es la fracción \\(1/B\\) de la varianza de un solo árbol, y obtenemos una mejora considerable en varianza. En el otro extremo, si la correlación es alta \\(\\rho(x)\\approx 1\\), entonces no obtenemos ganancias por promediar árboles y la varianza del ensamble es similar a la de un solo árbol. Cuando hacemos bagging de árboles, la limitación de mejora cuando promediamos muchos árboles está dada por la correlación entre ellos: cuanto más grande es la correlación, menor beneficio en reducción de varianza obtenemos. Si alteramos el proceso para producir árboles menos correlacionados (menor \\(\\rho(x)\\)), podemos mejorar el desempeño de bagging. Sin embargo, estas alteraciones generalmente están acompañadas de incrementos en la varianza (\\(\\sigma^x(x)\\)). 7.3 Bosques aleatorios Los bosques aleatorios son una versión de árboles de bagging decorrelacionados. Esto se logra introduciendo variabilidad en la construcción de los árboles (esto es paradójico - pero la explicación está arriba: aunque la varianza empeora (de cada árbol), la decorrelación de árboles puede valer la pena). 7.3.1 Sabiduría de las masas Una explicación simple de este proceso que se cita frecuentemente es el fenómeno de la sabiduría de las masas: cuando promediamos estimaciones pobres de un gran número de personas (digamos ignorantes), obtenemos mejores estimaciones que cualquiera de las componentes individuales, o incluso mejores que estimaciones de expertos. Supongamos por ejemplo que \\(G_1,G_2,\\ldots, G_M\\) son clasificadores débiles, por ejemplo \\[P(correcto) = P(G_i=G)=0.6\\] para un problema con probabilidad base \\(P(G=1)=0.5\\). Supongamos que los predictores son independientes, y sea \\(G^*\\) el clasificador que se construye por mayoría de votos a partir de \\(G_1,G_2,\\ldots, G_M\\), es decir \\(G^*=1\\) si y sólo si \\(\\#\\{ G_i = 1\\} &gt; M/2\\). Podemos ver que el número de aciertos (X) de \\(G_1,G_2,\\ldots, G_M\\), por independencia, es binomial \\(Bin(M, 0.6)\\). Si \\(M\\) es grande, podemos aproximar esta distribución con una normal con media \\(M*0.6\\) y varianza \\(0.6*0.4*M\\). Esto implica que \\[P(G^* correcto)=P(X &gt; 0.5M) \\approx P\\left( Z &gt; \\frac{0.5M-0.6M}{\\sqrt(0.24M)}\\right) = P\\left(Z &gt; -2.041 \\sqrt{M}\\right)\\] Y ahora observamos que cuando \\(M\\) es grande, la cantidad de la derecha tiende a 1: la masa, en promedio, tiene la razón! Nótese, sin embargo, que baja dependencia entre las “opiniones” es parte crucial del argumento, es decir, las opiniones deben estar decorrelacionadas. El proceso de decorrelación de bosques aleatorios consiste en que cada vez que tengamos que hacer un corte en un árbol de bagging, escoger al azar un número de variables y usar estas para buscar la mejor variable y el mejor punto de corte, como hicimos en la construcción de árboles. Bosques aleatorios Sea \\(m\\) fija. Sea \\({\\mathcal L} =\\{(x^{(i)}, y^{(i)})\\}_{i=1}^n\\) una muestra de entrenamiento, y sean \\[{\\mathcal L}_1^*, {\\mathcal L}_2^*, \\ldots, {\\mathcal L}_B^*,\\] muestras bootstrap de \\({\\mathcal L}\\) (muestreamos con reemplazo los pares \\((x^{(i)}, y^{(i)})\\), para obtener una muestra de tamaño \\(n\\)). Para cada muestra bootstrap construimos un árbol \\[{\\mathcal L}_b^* \\to T_b^*\\] de la siguiente forma: En cada nodo candidato a particionar, escogemos al azar \\(m\\) variables de las disponibles Buscamos la mejor variable y punto de corte (como en un árbol normal) pero solo entre las variables que seleccionamos al azar. Seguimos hasta construir un árbol grande. (Regresión) Promediamos árboles para reducir varianza \\[T^*(x) = \\frac{1}{B}\\sum_{i=b}^B T_b^*(x)\\] (Clasificación) Tomamos votos sobre todos los árboles: \\[T^*(x) = argmax_g \\{ \\# \\{i|T_b^*(x)=g\\}\\}.\\] Podemos también calcular probabilidades promedio sobre todos los árboles. Bosques aleatorios muchas veces reduce el error de predicción gracias a una reducción a veces considerable de varianza. El objetivo final es reducir la varianza alta que producen árboles normales debido a la forma tan agresiva de construir sus cortes. Observaciones 1. El número de variables \\(m\\) que se seleccionan en cada nodo es un parámetro que hay que escoger (usando validación, validación cruzada). 2. Ojo: no se selecciona un conjunto de \\(m\\) variables para cada árbol. En la construcción de cada árbol, en cada nodo se seleccionan \\(m\\) variables como candidatas para cortes. 3. Como inducimos aleatoriedad en la construcción de árboles, este proceso reduce la correlación entre árboles del bosque, aunque también incrementa su varianza. Los bosques aleatorios funcionan bien cuando la mejora en correlación es más grande que la pérdida en varianza. 4. Reducir \\(m\\), a grandes rasgos: - Aumenta el sesgo del bosque (pues es más restringido el proceso de construcción) - Disminuye la correlación entre árboles y aumenta la varianza de cada árbol 5. Intrementar \\(m\\) - Disminuye el sesgo del bosque (menos restricción) - Aumenta la correlacción entre árobles y disminuye la varianza de cada árbol 7.3.2 Ejemplo Regresamos a nuestro ejemplo de spam. Intentemos con 500 árboles, y 6 variables (de 58 variables) para escoger como candidatos en cada corte: library(randomForest) bosque_spam &lt;-randomForest(factor(spam) ~ ., data = spam_entrena, ntree = 1500, mtry = 6, importance=TRUE) Evaluamos desempeño, donde vemos que obtenemos una mejora inmediata con respecto a bagging: probas &lt;- predict(bosque_spam, newdata = spam_prueba, type=&#39;prob&#39;) head(probas) ## 0 1 ## 1 0.009333333 0.9906667 ## 2 0.016666667 0.9833333 ## 3 0.070000000 0.9300000 ## 4 0.398666667 0.6013333 ## 5 0.045333333 0.9546667 ## 6 0.028666667 0.9713333 prop_bosque &lt;- probas[,2] table(prop_bosque&gt; 0.5, spam_prueba$spam) %&gt;% prop.table(2) %&gt;% round(3) ## ## 0 1 ## FALSE 0.971 0.092 ## TRUE 0.029 0.908 Comparemos las curvas ROC para: árbol grande sin podar árbol podado con costo-complejidad bagging de árboles bosque aleatorio Las curvas de precision-recall library(ROCR) pred_arbol &lt;- prediction(prop_arbol_grande[,2], spam_prueba$spam) pred_podado &lt;- prediction(prop_arbol_podado[,2], spam_prueba$spam) pred_bagging &lt;- prediction(prop_bagging, spam_prueba$spam) pred_bosque &lt;- prediction(prop_bosque, spam_prueba$spam) preds_roc &lt;- list(pred_arbol, pred_podado, pred_bagging, pred_bosque) perfs &lt;- lapply(preds_roc, function(pred){ performance(pred, x.measure = &#39;prec&#39;, measure = &#39;rec&#39;) }) plot(perfs[[1]], lwd=2) plot(perfs[[2]], add=TRUE, col=&#39;orange&#39;, lwd=2) plot(perfs[[3]], add=TRUE, col=&#39;gray&#39;, lwd=2) plot(perfs[[4]], add=TRUE, col=&#39;purple&#39;, lwd=2) O las curvas ROC perfs &lt;- lapply(preds_roc, function(pred){ performance(pred, x.measure = &#39;fpr&#39;, measure = &#39;sens&#39;) }) plot(perfs[[1]], lwd=2) plot(perfs[[2]], add=TRUE, col=&#39;orange&#39;, lwd=2) plot(perfs[[3]], add=TRUE, col=&#39;gray&#39;, lwd=2) plot(perfs[[4]], add=TRUE, col=&#39;purple&#39;, lwd=2) 7.3.3 Más detalles de bosques aleatorios. Los bosques aleatorios, por su proceso de construcción, tienen aspectos interesantes. En primer lugar, tenemos la estimación de error de prueba Out-of-Bag (OOB), que es una estimación honesta del error de predicción basada en el proceso de bagging. Obsérvese en primer lugar, que cuando tomamos muestras con reemplazo para construir cada árbol, algunos casos de entrenamiento aparecen más de una vez, y otros casos no se usan en la construcción del árbol. La idea es entonces es usar esos casos excluidos para hacer una estimación honesta del error. Ejemplo Si tenemos una muestra de entrenamiento entrena &lt;- data_frame(x=1:10, y=rnorm(10, 1:10, 5)) entrena ## # A tibble: 10 x 2 ## x y ## &lt;int&gt; &lt;dbl&gt; ## 1 1 0.936 ## 2 2 -2.84 ## 3 3 -5.63 ## 4 4 -2.21 ## 5 5 7.04 ## 6 6 7.09 ## 7 7 13.0 ## 8 8 -0.423 ## 9 9 10.4 ## 10 10 5.03 Tomamos una muestra bootstrap: entrena_boot &lt;- sample_n(entrena, 10, replace = TRUE) entrena_boot ## # A tibble: 10 x 2 ## x y ## &lt;int&gt; &lt;dbl&gt; ## 1 7 13.0 ## 2 10 5.03 ## 3 2 -2.84 ## 4 8 -0.423 ## 5 2 -2.84 ## 6 1 0.936 ## 7 4 -2.21 ## 8 10 5.03 ## 9 8 -0.423 ## 10 8 -0.423 Construimos un predictor mod_boot &lt;- lm(y~x, data = entrena_boot) y ahora obtenemos los datos que no se usaron: prueba_boot &lt;- anti_join(entrena, entrena_boot) ## Joining, by = c(&quot;x&quot;, &quot;y&quot;) prueba_boot ## # A tibble: 4 x 2 ## x y ## &lt;int&gt; &lt;dbl&gt; ## 1 3 -5.63 ## 2 5 7.04 ## 3 6 7.09 ## 4 9 10.4 y usamos estos tres casos para estimar el error de predicción: mean(abs(predict(mod_boot, prueba_boot)-prueba_boot$y)) ## [1] 5.936181 Esta es la estimación OOB (out-of-bag) para este modelo particular. En un principio podemos pensar que quizá por mala suerte obtenemos pocos elementos OOB para evaluar el error, pero en realidad para muestras no tan chicas obtenemos una fracción considerable. Cuando el tamaño de muestra \\(n\\) es grande, el porcentaje esperado de casos que no están en la muestra bootstrap es alrededor del 37% Demuestra usando probabilidad y teoría de muestras con reemplazo. Estimación OOB del error Consideramos un bosque aleatorio \\(T_{ba}\\)con árboles \\(T_1^*, T_2^*, \\ldots, T_B^*\\), y conjunto de entrenamiento original \\({\\mathcal L} =\\{(x^{(i)}, y^{(i)}\\}_{i=1}^n\\). Para cada caso de entrenamiento \\((x^{(i)}, y^{(i)})\\) consideramos todos los árboles que no usaron este caso para construirse, y construimos un bosque \\(T_{ba}^{(i)}\\) basado solamente en esos árboles. La predicción OOB de \\(T_{ba}^{(i)}\\) para \\((x^{(i)}, y^{(i)})\\) es \\[y_{oob}^{(i)} = T_{ba}^{(i)}(x^{(i)})\\] El error OOB del árbol \\(T_{ba}\\) está dado por 1. Regresión (error cuadrático medio) \\[\\hat{Err}_{oob} = \\frac{1}{n} \\sum_{i=1}^n (y^{(i)} - y_{oob}^{(i)})^2\\] 2. Clasificación (error de clasificación) \\[\\hat{Err}_{oob} = \\frac{1}{n}\\sum_{i=1}^n I(y^{(i)} = y_{oob}^{(i)})\\] Para cada dato de entrenamiento, hacemos predicciones usando solamente los árboles que no consideraron ese dato en su construcción. Estas predicciones son las que evaluamos Es una especie de validación cruzada (se puede demostrar que es similar a validacion cruzada leave-one-out), pero es barata en términos computacionales. Como discutimos en validación cruzada, esto hace de OOB una buena medida de error para afinar los parámetros del modelo (principalmente el número \\(m\\) de variables que se escogen en cada corte). Ejempo Para el ejemplo de spam, podemos ver el error OOB ( y matriz de confusión también OOB): bosque_spam ## ## Call: ## randomForest(formula = factor(spam) ~ ., data = spam_entrena, ntree = 1500, mtry = 6, importance = TRUE) ## Type of random forest: classification ## Number of trees: 1500 ## No. of variables tried at each split: 6 ## ## OOB estimate of error rate: 4.96% ## Confusion matrix: ## 0 1 class.error ## 0 1807 54 0.02901666 ## 1 98 1108 0.08126036 Que comparamos con probas &lt;- predict(bosque_spam, newdata = spam_prueba, type=&#39;prob&#39;) prop_bosque &lt;- probas[,2] tab &lt;- table(prop_bosque&gt; 0.5, spam_prueba$spam) %&gt;% prop.table(2) %&gt;% round(3) 1-diag(tab) ## [1] 0.029 0.092 Podemos comparar con el cálculo de entrenamiento, que como sabemos típicamente es una mala estimación del error de predicción: probas &lt;- predict(bosque_spam, newdata = spam_entrena, type=&#39;prob&#39;) prop_bosque &lt;- probas[,2] table(prop_bosque&gt; 0.5, spam_entrena$spam) ## ## 0 1 ## FALSE 1861 11 ## TRUE 0 1195 tab &lt;- table(prop_bosque&gt; 0.5, spam_entrena$spam) %&gt;% prop.table(2) %&gt;% round(3) 1-diag(tab) ## [1] 0.000 0.009 Podemos también monitorear el error OOB conforme agregamos más árboles. Esta gráfica es útil para entender qué tanto esta mejorando el bosque dependiendo del número de árboles: err_spam &lt;- bosque_spam$err.rate %&gt;% as_data_frame %&gt;% mutate(ntrees = row_number()) head(err_spam) ## # A tibble: 6 x 4 ## OOB `0` `1` ntrees ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 0.113 0.0851 0.159 1 ## 2 0.113 0.0853 0.160 2 ## 3 0.109 0.0786 0.158 3 ## 4 0.101 0.0744 0.143 4 ## 5 0.102 0.0715 0.149 5 ## 6 0.0972 0.0712 0.137 6 err_spam &lt;- err_spam %&gt;% gather(métrica, valor, -ntrees) ggplot(err_spam, aes(x=ntrees, y=valor, colour=métrica)) + geom_line() Además de la estimación OOB del error de clasificación, en la gráfica están las estimaciones OOB dada cada una de las clases (probabilidad de clasificar correctamente dada la clase: en problemas binarios son tasa de falsos positivos y tasa de falsos negativos). 7.3.4 Importancia de variables Usando muestras bootstrap y error OOB, es posible tener mediciones útiles de la importancia de una variable en el modelo en un bosque aleatorio (todo esto también fue inventado por Breiman). En primer lugar, consideremos qué significa que una variable sea importante desde el punto predictivo en un modelo. Podemos considerar, por ejemplo: Si quitamos una variable, y el error de predicción se degrada, la variable es importante. Este no es un muy buen enfoque, porque muchas veces tenemos conjuntos de variables correlacionadas. Aún cuando una variable influya en la predicción, si la quitamos, otras variable pueden hacer su trabajo, y el modelo no se degrada mucho (piensa en regresión, en donde incluso esta variable eliminada puede tener un coeficiente grande e influir mucho en la predicción). También requiere ajustar modelos adicionales. Si las predicciones cambian mucho cuando una variable cambia, entonces la variable es importante. Este concepto funciona mejor, al menos desde el punto de vista predictivo. Su defecto es que debemos decidir qué cambios queremos medir. Si el modelo es simple (por ejemplo, lineal), entonces es relativamente fácil usar cambios marginales. Pero en modelos no lineales cambios marginales no necesariamente evalúan correctamente el efecto de la variable sobre las predicciones. La situación se complica adicionalmente si hay interacciones con otras variables, lo que típicamente sucede en métodos basados en árbles. La idea de Breiman, que intenta atender estas observaciones, es como sigue: Consideramos un árbol \\(T^*_j\\) del bosque, con muestra bootstrap \\({\\mathcal L}^*_i\\). Calculamos un tipo de error out-of-bag para el árbol, promediando sobre todos los elementos de \\({\\mathcal L}\\) que no están en \\({\\mathcal L}^*_i\\) \\[\\widehat{Err}_{oob}(T^*_j) = \\frac{1}{A_j}\\sum_{(x^{(i)}, y^{(i)}) \\in {\\mathcal L} -{\\mathcal L}^*_i} L(y^{(i)}, T^*_j(x^{(i)}))\\] donde \\(A_j\\) es el tamaño de \\({\\mathcal L} -{\\mathcal L}^*_i\\). Ahora permutamos al azar la variable \\(X_k\\) en la muestra OOB \\({\\mathcal L} -{\\mathcal L}^*_i\\). Describimos esta operación como \\(x^{(i)} \\to x^{(i)}_k\\). Calculamos el error nuevamente: \\[\\widehat{Err}_{k}(T^*_j) = \\frac{1}{A_j}\\sum_{(x^{(i)}, y^{(i)}) \\in {\\mathcal L} -{\\mathcal L}^*_i} L(y^{(i)}, T^*_j(x_k^{(i)}))\\] Ahora calculamos la degradación del error out-of-bag debido a la permutación: \\[ D_k(T_j^*) = \\widehat{Err}_{k}(T^*_j) - \\widehat{Err}_{oob}(T^*_j) \\] Y promediamos sobre el bosque entero \\[I_k =\\frac{1}{B} \\sum_{j=1}^B D_k(T^*_j)\\] y a esta cantidad le llamamos la importancia (basada en permutaciones) de la variable \\(k\\) en el bosque aleatorio. Es el decremento promedio de capacidad predictiva cuando “quitamos” la variable \\(X_k\\). Nótese que: No podemos “quitar” la variable durante el entrenamiento de los árboles, pues entonces otras variables pueden hacer su trabajo, subestimando su importancia. No podemos “quitar” la variable al medir el error OOB, pues se necesitan todas las variables para poder clasificar con cada árbol (pues cada árbol usa esa variable, o tiene probabilidad de usarla). Pero podemos permutar a la hora calcular el error OOB (y no durante el entrenamiento), rompiendo la relación que hay entre \\(X_k\\) y la variable respuesta. Aunque podríamos usar esta medida para árboles, no es muy buena idea por el problema de “enmascaramiento”. Este problema se aminora en los bosques aleatorios pues todas las variables tienen oportunidad de aportar cortes en ausencia de otras variables. Otra manera de medir importancia para árboles de regresión y clasificación es mediante el decremento de impureza promedio sobre el bosque, para cada variable. Cada vez que una variable aporta un corte en un árbol, la impureza del árbol disminuye. Sumamos, en cada árbol, todos estos decrementos de impureza (cada vez que aparece la variable en un corte) Finalmente, promediamos esta medida de importancia dentro de cada árbol sobre el bosque completo. Repetimos para cada variable. Para árboles de clasificación, usualmente se toma la importancia de Gini, que está basada in la impureza de Gini en lugar de la entropía. La impureza de Gini está dada por \\[I_G(p_1, \\ldots, p_K) = \\sum_{k=1}^K p_k(1-p_k),\\] que es similar a la impureza de entropía que discutimos en la construcción de árboles: \\[I_G(p_1, \\ldots, p_K) = \\sum_{k=1}^K -p_k\\log (p_k),\\] Nótese por ejemplo que ambas toman su valor máximo en \\(p_k=1/K\\) (distribución más uniforme posible sobre las clases), y que son iguales a cero cuando \\(p_k=1\\) para alguna \\(k\\). #### Ejemplo{-} En nuestro ejemplo de spam imp &lt;- importance(bosque_spam, type=1) importancia_df &lt;- data_frame(variable = rownames(imp), MeanDecreaseAccuracy = imp[,1]) %&gt;% arrange(desc(MeanDecreaseAccuracy)) importancia_df ## # A tibble: 58 x 2 ## variable MeanDecreaseAccuracy ## &lt;chr&gt; &lt;dbl&gt; ## 1 cfexc 73.2 ## 2 wfremove 63.1 ## 3 crlaverage 63.0 ## 4 cfdollar 60.3 ## 5 wfhp 55.2 ## 6 crllongest 54.7 ## 7 wffree 54.3 ## 8 crltotal 52.0 ## 9 wfedu 47.8 ## 10 wfyour 45.3 ## # ... with 48 more rows importancia_df &lt;- importancia_df %&gt;% mutate(variable = reorder(variable, MeanDecreaseAccuracy)) ggplot(importancia_df , aes(x=variable, y= MeanDecreaseAccuracy)) + geom_point() + coord_flip() Observación: en el paquete randomForest, las importancias están escaladas por su la desviación estándar sobre los árboles - la idea es que puedan ser interpretados como valores-\\(z\\) (estandarizados). En este caso, nos podríamos fijar en importancias que están por arriba de \\(2\\), por ejemplo. Para obtener los valores no estandarizados (y ver la degradación en desempeño directamente) podemos calcular importance(bosque_spam, type = 1, scale = FALSE) ## MeanDecreaseAccuracy ## X -3.398063e-04 ## wfmake 7.820918e-04 ## wfaddress 1.509922e-03 ## wfall 3.607607e-03 ## wf3d 6.865265e-05 ## wfour 1.415974e-02 ## wfover 2.559785e-03 ## wfremove 3.466735e-02 ## wfinternet 5.113536e-03 ## wforder 1.229169e-03 ## wfmail 2.388153e-03 ## wfreceive 4.081920e-03 ## wfwill 3.701128e-03 ## wfpeople 6.623610e-04 ## wfreport 6.582026e-04 ## wfaddresses 8.486423e-04 ## wffree 2.377365e-02 ## wfbusiness 5.742176e-03 ## wfemail 2.207889e-03 ## wfyou 1.151620e-02 ## wfcredit 3.088054e-03 ## wfyour 1.909754e-02 ## wffont 1.687250e-03 ## wf000 1.358799e-02 ## wfmoney 1.171880e-02 ## wfhp 3.220300e-02 ## wfhpl 1.321378e-02 ## wfgeorge 1.677690e-02 ## wf650 3.714641e-03 ## wflab 1.205268e-03 ## wflabs 2.968365e-03 ## wftelnet 1.252834e-03 ## wf857 5.362343e-04 ## wfdata 8.375305e-04 ## wf415 4.832454e-04 ## wf85 2.268768e-03 ## wftechnology 1.603492e-03 ## wf1999 6.902904e-03 ## wfparts 7.131246e-05 ## wfpm 1.255157e-03 ## wfdirect 6.650049e-04 ## wfcs 5.034624e-04 ## wfmeeting 3.209452e-03 ## wforiginal 8.825843e-04 ## wfproject 6.864723e-04 ## wfre 4.000573e-03 ## wfedu 1.049319e-02 ## wftable 2.721772e-05 ## wfconference 4.790163e-04 ## cfsc 1.527800e-03 ## cfpar 4.051610e-03 ## cfbrack 9.434229e-04 ## cfexc 3.979771e-02 ## cfdollar 3.244195e-02 ## cfpound 9.215076e-04 ## crlaverage 2.784469e-02 ## crllongest 3.617719e-02 ## crltotal 3.151068e-02 7.3.5 Ajustando árboles aleatorios. El parámetro más importante de afinar es usualmente \\(m\\), el número de variables que se escogen al azar en cada nodo. A veces podemos obtener algunas ventajas de afinar el número mínimo de observaciones por nodo terminal y/o el número mínimo de observaciones por nodo para considerar hacer cortes adicionales Usualmente corremos tantos árboles como podamos (cientos, miles), o hasta que se estabiliza el error. Aumentar más arboles rara vez producen sobreajuste adicional (aunque esto no quiere decir que los bosques aleatorios no puedan sobreajustar!) Ejemplo Consideremos datos de (casas en venta en Ames, Iowa)[https://ww2.amstat.org/publications/jse/v19n3/decock.pdf]. Queremos predecir el precio listado de una casa en función de las características de las casa. El análisis completo (desde limpieza y exploración) está en scripts/bosque-housing.Rmd 7.3.6 Ventajas y desventajas de árboles aleatorios Ventajas: Entre los métodos estándar (off-the shelf), son quizá el mejor método: tienen excelentes tasas de error de predicción. Los bosques aleatorios son relativamente fáciles de entrenar (usualmente 1 o 2 parámetros) y rápidos de ajustar. Heredan las ventajas de los árboles: no hay necesidad de transformar variables o construir interacciones (pues los árboles pueden descubrirlas), son robustos a valores atípicos. Igual que con los árboles, las predicciones de los bosques siempre están en el rango de las variables de predicción (no extrapolan) Desventajas: - Pueden ser lentos en la predicción, pues muchas veces requieren evaluar grandes cantidades de árboles. - No es tan simple adaptarlos a distintos tipos de problemas (por ejemplo, como redes neuronales, que combinando capas podemos construir modelos ad-hoc a problemas particulares). - La falta de extrapolación puede ser también un defecto (por ejemplo, cuando hay una estructura lineal aproximada). 7.3.7 Tarea (para 23 de octubre) Las instrucciones están en scripts/tarea_arboles_bosques.Rmd "],
["validacion-de-modelos-problemas-comunes.html", "Sección 8 Validación de modelos: problemas comunes 8.1 Filtración de datos 8.2 Series de tiempo 8.3 Filtración en el preprocesamiento 8.4 Uso de variables fuera de rango temporal 8.5 Datos en conglomerados y muestreo complejo 8.6 Muestras de validación chicas 8.7 Otros ejemplos 8.8 Resumen", " Sección 8 Validación de modelos: problemas comunes En aprendizaje de máquina, el ajuste y afinación de parámetros es tan importante como la evaluación de desempeño o validación de los modelos resultantes. Ninguna funciona bien sin que la otra sea correctamente ejecutada. Hemos visto que ambas partes tienen dificultades algunas veces sutiles (tanto el ajuste y optimización como la evaluación de las predicciones) que pueden hacer fracasar nuestro ejercicio de modelación. En esta parte hablaremos de la evaluación de modelos. En aprendizaje máqina, considerando que utilizamos relativamente pocos supuestos teóricos, dependemos de esa evaluación para asegurarnos que estamos capturando patrones reales y útiles en los datos. Todo lo que veremos aplica tanto a separación de muestras de validación como a uso de algún tipo de validación cruzada (validación cruzada, estimación OOB en árboles, validación bootstrap, etc.) 8.1 Filtración de datos La filtración de datos ocurre cuando nuestro proceso de validación está contaminado por información que en la tarea real de predicción no tendremos disponible. En consecuencia, nuestras estimaciones de desempeño del modelo (validación) son optimistas en relación al desempeño verdadero. También podemos pensar en filtraciones tanto al conjunto de entrenamiento y validación, cuando ambos están contaminados con información que no estará disponible al momento de hacer las predicciones. Esto produce modelos que no es posible poner en producción. El primer tipo de filtraciones es más difícil de detectar antes de la puesta en producción de los modelos. El segundo tipo puede descubrirse cuando nos damos cuenta de que no es posible implementar en producción nuestro modelo porque no hay información disponible que usamos para construirlo (o peor, cuando cometemos un error en la implementación y el modelo se desempeña mal posterioremente). Veamos el primer caso: filtración de conjuntos de validación al conjunto de entrenamiento. La filtración de datos puede ocurrir de muchas maneras, muchas veces inesperadas. Quizá uno de los ejemplos más típicos es el validación de modelos de series de tiempo. 8.2 Series de tiempo Comenzamos con un ejemplo simulado. Haremos varias simulaciones para incorporar la variación producida en los modelos por la muestra de entrenamineto library(methods) library(randomForest) library(tidyverse) library(glmnet) simular_datos &lt;- function(n = 500,...){ datos &lt;- data_frame(t=1:n, x = rnorm(n,0,1)) y &lt;- numeric(n) #nivel &lt;- numeric(n) #nivel[1] &lt;- 10 y[1] &lt;- datos$x[1] #+ nivel[1] for(i in 2:n){ #nivel[i] &lt;- nivel[i-1] + rnorm(1, 0, 0.1) #y[i] &lt;- 0.01*i + datos$x[i] + nivel[i] + rnorm(1,0,0.05) y[i] &lt;- 0.01*i + datos$x[i] + 0.9*y[i-1] + rnorm(1,0,0.05) } datos$y &lt;- y datos } separar &lt;- function(df, prop){ df &lt;- df %&gt;% rowwise %&gt;% mutate(tipo = ifelse(t &gt; floor(nrow(df)*(prop[1]+prop[2])), &#39;prueba&#39;, sample(c(&#39;entrena&#39;,&#39;valida&#39;),1))) split(df, df$tipo) } ajustar_evaluar &lt;- function(df_split){ mod_1 &lt;- randomForest(y ~ x + t, data = df_split[[&#39;entrena&#39;]]) error_valida &lt;- sd(predict(mod_1, df_split[[&#39;valida&#39;]])-df_split[[&#39;valida&#39;]]$y) error_prueba &lt;- sd(predict(mod_1, df_split[[&#39;prueba&#39;]])-df_split[[&#39;prueba&#39;]]$y) c(error_valida = error_valida, error_prueba = error_prueba) } Por ejemplo: ggplot(simular_datos(), aes(x=t, y=y)) + geom_line() Separamos ingenuamente entrenamiento y prueba y ajustamos un modelo de regresión: errores &lt;- simular_datos(500) %&gt;% separar(prop= c(0.4,0.4,0.2)) %&gt;% ajustar_evaluar errores ## error_valida error_prueba ## 1.959697 2.637622 reps_1 &lt;- map(1:50, simular_datos, n = 500) %&gt;% map(separar, prop= c(0.6,0.2,0.2)) %&gt;% map(ajustar_evaluar) %&gt;% transpose %&gt;% map(unlist) %&gt;% as_data_frame gr_reps_1 &lt;- reps_1 %&gt;% mutate(rep = row_number()) %&gt;% gather(tipo, valor, -rep) ggplot(reps_1, aes(x=error_valida, y=error_prueba)) + geom_point() + geom_abline() + xlim(c(0,10)) + ylim(c(0,10)) Y vemos que los errores de validación son consistentemente menores, y por margen alto, que los errores de prueba. Podemos ver que hay un desacuerdo entre el proceso de validación y de prueba: Los valores de validación y de entrenamiento están intercalados, pues fueron seleccionados al azar. Pero el error de predicción se calcula para el futuro, y esos datos futuros no tienen traslape en tiempo con la muestra de entrenamiento. De esta manera, podríamos decir que cuando hacemos predicciones para el conjunto de validación, se nos filtran valores del futuro cercano, lo cual no tenemos disponible a la hora de probar el modelo. Podríamos cambiar nuestra manera de probar el modelo, escogendo la muestra de validación al final del periodo. separar_valid_futura &lt;- function(df, prop){ df &lt;- df %&gt;% rowwise %&gt;% mutate(tipo = ifelse(t &lt; nrow(df)*prop[1], &#39;entrena&#39;, ifelse(t&lt;nrow(df)*(prop[1]+prop[2]),&#39;valida&#39;,&#39;prueba&#39;))) split(df, df$tipo) } reps_2 &lt;- map(1:50, simular_datos, n = 500) %&gt;% map(separar_valid_futura, prop= c(0.6,0.2,0.2)) %&gt;% map(ajustar_evaluar) %&gt;% transpose %&gt;% map(unlist) %&gt;% as_data_frame gr_reps_2 &lt;- reps_2 %&gt;% mutate(rep = row_number()) %&gt;% gather(tipo, valor, -rep) ggplot(gr_reps_2, aes(x=valor, group=tipo, fill=tipo)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ggplot(reps_2, aes(x=error_valida, y=error_prueba)) + geom_point() + geom_abline() + xlim(c(0,10)) + ylim(c(0,10)) Observaciónes: Nótese que la fuente más grande de error no proviene de el hecho de que el sistema que queremos predecir es dinámico (el primer modelo, por ejemplo, usa valores más cercanos a los del futuro que queremos predecir). El problema es la filtración de datos del pasado cercano y futuro desde el conjunto de validación al de prueba. Este era parte del problema en hacer validación aleatoria simple en el concurso de las fotos. Un tratamiento de este tipo para el problema de las fotos ayudaba a obtener estimaciones más realistas del desempeño. 8.3 Filtración en el preprocesamiento Cuando preprocesamos datos para incluir en el modelo, es importante asegurarnos de no filtrar información de los datos de validación hacia los datos de enrenamiento. Nos aseguramos de esto si nuestro procesamiento, por ejemplo, es caso por caso con parámetros preestablecidos (no calculamos agregados de todos los datos, por ejemplo), o para más seguridad, haciendo por separado el preprocesamiento de entrenamiento y validación y considerando qué valores pasamos de un conjunto de datos al otro. Un ejemplo clásico es el de selección de variables, como vimos en el examen. Repetiremos varias veces para confirmar más sólidamente la idea seleccion_ajuste &lt;- function(...){ y &lt;- rbinom(50, 1, 0.5) x &lt;- matrix(rnorm(50*500,0,1), 50, 500) correlaciones &lt;- cor(x, y) # Seleccionamos las 50 variables con mayor correlación vars_selec &lt;- order(correlaciones, decreasing=TRUE)[1:50] # Hacemos la validación cruzada usual - que en este caso es errónea est_val_cruzada &lt;- sapply(1:10, function(i){ x_vc &lt;- x[-((5*i -4):(5*i)),] y_vc &lt;- y[-((5*i -4):(5*i))] mod &lt;- glmnet(y=y_vc, x= x_vc[,vars_selec], alpha=0, family=&#39;binomial&#39;, lambda = 0.5) preds_p &lt;- predict(mod, newx = x[((5*i -4):(5*i)),vars_selec])[,1] mean((preds_p &gt; 0) != y[((5*i -4):(5*i))]) }) error_validacion &lt;- mean(est_val_cruzada) modelo &lt;- glmnet(y=y, x= x[,vars_selec], alpha=0, family=&#39;binomial&#39;, lambda = 0.5) y_p &lt;- rbinom(1000, 1, 0.5) x_p &lt;- matrix(rnorm(1000*500,0,1), 1000, 500) preds_p &lt;- predict(modelo, newx = x_p[, vars_selec])[,1] error_prueba &lt;- mean((preds_p &gt; 0) != y_p) c(&#39;error_valida&#39;=error_validacion, &#39;error_prueba&#39;=error_prueba) } seleccion_ajuste() ## error_valida error_prueba ## 0.080 0.471 El resultado es catastrófico otra vez: errores_selec &lt;- map(1:30, seleccion_ajuste) %&gt;% transpose %&gt;% map(unlist) %&gt;% as.data.frame ggplot(errores_selec, aes(x=error_prueba, y=error_valida)) + geom_point() + geom_abline(colour=&#39;red&#39;) + xlim(c(0,1)) + ylim(c(0,1)) Esto lo podemos arreglar haciendo la selección de variables dentro de cada corte de validación cruzada, y así no permitimos que los datos de validación se filtren al conjunto de entrenamiento seleccion_ajuste_correcto &lt;- function(...){ y &lt;- rbinom(50, 1, 0.5) x &lt;- matrix(rnorm(50*500,0,1), 50, 500) est_val_cruzada &lt;- sapply(1:10, function(i){ x_vc &lt;- x[-((5*i -4):(5*i)),] y_vc &lt;- y[-((5*i -4):(5*i))] correlaciones_vc &lt;- cor(x_vc, y_vc) vars_selec &lt;- order(correlaciones_vc, decreasing=TRUE)[1:50] mod &lt;- glmnet(y=y_vc, x= x_vc[,vars_selec], alpha=0, family=&#39;binomial&#39;, lambda = 0.5) preds_p &lt;- predict(mod, newx = x[((5*i -4):(5*i)),vars_selec])[,1] mean((preds_p &gt; 0) != y[((5*i -4):(5*i))]) }) error_validacion &lt;- mean(est_val_cruzada) y_p &lt;- rbinom(1000, 1, 0.5) x_p &lt;- matrix(rnorm(1000*500,0,1), 1000, 500) correlaciones &lt;- cor(x, y) vars_selec &lt;- order(correlaciones, decreasing=TRUE)[1:50] modelo &lt;- glmnet(y=y, x= x[,vars_selec], alpha=0, family=&#39;binomial&#39;, lambda = 0.5) preds_p &lt;- predict(modelo, newx = x_p[, vars_selec])[,1] error_prueba &lt;- mean((preds_p &gt; 0) != y_p) c(&#39;error_valida&#39;=error_validacion, &#39;error_prueba&#39;=error_prueba) } errores_selec &lt;- map(1:30, seleccion_ajuste_correcto) %&gt;% transpose %&gt;% map(unlist) %&gt;% as.data.frame ggplot(errores_selec, aes(x=error_prueba, y=error_valida)) + geom_point() + geom_abline(colour=&#39;red&#39;) + xlim(c(0,1)) + ylim(c(0,1)) 8.4 Uso de variables fuera de rango temporal Otra razón por la que nuestro proceso de validación puede estar contaminado es porque usamos agregados que no están disponibles al momento de la predicción, y están relacionados con la variable que queremos predecir. La contaminación puede ser del conjunto de validación al de entrenamiento, o puede incluir tanto entrenamiento como validación. Imaginemos que queremos predecir los clientes que se van a quedar y los que se van a ir en función de las visitas que hacen a un sitio. Vamos a simular el tiempo que se queda cada cliente independiente de otras variables, y construimos una variable de entrada, el número de visitas, que depende del tiempo que un cliente permanece. Por simplicidad, suponemos que todos los clientes empiezan en el tiempo 0. Vamos a suponer durante el tiempo 0.5 y 1.5, hubo una campaña de ventas para intentar recuperar a clientes abandonadores. Una fracción los clientes que abandonaron entre el tiempo 0.5 y 1.5 recibieron una llamada de servicio a cliente. Esto está registrado en la base de datos. simular_clientes &lt;- function(n,...){ tiempo_cliente &lt;- rexp(n, 0.5) llamada &lt;- ifelse(tiempo_cliente &gt; 0.5 &amp; tiempo_cliente &lt; 1.5, rbinom(1,1,0.9), 0) #cuántas visitas, dependen del tiempo (proceso de poisson) num_visitas &lt;- 1 + rpois(n, 5*tiempo_cliente) #calculamos los tiempos cuando ocurrieron esos eventos tiempos &lt;- lapply(1:n, function(i){ c(0, runif(num_visitas[i]-1, 0, tiempo_cliente[i]))}) df &lt;- data_frame(id_cliente=1:n, visitas = tiempos, tiempo_cliente = tiempo_cliente, llamada = llamada) df } set.seed(234) simular_clientes(1) %&gt;% unnest ## # A tibble: 2 x 4 ## id_cliente tiempo_cliente llamada visitas ## &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1 0.982 1 0 ## 2 1 0.982 1 0.762 clientes_futura &lt;- simular_clientes(20000) %&gt;% unnest Ahora supongamos que hoy estamos en el tiempo t=2, así que los datos que tenemos son los siguientes (también calculamos cuántas visitas ha tendido cada cliente hoy: clientes_hoy &lt;- filter(clientes_futura, visitas &lt; 2) num_visitas_hoy &lt;- clientes_hoy %&gt;% group_by(id_cliente) %&gt;% summarise(num_visitas=n()) Queremos calificar a nuestros clientes actuales con probabilidad de que se vaya, y queremos también evaluar esta predicción. Para hacer esto, usamos los datos con tiempo &lt; 1. ¿Quienes no se han ido? Filtramos clientes activos al tiempo t=1 y vemos quiénes abandonaron al mes t=2 (próximo mes): clientes_1 &lt;- filter(clientes_hoy, tiempo_cliente &gt; 1) %&gt;% mutate(abandona = tiempo_cliente &lt; 2) Para hacer nuestro modelo, ahora usamos el número de visitas de hoy: datos_mod &lt;- clientes_1 %&gt;% left_join(num_visitas_hoy) ## Joining, by = &quot;id_cliente&quot; Y ahora dividimos entre entrenamiento y prueba: set.seed(72427) datos_mod &lt;- datos_mod %&gt;% group_by(id_cliente) %&gt;% summarise(u = runif(1,0,1), abandona = first(abandona), num_visitas=first(num_visitas), llamada = first(llamada)) entrena &lt;- filter(datos_mod, u &lt; 0.5) valida &lt;- filter(datos_mod, u &gt;= 0.5) Ajustamos nuestro modelo mod_1 &lt;- glm(abandona ~ num_visitas + llamada, entrena, family = &#39;binomial&#39;) summary(mod_1) ## ## Call: ## glm(formula = abandona ~ num_visitas + llamada, family = &quot;binomial&quot;, ## data = entrena) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -1.24755 -0.70896 -0.53240 0.00014 2.46293 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 0.32076 0.12668 2.532 0.0113 * ## num_visitas -0.15735 0.01229 -12.799 &lt;2e-16 *** ## llamada 19.44652 172.98954 0.112 0.9105 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 8186.9 on 6114 degrees of freedom ## Residual deviance: 4750.6 on 6112 degrees of freedom ## AIC: 4756.6 ## ## Number of Fisher Scoring iterations: 17 Esto parece tener sentido: cuantas más visitas, menor proabilidad de abandonar. Probamos (con devianza) preds &lt;- predict(mod_1, valida, type = &#39;response&#39;) -2*mean(valida$abandona*log(preds) + (1-valida$abandona)*log(1-preds)) ## [1] 0.7876797 Así que parece ser que nuestro modelo está haciendo una predicción razonablemente buena. Ahora calificamos a los clientes corrientes del día de hoy (t=2) prueba &lt;- clientes_hoy %&gt;% filter(tiempo_cliente&gt;=2) %&gt;% group_by(id_cliente) %&gt;% summarise(num_visitas = length(visitas), tiempo_cliente = first(tiempo_cliente), llamada = first(llamada)) prueba$abandona &lt;- prueba$tiempo_cliente &lt; 3 preds &lt;- predict(mod_1, prueba, type = &#39;response&#39;) -2*mean(prueba$abandona*log(preds) + (1-prueba$abandona)*log(1-preds)) ## [1] 1.571454 Y nuestro modelo se degrada considerablemente - no supimos predecir los abandonadores en el próximo mes. ¿Qué está mal? En primer lugar, tenemos filtración de datos porque la variable llamada contiene información futura del abandono de los clientes - aquellos clientes que abandonaron entre t=1 y t=1.5 usaron una llamada, y esto contamina nuestra muestra de entrenamiento con una variable que indica directamente abandono entre t=1 y t=2. No podemos usar esta variable, porque cuando queramos hacer predicciones no vamos a saber que ventas llamó en el futuro a una persona porque había abandonado. Ajustamos nuestro modelo sin llamada: mod_1 &lt;- glm(abandona ~ num_visitas , entrena, family = &#39;binomial&#39;) summary(mod_1) ## ## Call: ## glm(formula = abandona ~ num_visitas, family = &quot;binomial&quot;, data = entrena) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.1191 -0.9487 -0.5624 1.0391 2.7870 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 2.43313 0.09974 24.39 &lt;2e-16 *** ## num_visitas -0.29981 0.01028 -29.17 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 8186.9 on 6114 degrees of freedom ## Residual deviance: 7089.2 on 6113 degrees of freedom ## AIC: 7093.2 ## ## Number of Fisher Scoring iterations: 4 y probamos preds &lt;- predict(mod_1, valida, type = &#39;response&#39;) -2*mean(valida$abandona*log(preds) + (1-valida$abandona)*log(1-preds)) ## [1] 1.159981 Y como esperábamos, el error es más grande. Ahora calificamos a los clientes corrientes del día de hoy (t=2) prueba &lt;- clientes_hoy %&gt;% filter(tiempo_cliente&gt;=2) %&gt;% group_by(id_cliente) %&gt;% summarise(num_visitas = length(visitas), tiempo_cliente = first(tiempo_cliente), llamada = first(llamada)) prueba$abandona &lt;- prueba$tiempo_cliente &lt; 3 preds &lt;- predict(mod_1, prueba, type = &#39;response&#39;) -2*mean(prueba$abandona*log(preds) + (1-prueba$abandona)*log(1-preds)) ## [1] 1.548026 y vemos que todavía tenemos problemas, aunque menos graves. ¿Qué está pasando? Tenemos filtración adicional de datos porque usamos las visitas totales hasta hoy. Cuando este número es grande, quiere decir que un cliente no abandona en el futuro. Así en el modelo usamos el hecho de que no había abandonado para predecir que no abandonó (!!) Podemos corregir nuestro modelo usando el número de visitas antes del momento \\(t=1\\), que es nuestro punto de corte para la predicción: num_visitas_1 &lt;- clientes_hoy %&gt;% filter(visitas &lt; 1) %&gt;% group_by(id_cliente) %&gt;% summarise(num_visitas=n()) datos_mod_2 &lt;- clientes_1 %&gt;% left_join(num_visitas_1) ## Joining, by = &quot;id_cliente&quot; Y ahora dividimos entre entrenamiento y prueba: set.seed(72427) datos_mod_2 &lt;- datos_mod_2 %&gt;% group_by(id_cliente) %&gt;% summarise(u = runif(1,0,1), abandona = first(abandona), num_visitas=first(num_visitas), llamada=first(llamada)) entrena_2 &lt;- filter(datos_mod_2, u &lt; 0.5) valida_2 &lt;- filter(datos_mod_2, u &gt;= 0.5) Ajustamos nuestro modelo mod_2 &lt;- glm(abandona ~num_visitas, entrena_2, family = &#39;binomial&#39;) summary(mod_2) ## ## Call: ## glm(formula = abandona ~ num_visitas, family = &quot;binomial&quot;, data = entrena_2) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -1.0237 -1.0022 -0.9862 1.3634 1.4301 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -0.35920 0.07556 -4.754 2e-06 *** ## num_visitas -0.01360 0.01179 -1.153 0.249 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 8186.9 on 6114 degrees of freedom ## Residual deviance: 8185.6 on 6113 degrees of freedom ## AIC: 8189.6 ## ## Number of Fisher Scoring iterations: 4 Nótese que el coeficiente de num_visitas es mucho más chico esta vez. Validamos: preds &lt;- predict(mod_2, valida, type = &#39;response&#39;) -2*mean(valida$abandona*log(preds) + (1-valida$abandona)*log(1-preds)) ## [1] 1.323245 Ahora calificamos a los clientes corrientes del día de hoy (t=2) y vemos qué pasa: prueba &lt;- clientes_hoy %&gt;% filter(tiempo_cliente&gt;=2) %&gt;% group_by(id_cliente) %&gt;% summarise(num_visitas = length(visitas), tiempo_cliente = first(tiempo_cliente), llamada = first(llamada)) prueba$abandona &lt;- prueba$tiempo_cliente &lt; 3 preds &lt;- predict(mod_2, prueba, type = &#39;response&#39;) -2*mean(prueba$abandona*log(preds) + (1-prueba$abandona)*log(1-preds)) ## [1] 1.336908 Y vemos que nuestra validación y desempeño real coinciden, pues nuestro ejercicio de validación ya coincide con la tarea de predicción que nos interesa. En este caso, incluso nuestro proceso de entrenamiento está contaminado con datos que no tendremos cuando hacemos predicciones. Desgraciadamente, en este ejemplo simulado no pudimos hacer nada para predecir abandono (por construcción). Pero una validación incorrecta parecía indicar que nuestro modelo podría aportar algo. 8.5 Datos en conglomerados y muestreo complejo En muestras complejas, con el fin de reducir costos, muchas veces se muestrean casos dentro de lo que se llama comunmente unidades primarias de muestreo. Por ejemplo, las unidades primarias de muestreo pueden ser manzanas, y se muestrean varios hogares dentro de cada manzana. Es más simple técnicamente y mejor desde punto de vista del error tomar hogares al azar (no agrupados), pero los costos generalmente aumentan mucho si no usamos alguna agrupación - en este ejemplo, el encuestador tendría que transportarse continuamente para levantar encuestas que fueran seleccionadas sin agrupaciones. Como casos dentro de unidades primarias de muestreo son similares, y la mayor parte de las unidades primarias de muestreo no son muestreadas, tenemos un riesgo en nuestra validación: si hacemos conjuntos de validación al azar, podemos incluir casos de las mismas unidades primarias dentro de entremiento y validación. La homogeneidad de casos dentro de unidades primarias hace fácil predecir casos de validación, o dicho de otra manera: se nos está filtrando información desde el conjunto de validación al de entrenamiento (a través del comportamiento común dentro de unidades primarias de muestreo). En la realidad, observaremos probablemente casos para los que no tenemos ejemplos de unidades primarias. Así que tenemos que construir nuestra validación para que refleje esta tarea. set.seed(12) upms &lt;- seq(1,100,1) simular_upms &lt;- function(n){ map(seq(1, n, 1), function(upm){ num_upm &lt;- runif(1, 10, 100) a &lt;- runif(1, 0, 100) b &lt;- runif(1, 0, 1) x &lt;- rnorm(num_upm, 0, 0.2) z &lt;- rnorm(1, 0, 1) data_frame(upm = upm, x = x, z= z, y = a + b*x + rnorm(num_upm, 0, 1)) }) %&gt;% bind_rows } dat &lt;- simular_upms(n=100) prueba &lt;- simular_upms(1000) dat &lt;- dat %&gt;% mutate(u=runif(nrow(dat), 0,1)) entrena &lt;- dat %&gt;% filter(u &lt; 0.5) valida &lt;- dat %&gt;% filter(u &gt; 0.5) mod_1 &lt;- randomForest(y~x+z, data=entrena) sd(predict(mod_1, valida)-valida$y) ## [1] 13.64769 sd(predict(mod_1, prueba)- prueba$y) ## [1] 33.66098 La diferencia es considerable. Podemos arreglar haciendo la validación separando distintos upms. dat &lt;- dat %&gt;% mutate(u=runif(nrow(dat), 0,1)) entrena &lt;- dat %&gt;% filter(upm &lt; 50) valida &lt;- dat %&gt;% filter(upm &gt;= 50) mod_1 &lt;- randomForest(y~x+z, data=entrena) sd(predict(mod_1, valida)-valida$y) ## [1] 39.08368 sd(predict(mod_1, prueba)- prueba$y) ## [1] 36.99774 En encuestas reales, este efecto puede variar dependiendo de la capacidad del modelo, el diseño de la encuesta (por ejemplo, si las unidades primarias de muestreo son más homogéneas o menos homogéneas, etc), y puede ir desde un efecto prácticamente ignorable hasta uno muy grande. Ejemplo Otro ejemplo de datos en conglomerados está en nuestro ejemplo de reconocimiento de dígitos. Considera por qué es importante separar a las personas que escribieron los dígitos en entrenamiento y validación, y no los dígitos particulares. 8.5.1 Censura y evaluación incompleta Algunas veces, no todos los datos que quisiéramos tener están disponibles para construir nuestros modelos: algunos clientes o casos, por ejemplo, no están en nuestros datos (son datos censurados). Sin embargo, al poner los modelos en producción, hacemos predicciones para todos los datos, y nuestras predicciones malas para aquellos casos antes censurados pueden dañar severamente el desempeño de nuestros modelos. Este es un ejemplo de datos faltantes, pero más serio: todos las variables de algunos casos están faltantes, y algunas veces ni siquiera sabemos esto. 8.5.2 Ejemplo: tiendas cerradas Supongamos que queremos predecir las ventas de tiendas según las características del un local potencial después de un año de ser abiertas. Este modelo tiene el propósito de dedicir si abrir o uno una tienda en un local posible. Vamos a hacer este ejemplo con datos simulados. h &lt;- function(z) 1/(1+exp(-z)) simular_tiendas &lt;- function(n){ #Variables de entrada x &lt;- rnorm(n, 0, 1) a &lt;- rnorm(n, 0, 1) w &lt;- rbinom(n, 1, 0.5) # respuesta en ventas después de un año z &lt;- 2*x + a+ w + rnorm(n, 0, 0.1) ventas &lt;- exp(z)*1e5 # prob de cerrar es alta cuando las ventas son más bajas p_cerrar &lt;- h(-3 - 2*z) # Algunas tiendas quebraron (dependiendo del nivel de ventas) cerrada &lt;- rbinom(n, 1, prob = p_cerrar) data_frame(id_tienda=1:n, x=x, w=w, a=a, ventas=ventas, cerrada = cerrada) } simular_tiendas(10) ## # A tibble: 10 x 6 ## id_tienda x w a ventas cerrada ## &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 1 -0.295 0 0.693 117121. 0 ## 2 2 -1.15 0 1.08 28253. 0 ## 3 3 0.369 0 -0.843 113515. 0 ## 4 4 -1.19 1 -0.886 9871. 1 ## 5 5 -2.08 0 1.78 9607. 0 ## 6 6 -1.97 1 -0.822 2160. 1 ## 7 7 0.533 0 -0.126 257014. 0 ## 8 8 -1.09 1 0.699 56708. 0 ## 9 9 0.120 1 0.848 779766. 0 ## 10 10 -1.25 0 2.72 122474. 0 set.seed(923) tiendas_entrena_valida &lt;- simular_tiendas(2000) tiendas_prueba &lt;- simular_tiendas(2000) table(tiendas_entrena_valida$cerrada) ## ## 0 1 ## 1571 429 Ahora supongamos que el sistema borró los datos históricos de las tiendas que cerraron. Nuestros datos para trabajar son entrena_valida &lt;- filter(tiendas_entrena_valida, cerrada == 0) nrow(entrena_valida) ## [1] 1571 set.seed(72427) datos &lt;- entrena_valida %&gt;% ungroup %&gt;% mutate(u = runif(nrow(entrena_valida),0,1)) entrena &lt;- filter(datos, u &lt; 0.5) %&gt;% select(-u) valida &lt;- filter(datos, u &gt;= 0.5) %&gt;% select(-u) nrow(entrena) ## [1] 805 nrow(valida) ## [1] 766 mod_log &lt;- randomForest(log(ventas)~x+w+a, data=entrena, mtry=3) #mod_log &lt;- lm(log(ventas)~x+w+a, data=entrena) preds_log &lt;- predict(mod_log, valida) valida$preds_valida &lt;- preds_log sd(preds_log-log(valida$ventas)) ## [1] 0.3004177 ggplot(valida, aes(y=log(ventas), x= preds_valida))+ geom_point() + geom_abline(colour=&#39;red&#39;) Cuando lo aplicamos a nuevas tiendas, desgraciadamente, observamos preds_log &lt;- predict(mod_log, tiendas_prueba) sd(preds_log-log(tiendas_prueba$ventas)) ## [1] 0.5729648 El error es más alto de lo que esperábamos, y nuestra predicción para las tiendas malas es especialmente malo: tiendas_prueba$pred_prueba &lt;- preds_log ggplot(tiendas_prueba, aes(y=log(ventas), x= pred_prueba,colour=cerrada))+ geom_point() + geom_abline(colour=&#39;red&#39;) Veamos la cadena que produjo este error: La variable cerrar está naturalmente relacionada con ventas: cuanto más bajas son las ventas al año, mayor la probabilidad de cerrar. En los datos de entrenamiento no tenemos las tiendas que cerraron (que tienen ventas más bajas) - estos datos están censurados Nuestro modelo se desempeña bien para tiendas que tienen ventas relativamente altas. Pero falla cuando intentamos predecir tiendas con ventas relativamente bajas. Soluciones para este problema son analizar cuidadosamente que datos han sido censurados de las bases de datos. En caso de que haya ocurrido, rara vez todos los datos fueron borrados: por ejemplo, quizá la variable respuesta se puede conseguir, y existen algunas de las variables explicativas - en este caso podríamos intentar imputación de datos. 8.6 Muestras de validación chicas Una muestra de validación chica es casi tan malo como una muestra de entrenamiento chica. Una muestra de entrenamiento grande nos permite intentar modelos más complejos y flexible. Pero con una muestra de validación demasiado chica, no es posible discriminar entre los que se desempeñan bien y mal, desaprovechando las ganancias que podríamos tener por tener una buena muestra de entrenamiento. Podemos ver la situación con el ejemplo de spam spam &lt;- read_csv(&#39;datos/spam-entrena.csv&#39;) spam_prueba &lt;- read_csv(&#39;datos/spam-prueba.csv&#39;) nrow(spam) ## [1] 3067 nrow(spam_prueba) ## [1] 1534 spam &lt;- bind_cols(spam, data.frame(matrix(rnorm(nrow(spam)*100,0,1), nrow(spam), 100))) spam_prueba &lt;- bind_cols(spam_prueba, data.frame(matrix(rnorm(nrow(spam_prueba)*100,0,1), nrow(spam_prueba), 100))) Haremos cortes de distinto tamaño entrenamiento/validación y veremos qué desempeño resulta de escoger nuestro modelo final (lasso) usando una muestra de validación. library(glmnet) separar &lt;- function(datos, prop_entrena){ n &lt;- nrow(datos) datos &lt;- datos %&gt;% mutate(u = runif(n, 0, 1)) %&gt;% mutate(tipo = ifelse(u &lt; prop_entrena, &#39;entrena&#39;, &#39;validación&#39;)) %&gt;% select(-u) print(table(datos$tipo)) datos } devianza &lt;- function(z, y){ apply(-2*(y*z - log(1+exp(z))),2,mean) } ajusta_valida &lt;- function(datos, spam_prueba){ entrena &lt;- datos %&gt;% filter(tipo ==&#39;entrena&#39;) %&gt;% select(-tipo) validación &lt;- datos %&gt;% filter(tipo==&#39;validación&#39;) %&gt;% select(-tipo) x &lt;- as.matrix(entrena %&gt;% select(-spam)) y &lt;- entrena$spam mod &lt;- glmnet(x = x, y = y, alpha = 0.0, family =&#39;binomial&#39;, lambda = exp(seq(-20, -2, 0.25) )) x_val &lt;- as.matrix(validación %&gt;% select(-spam)) y_val &lt;- validación$spam x_prueba &lt;- as.matrix(spam_prueba %&gt;% select(-spam)) y_prueba &lt;- spam_prueba$spam val_error &lt;- devianza(predict(mod, x_val, type=&#39;response&#39;), y_val) prueba_error &lt;- devianza(predict(mod, x_prueba, type=&#39;response&#39;), y_prueba) #val_error &lt;- apply((predict(mod, x_val) &gt; 0) != (y_val==1), 2, mean) #prueba_error &lt;- apply((predict(mod, x_prueba) &gt; 0) != (y_prueba==1), 2, mean) data_frame(lambda = mod$lambda, val_error=val_error, prueba_error = prueba_error) } Si la muestra de validación es chica, podemos escoger un modelo subóptimo, además que la estimación del error es mala library(tidyr) set.seed(923) dat &lt;- separar(spam, 0.98) ## ## entrena validación ## 3011 56 df_1 &lt;- ajusta_valida(dat, spam_prueba) %&gt;% gather(tipo, valor, -lambda) ggplot(df_1, aes(x=lambda, y=valor, group=tipo, colour=tipo))+ geom_line() + geom_point() + scale_x_log10() En este caso escogemos un modelo bueno, pero la estimación es mala set.seed(91123) dat &lt;- separar(spam, 0.98) ## ## entrena validación ## 3004 63 df_1 &lt;- ajusta_valida(dat, spam_prueba) %&gt;% gather(tipo, valor, -lambda) ggplot(df_1, aes(x=lambda, y=valor, group=tipo, colour=tipo))+ geom_line() + geom_point()+ scale_x_log10() Por otro lado, más datos de validación nos dan una mejor estimación el error y nos permite elegir el modelo óptimo. Pero el modelo no es tan bueno porque usamos menos datos de entrenamiento. set.seed(9113) dat &lt;- separar(spam, 0.2) ## ## entrena validación ## 609 2458 df_1 &lt;- ajusta_valida(dat, spam_prueba) %&gt;% gather(tipo, valor, -lambda) ggplot(df_1, aes(x=lambda, y=valor, group=tipo, colour=tipo))+ geom_line() + geom_point()+ scale_x_log10() Cuando tenemos una muestra de validación chica, es posible obtener rangos de error para el error. El error de validación es un promedio sobre una muestra (\\(\\overline{x}\\)), así que podemos estimar su desviación estándar mediante el error estándar \\(\\frac{s}{\\sqrt{n}}\\), donde \\(s\\) es la desviación estándar de los errores individuales de la muestra de entrenamiento. 8.6.0.1 Ejemplo set.seed(91123) dat &lt;- separar(spam, 0.98) ## ## entrena validación ## 3004 63 devianza_valor &lt;- function(z, y){ -2*(y*z - log(1+exp(z))) } entrena &lt;- dat %&gt;% filter(tipo ==&#39;entrena&#39;) %&gt;% select(-tipo) validación &lt;- dat %&gt;% filter(tipo==&#39;validación&#39;) %&gt;% select(-tipo) x &lt;- as.matrix(entrena %&gt;% select(-spam)) y &lt;- entrena$spam mod &lt;- glmnet(x = x, y = y, alpha = 0.0, family =&#39;binomial&#39;, lambda = exp(-10 )) x_val &lt;- as.matrix(validación %&gt;% select(-spam)) y_val &lt;- validación$spam validacion &lt;- devianza_valor(predict(mod, x_val, type=&#39;response&#39;), y_val) Y ahora podemos calcular el estimador puntual y el error estándar: media &lt;- mean(validacion) ee &lt;- sd(validacion)/sqrt(length(validacion)) media ## [1] 1.122394 ee ## [1] 0.05137938 Un intervalo del 95% para esta estimación es entonces c(media-2*ee, media+2*ee) ## [1] 1.019635 1.225153 Si hacemos más grande la muestra de validación dat &lt;- separar(spam, 0.5) ## ## entrena validación ## 1555 1512 entrena &lt;- dat %&gt;% filter(tipo ==&#39;entrena&#39;) %&gt;% select(-tipo) validación &lt;- dat %&gt;% filter(tipo==&#39;validación&#39;) %&gt;% select(-tipo) x &lt;- as.matrix(entrena %&gt;% select(-spam)) y &lt;- entrena$spam mod &lt;- glmnet(x = x, y = y, alpha = 0.0, family =&#39;binomial&#39;, lambda = exp(-10 )) x_val &lt;- as.matrix(validación %&gt;% select(-spam)) y_val &lt;- validación$spam validacion &lt;- devianza_valor(predict(mod, x_val, type=&#39;response&#39;), y_val) media &lt;- mean(validacion) ee &lt;- sd(validacion)/sqrt(length(validacion)) media ## [1] 1.215183 ee ## [1] 0.01197234 c(media-2*ee, media+2*ee) ## [1] 1.191238 1.239127 Ejercicio Repite el ejercicio anterior para la tasa de clasificación incorrecta (ajusta un modelo y calcula el estimador de validación del error junto a su error estándar) Repite el ejercicio anterior para un problema de regresión: en este caso, considera que el error cuadrático medio es el promedio de los errores cuadráticos de cada caso de validación. ¿Cómo harías un intervalo para la raíz del error cuadrático medio? ¿Para el error absoluto promedio? 8.7 Otros ejemplos En kaggle: un concurso para detectar cáncer de próstata contenía una variable que indicaba si el paciente había tenido una operación de próstata o no. Claramente esta variable contiene información acerca de la respuesta, pero un modelo que contiene esta variable no es útil (ve al futuro para la mayoría de los pacientes). En este caso es una filtración de la respuesta a conjunto de entrenamiento y validación. E-commerce: si intentamos predecir quién va a hacer grandes compras, variables como iva (impuesto) incurrido o uso de envío gratis (que solo aplica a compras grandes) son variables que filtran información de lo que queremos predecir y no son útiles en el modelo final. Estas variables también ven al futuro. En kaggle: en el proceso de recolección de los datos, el tamaño de archivos de grabaciones que contenían llamadas de ballenas era diferente de los que no contenían llamadas. Esta es una filtración, pues en la tarea real de predicción no tendremos a alguien que prepare estos archivos de la misma manera. Recientemente se publicó un artículo donde se argumentaba que era posible distinguir (usando redes neuronales convolucionales) caras de criminales y no criminales. Las fotos se obtuvieron de fotos de la policía (criminales) y fotos de idetificaciones (no criminales). ¿Qué crees que podría fallar aquí en términos de filtración de datos? 8.8 Resumen El procesamiento de datos para modelo predictivos es difícil. Cuando hay una dimensión temporal, es bueno usarla a lo largo de todo el proceso para poner una barrera entre entrenamiento y validación. Cuando los datos están organizados en grupos dentro de los que hacemos predicciones, preguntarnos si queremos predecir para nuevos grupos o los mismo grupos existentes (ejemplo de las unidades primarias de muestreo). Investigar cuando hay casos faltantes, y evaluar qué tan peligroso es construir un modelo para hacer predicciones Muchas filtraciones son muy sutiles y dificiles de detectar. Puede tener que ver con cómo funcionan los sistemas que registran los datos, decisiones de diseños de base de datos, decisiones de limpieza de datos. Siempre es bueno proponer un piloto para verificar que nuestros modelos funcionan como se espera - y considerar que una degradación del desempeño puede deberse a una filtración. Finalmente, recordamos que la mejor división es entrenamiento-validación-prueba, con separaciones claras entre ellos. Usamos validación para ajustar hiperparámetros, y con prueba sólo evaluamos unos cuantos modelos. "]
]
